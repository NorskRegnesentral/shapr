<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Train the Vaeac Model — vaeac_train_model • shapr</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Train the Vaeac Model — vaeac_train_model"><meta property="og:description" content="Function that fits a vaeac model to the given dataset based on the provided parameters,
as described in Olsen et al. (2022). Note that
all default parameters specified below origin from setup_approach.vaeac() and
vaeac_get_extra_para_default()."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">shapr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Vignettes

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/general_usage.html">General usage of shapr</a>
    </li>
    <li>
      <a href="../articles/vaeac.html">Advanced usage of the `vaeac` approach</a>
    </li>
    <li>
      <a href="../articles/regression.html">The separate and surrogate regression approches</a>
    </li>
    <li>
      <a href="../articles/asymmetric_causal.html">Asymmetric and Causal Shapley values</a>
    </li>
  </ul></li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Manual</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/NorskRegnesentral/shapr/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Train the Vaeac Model</h1>
    <small class="dont-index">Source: <a href="https://github.com/NorskRegnesentral/shapr/blob/master/R/approach_vaeac.R" class="external-link"><code>R/approach_vaeac.R</code></a></small>
    <div class="hidden name"><code>vaeac_train_model.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Function that fits a vaeac model to the given dataset based on the provided parameters,
as described in <a href="https://www.jmlr.org/papers/volume23/21-1413/21-1413.pdf" class="external-link">Olsen et al. (2022)</a>. Note that
all default parameters specified below origin from <code><a href="setup_approach.html">setup_approach.vaeac()</a></code> and
<code><a href="vaeac_get_extra_para_default.html">vaeac_get_extra_para_default()</a></code>.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">vaeac_train_model</span><span class="op">(</span></span>
<span>  <span class="va">x_train</span>,</span>
<span>  <span class="va">model_description</span>,</span>
<span>  <span class="va">folder_to_save_model</span>,</span>
<span>  <span class="va">cuda</span>,</span>
<span>  <span class="va">n_vaeacs_initialize</span>,</span>
<span>  <span class="va">epochs_initiation_phase</span>,</span>
<span>  <span class="va">epochs</span>,</span>
<span>  <span class="va">epochs_early_stopping</span>,</span>
<span>  <span class="va">save_every_nth_epoch</span>,</span>
<span>  <span class="va">val_ratio</span>,</span>
<span>  <span class="va">val_iwae_n_samples</span>,</span>
<span>  <span class="va">depth</span>,</span>
<span>  <span class="va">width</span>,</span>
<span>  <span class="va">latent_dim</span>,</span>
<span>  <span class="va">lr</span>,</span>
<span>  <span class="va">batch_size</span>,</span>
<span>  <span class="va">running_avg_n_values</span>,</span>
<span>  <span class="va">activation_function</span>,</span>
<span>  <span class="va">skip_conn_layer</span>,</span>
<span>  <span class="va">skip_conn_masked_enc_dec</span>,</span>
<span>  <span class="va">batch_normalization</span>,</span>
<span>  <span class="va">paired_sampling</span>,</span>
<span>  <span class="va">masking_ratio</span>,</span>
<span>  <span class="va">mask_gen_coalitions</span>,</span>
<span>  <span class="va">mask_gen_coalitions_prob</span>,</span>
<span>  <span class="va">sigma_mu</span>,</span>
<span>  <span class="va">sigma_sigma</span>,</span>
<span>  <span class="va">save_data</span>,</span>
<span>  <span class="va">log_exp_cont_feat</span>,</span>
<span>  <span class="va">which_vaeac_model</span>,</span>
<span>  <span class="va">verbose</span>,</span>
<span>  <span class="va">seed</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-x-train">x_train<a class="anchor" aria-label="anchor" href="#arg-x-train"></a></dt>
<dd><p>A data.table containing the training data. Categorical data must have class names \(1,2,\dots,K\).</p></dd>


<dt id="arg-model-description">model_description<a class="anchor" aria-label="anchor" href="#arg-model-description"></a></dt>
<dd><p>String (default is <code>make.names(Sys.time())</code>). String containing, e.g., the name of the
data distribution or additional parameter information. Used in the save name of the fitted model. If not provided,
then a name will be generated based on <code><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">base::Sys.time()</a></code> to ensure a unique name. We use <code><a href="https://rdrr.io/r/base/make.names.html" class="external-link">base::make.names()</a></code> to
ensure a valid file name for all operating systems.</p></dd>


<dt id="arg-folder-to-save-model">folder_to_save_model<a class="anchor" aria-label="anchor" href="#arg-folder-to-save-model"></a></dt>
<dd><p>String (default is <code><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">base::tempdir()</a></code>). String specifying a path to a folder where
the function is to save the fitted vaeac model. Note that  the path will be removed from the returned
<code><a href="explain.html">explain()</a></code> object if <code>vaeac.save_model = FALSE</code>.</p></dd>


<dt id="arg-cuda">cuda<a class="anchor" aria-label="anchor" href="#arg-cuda"></a></dt>
<dd><p>Logical (default is <code>FALSE</code>). If <code>TRUE</code>, then the <code>vaeac</code> model will be trained using cuda/GPU.
If <code><a href="https://rdrr.io/pkg/torch/man/cuda_is_available.html" class="external-link">torch::cuda_is_available()</a></code> is <code>FALSE</code>, the we fall back to use CPU. If <code>FALSE</code>, we use the CPU. Using a GPU
for smaller tabular dataset often do not improve the efficiency.
See <code><a href="https://cran.rstudio.com/web/packages/torch/vignettes/installation.html" class="external-link">vignette("installation", package = "torch")</a></code> fo help to enable running on the GPU (only Linux and Windows).</p></dd>


<dt id="arg-n-vaeacs-initialize">n_vaeacs_initialize<a class="anchor" aria-label="anchor" href="#arg-n-vaeacs-initialize"></a></dt>
<dd><p>Positive integer (default is <code>4</code>). The number of different vaeac models to initiate
in the start. Pick the best performing one after <code>epochs_initiation_phase</code>
epochs (default is <code>2</code>) and continue training that one.</p></dd>


<dt id="arg-epochs-initiation-phase">epochs_initiation_phase<a class="anchor" aria-label="anchor" href="#arg-epochs-initiation-phase"></a></dt>
<dd><p>Positive integer (default is <code>2</code>). The number of epochs to run each of the
<code>n_vaeacs_initialize</code> <code>vaeac</code> models before continuing to train only the best performing model.</p></dd>


<dt id="arg-epochs">epochs<a class="anchor" aria-label="anchor" href="#arg-epochs"></a></dt>
<dd><p>Positive integer (default is <code>100</code>). The number of epochs to train the final vaeac model.
This includes <code>epochs_initiation_phase</code>, where the default is <code>2</code>.</p></dd>


<dt id="arg-epochs-early-stopping">epochs_early_stopping<a class="anchor" aria-label="anchor" href="#arg-epochs-early-stopping"></a></dt>
<dd><p>Positive integer (default is <code>NULL</code>). The training stops if there has been no
improvement in the validation IWAE for <code>epochs_early_stopping</code> epochs. If the user wants the training process
to be solely based on this training criterion, then <code>epochs</code> in <code><a href="explain.html">explain()</a></code> should be set to a large
number. If <code>NULL</code>, then <code>shapr</code> will internally set <code>epochs_early_stopping = vaeac.epochs</code> such that early
stopping does not occur.</p></dd>


<dt id="arg-save-every-nth-epoch">save_every_nth_epoch<a class="anchor" aria-label="anchor" href="#arg-save-every-nth-epoch"></a></dt>
<dd><p>Positive integer (default is <code>NULL</code>). If provided, then the vaeac model after
every <code>save_every_nth_epoch</code>th epoch will be saved.</p></dd>


<dt id="arg-val-ratio">val_ratio<a class="anchor" aria-label="anchor" href="#arg-val-ratio"></a></dt>
<dd><p>Numeric (default is <code>0.25</code>). Scalar between <code>0</code> and <code>1</code> indicating the ratio of
instances from the input data which will be used as validation data. That is, <code>val_ratio = 0.25</code> means
that <code>75%</code> of the provided data is used as training data, while the remaining <code>25%</code> is used as validation data.</p></dd>


<dt id="arg-val-iwae-n-samples">val_iwae_n_samples<a class="anchor" aria-label="anchor" href="#arg-val-iwae-n-samples"></a></dt>
<dd><p>Positive integer (default is <code>25</code>). The number of generated samples used
to compute the IWAE criterion when validating the vaeac model on the validation data.</p></dd>


<dt id="arg-depth">depth<a class="anchor" aria-label="anchor" href="#arg-depth"></a></dt>
<dd><p>Positive integer (default is <code>3</code>). The number of hidden layers
in the neural networks of the masked encoder, full encoder, and decoder.</p></dd>


<dt id="arg-width">width<a class="anchor" aria-label="anchor" href="#arg-width"></a></dt>
<dd><p>Positive integer (default is <code>32</code>). The number of neurons in each
hidden layer in the neural networks of the masked encoder, full encoder, and decoder.</p></dd>


<dt id="arg-latent-dim">latent_dim<a class="anchor" aria-label="anchor" href="#arg-latent-dim"></a></dt>
<dd><p>Positive integer (default is <code>8</code>). The number of dimensions in the latent space.</p></dd>


<dt id="arg-lr">lr<a class="anchor" aria-label="anchor" href="#arg-lr"></a></dt>
<dd><p>Positive numeric (default is <code>0.001</code>). The learning rate used in the <code><a href="https://rdrr.io/pkg/torch/man/optim_adam.html" class="external-link">torch::optim_adam()</a></code> optimizer.</p></dd>


<dt id="arg-batch-size">batch_size<a class="anchor" aria-label="anchor" href="#arg-batch-size"></a></dt>
<dd><p>Positive integer (default is <code>64</code>). The number of samples to include in each batch
during the training of the vaeac model. Used in <code><a href="https://rdrr.io/pkg/torch/man/dataloader.html" class="external-link">torch::dataloader()</a></code>.</p></dd>


<dt id="arg-running-avg-n-values">running_avg_n_values<a class="anchor" aria-label="anchor" href="#arg-running-avg-n-values"></a></dt>
<dd><p>running_avg_n_values Positive integer (default is <code>5</code>).
The number of previous IWAE values to include
when we compute the running means of the IWAE criterion.</p></dd>


<dt id="arg-activation-function">activation_function<a class="anchor" aria-label="anchor" href="#arg-activation-function"></a></dt>
<dd><p>An <code><a href="https://rdrr.io/pkg/torch/man/nn_module.html" class="external-link">torch::nn_module()</a></code> representing an activation function such as, e.g.,
<code><a href="https://rdrr.io/pkg/torch/man/nn_relu.html" class="external-link">torch::nn_relu()</a></code> (default), <code><a href="https://rdrr.io/pkg/torch/man/nn_leaky_relu.html" class="external-link">torch::nn_leaky_relu()</a></code>, <code><a href="https://rdrr.io/pkg/torch/man/nn_selu.html" class="external-link">torch::nn_selu()</a></code>, or <code><a href="https://rdrr.io/pkg/torch/man/nn_sigmoid.html" class="external-link">torch::nn_sigmoid()</a></code>.</p></dd>


<dt id="arg-skip-conn-layer">skip_conn_layer<a class="anchor" aria-label="anchor" href="#arg-skip-conn-layer"></a></dt>
<dd><p>Logical (default is <code>TRUE</code>). If <code>TRUE</code>, we apply identity skip connections in each
layer, see <code><a href="skip_connection.html">skip_connection()</a></code>. That is, we add the input \(X\) to the outcome of each hidden layer,
so the output becomes \(X + activation(WX + b)\).</p></dd>


<dt id="arg-skip-conn-masked-enc-dec">skip_conn_masked_enc_dec<a class="anchor" aria-label="anchor" href="#arg-skip-conn-masked-enc-dec"></a></dt>
<dd><p>Logical (default is <code>TRUE</code>). If <code>TRUE</code>, we apply concatenate skip
connections between the layers in the masked encoder and decoder. The first layer of the masked encoder will be
linked to the last layer of the decoder. The second layer of the masked encoder will be
linked to the second to last layer of the decoder, and so on.</p></dd>


<dt id="arg-batch-normalization">batch_normalization<a class="anchor" aria-label="anchor" href="#arg-batch-normalization"></a></dt>
<dd><p>Logical (default is <code>FALSE</code>). If <code>TRUE</code>, we apply batch normalization after the
activation function. Note that if <code>skip_conn_layer = TRUE</code>, then the normalization is applied after the
inclusion of the skip connection. That is, we batch normalize the whole quantity \(X + activation(WX + b)\).</p></dd>


<dt id="arg-paired-sampling">paired_sampling<a class="anchor" aria-label="anchor" href="#arg-paired-sampling"></a></dt>
<dd><p>Logical (default is <code>TRUE</code>). If <code>TRUE</code>, we apply paired sampling to the training
batches. That is, the training observations in each batch will be duplicated, where the first instance will be masked
by \(S\) while the second instance will be masked by \(\bar{S}\). This ensures that the training of the
<code>vaeac</code> model becomes more stable as the model has access to the full version of each training observation. However,
this will increase the training time due to more complex implementation and doubling the size of each batch. See
<code><a href="paired_sampler.html">paired_sampler()</a></code> for more information.</p></dd>


<dt id="arg-masking-ratio">masking_ratio<a class="anchor" aria-label="anchor" href="#arg-masking-ratio"></a></dt>
<dd><p>Numeric (default is <code>0.5</code>). Probability of masking a feature in the
<code><a href="mcar_mask_generator.html">mcar_mask_generator()</a></code> (MCAR = Missing Completely At Random). The MCAR masking scheme ensures that <code>vaeac</code>
model can do arbitrary conditioning as all coalitions will be trained. <code>masking_ratio</code> will be overruled if
<code>mask_gen_coalitions</code> is specified.</p></dd>


<dt id="arg-mask-gen-coalitions">mask_gen_coalitions<a class="anchor" aria-label="anchor" href="#arg-mask-gen-coalitions"></a></dt>
<dd><p>Matrix (default is <code>NULL</code>). Matrix containing the coalitions that the
<code>vaeac</code> model will be trained on, see <code><a href="specified_masks_mask_generator.html">specified_masks_mask_generator()</a></code>. This parameter is used internally
in <code>shapr</code> when we only consider a subset of coalitions, i.e., when
<code>n_coalitions</code> \(&lt; 2^{n_{\text{features}}}\), and for group Shapley, i.e.,
when <code>group</code> is specified in <code><a href="explain.html">explain()</a></code>.</p></dd>


<dt id="arg-mask-gen-coalitions-prob">mask_gen_coalitions_prob<a class="anchor" aria-label="anchor" href="#arg-mask-gen-coalitions-prob"></a></dt>
<dd><p>Numeric array (default is <code>NULL</code>). Array of length equal to the height
of <code>mask_gen_coalitions</code> containing the probabilities of sampling the corresponding coalitions in
<code>mask_gen_coalitions</code>.</p></dd>


<dt id="arg-sigma-mu">sigma_mu<a class="anchor" aria-label="anchor" href="#arg-sigma-mu"></a></dt>
<dd><p>Numeric (default is <code>1e4</code>). One of two hyperparameter values in the normal-gamma prior
used in the masked encoder, see Section 3.3.1 in
<a href="https://www.jmlr.org/papers/volume23/21-1413/21-1413.pdf" class="external-link">Olsen et al. (2022)</a>.</p></dd>


<dt id="arg-sigma-sigma">sigma_sigma<a class="anchor" aria-label="anchor" href="#arg-sigma-sigma"></a></dt>
<dd><p>Numeric (default is <code>1e-4</code>). One of two hyperparameter values in the normal-gamma prior
used in the masked encoder, see Section 3.3.1 in
<a href="https://www.jmlr.org/papers/volume23/21-1413/21-1413.pdf" class="external-link">Olsen et al. (2022)</a>.</p></dd>


<dt id="arg-save-data">save_data<a class="anchor" aria-label="anchor" href="#arg-save-data"></a></dt>
<dd><p>Logical (default is <code>FALSE</code>). If <code>TRUE</code>, then the data is stored together with
the model. Useful if one are to continue to train the model later using <code><a href="vaeac_train_model_continue.html">vaeac_train_model_continue()</a></code>.</p></dd>


<dt id="arg-log-exp-cont-feat">log_exp_cont_feat<a class="anchor" aria-label="anchor" href="#arg-log-exp-cont-feat"></a></dt>
<dd><p>Logical (default is <code>FALSE</code>). If we are to \(\log\) transform all
continuous features before sending the data to <code><a href="vaeac.html">vaeac()</a></code>. The <code>vaeac</code> model creates unbounded Monte Carlo
sample values. Thus, if the continuous features are strictly positive (as for, e.g., the Burr distribution and
Abalone data set), it can be advantageous to \(\log\) transform the data to unbounded form before using <code>vaeac</code>.
If <code>TRUE</code>, then <code><a href="vaeac_postprocess_data.html">vaeac_postprocess_data()</a></code> will take the \(\exp\) of the results to get back to strictly
positive values when using the <code>vaeac</code> model to impute missing values/generate the Monte Carlo samples.</p></dd>


<dt id="arg-which-vaeac-model">which_vaeac_model<a class="anchor" aria-label="anchor" href="#arg-which-vaeac-model"></a></dt>
<dd><p>String (default is <code>best</code>). The name of the <code>vaeac</code> model (snapshots from different
epochs) to use when generating the Monte Carlo samples. The standard choices are: <code>"best"</code> (epoch with lowest IWAE),
<code>"best_running"</code> (epoch with lowest running IWAE, see <code>vaeac.running_avg_n_values</code>), and <code>last</code> (the last epoch).
Note that additional choices are available if <code>vaeac.save_every_nth_epoch</code> is provided. For example, if
<code>vaeac.save_every_nth_epoch = 5</code>, then <code>vaeac.which_vaeac_model</code> can also take the values <code>"epoch_5"</code>, <code>"epoch_10"</code>,
<code>"epoch_15"</code>, and so on.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>String vector or NULL.
Specifies the verbosity (printout detail level) through one or more of strings <code>"basic"</code>, <code>"progress"</code>,
<code>"convergence"</code>, <code>"shapley"</code> and <code>"vS_details"</code>.
<code>"basic"</code> (default) displays basic information about the computation which is being performed.
<code>"progress</code> displays information about where in the calculation process the function currently is.
#' <code>"convergence"</code> displays information on how close to convergence the Shapley value estimates are
(only when <code>iterative = TRUE</code>) .
<code>"shapley"</code> displays intermediate Shapley value estimates and standard deviations (only when <code>iterative = TRUE</code>)</p><ul><li><p>the final estimates.
<code>"vS_details"</code> displays information about the v_S estimates.
This is most relevant for <code>approach %in% c("regression_separate", "regression_surrogate", "vaeac"</code>).
<code>NULL</code> means no printout.
Note that any combination of four strings can be used.
E.g. <code>verbose = c("basic", "vS_details")</code> will display basic information + details about the v(S)-estimation process.</p></li>
</ul></dd>


<dt id="arg-seed">seed<a class="anchor" aria-label="anchor" href="#arg-seed"></a></dt>
<dd><p>Positive integer (default is <code>1</code>). Seed for reproducibility. Specifies the seed before any randomness
based code is being run.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>List of extra parameters, currently not used.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>A list containing the training/validation errors and paths to where the vaeac models are saved on the disk.</p>
    </div>
    <div id="details">
    <h2>Details</h2>
    <p>The vaeac model consists of three neural networks, i.e., a masked encoder, a full encoder, and a decoder.
The networks have shared <code>depth</code>, <code>width</code>, and <code>activation_function</code>. The encoders maps the <code>x_train</code>
to a latent representation of dimension <code>latent_dim</code>, while the decoder maps the latent representations
back to the feature space. See <a href="https://www.jmlr.org/papers/volume23/21-1413/21-1413.pdf" class="external-link">Olsen et al. (2022)</a>
for more details. The function first initiates <code>n_vaeacs_initialize</code> vaeac models with different randomly
initiated network parameter values to remedy poorly initiated values. After <code>epochs_initiation_phase</code> epochs, the
<code>n_vaeacs_initialize</code> vaeac models are compared and the function continues to only train the best performing
one for a total of <code>epochs</code> epochs. The networks are trained using the ADAM optimizer with the learning rate is <code>lr</code>.</p>
    </div>
    <div id="references">
    <h2>References</h2>

<ul><li><p><a href="https://www.jmlr.org/papers/volume23/21-1413/21-1413.pdf" class="external-link">
Olsen, L. H., Glad, I. K., Jullum, M., &amp; Aas, K. (2022). Using Shapley values and variational autoencoders to
explain predictive models with dependent mixed features. Journal of machine learning research, 23(213), 1-51</a></p></li>
</ul></div>
    <div id="author">
    <h2>Author</h2>
    <p>Lars Henry Berge Olsen</p>
    </div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Martin Jullum, Lars Henry Berge Olsen, Annabelle Redelmeier, Jon Lachmann, Nikolai Sellereite, Norsk Regnesentral.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

      </footer></div>






  </body></html>

