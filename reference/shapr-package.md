# shapr: Prediction Explanation with Dependence-Aware Shapley Values

Complex machine learning models are often hard to interpret. However, in
many situations it is crucial to understand and explain why a model made
a specific prediction. Shapley values is the only method for such
prediction explanation framework with a solid theoretical foundation.
Previously known methods for estimating the Shapley values do, however,
assume feature independence. This package implements methods which
accounts for any feature dependence, and thereby produces more accurate
estimates of the true Shapley values. An accompanying 'Python' wrapper
('shaprpy') is available through PyPI.

## See also

Useful links:

- <https://norskregnesentral.github.io/shapr/>

- <https://github.com/NorskRegnesentral/shapr/>

- Report bugs at <https://github.com/NorskRegnesentral/shapr/issues>

## Author

**Maintainer**: Martin Jullum <Martin.Jullum@nr.no>
([ORCID](https://orcid.org/0000-0003-3908-5155))

Authors:

- Lars Henry Berge Olsen <lhbolsen@nr.no>
  ([ORCID](https://orcid.org/0009-0006-9360-6993))

- Annabelle Redelmeier <ardelmeier@gmail.com>

- Jon Lachmann <Jon@lachmann.nu>
  ([ORCID](https://orcid.org/0000-0001-8396-5673))

- Nikolai Sellereite <nikolaisellereite@gmail.com>
  ([ORCID](https://orcid.org/0000-0002-4671-0337))

Other contributors:

- Anders Løland <Anders.Loland@nr.no> \[contributor\]

- Jens Christian Wahl <jens.c.wahl@gmail.com> \[contributor\]

- Camilla Lingjærde \[contributor\]

- Norsk Regnesentral \[copyright holder, funder\]
