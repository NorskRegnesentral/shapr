% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/setup.R
\name{setup}
\alias{setup}
\title{check_setup}
\usage{
setup(
  x_train,
  x_explain,
  approach,
  paired_shap_sampling = FALSE,
  prediction_zero,
  output_size = 1,
  max_n_coalitions,
  group,
  n_MC_samples,
  n_batches,
  seed,
  keep_samp_for_vS,
  feature_specs,
  MSEv_uniform_comb_weights = TRUE,
  type = "normal",
  horizon = NULL,
  y = NULL,
  xreg = NULL,
  train_idx = NULL,
  explain_idx = NULL,
  explain_y_lags = NULL,
  explain_xreg_lags = NULL,
  group_lags = NULL,
  verbose,
  adaptive = FALSE,
  adaptive_arguments = list(),
  shapley_reweighting = "none",
  is_python = FALSE,
  testing = FALSE,
  init_time = NULL,
  prev_shapr_object = NULL,
  ...
)
}
\arguments{
\item{x_train}{Matrix or data.frame/data.table.
Contains the data used to estimate the (conditional) distributions for the features
needed to properly estimate the conditional expectations in the Shapley formula.}

\item{x_explain}{A matrix or data.frame/data.table.
Contains the the features, whose predictions ought to be explained.}

\item{approach}{Character vector of length \code{1} or one less than the number of features.
All elements should, either be \code{"gaussian"}, \code{"copula"}, \code{"empirical"}, \code{"ctree"}, \code{"vaeac"},
\code{"categorical"}, \code{"timeseries"}, \code{"independence"}, \code{"regression_separate"}, or \code{"regression_surrogate"}.
The two regression approaches can not be combined with any other approach. See details for more information.}

\item{paired_shap_sampling}{TODO: document}

\item{prediction_zero}{Numeric.
The prediction value for unseen data, i.e. an estimate of the expected prediction without conditioning on any
features.
Typically we set this value equal to the mean of the response variable in our training data, but other choices
such as the mean of the predictions in the training data are also reasonable.}

\item{output_size}{TODO: Document}

\item{max_n_coalitions}{Integer.
The upper limit on the number of unique feature/group coalitions to use in the adaptive procedure
(if \code{adaptive = TRUE}).
If \code{adaptive = FALSE} it represents the number of feature/group coalitions to use directly.
The quantity refers to the number of unique feature coalitions if \code{group = NULL},
and group coalitions if \code{group != NULL}.
\code{max_n_coalitions = NULL} corresponds to \code{max_n_coalitions=2^n_features}.}

\item{group}{List.
If \code{NULL} regular feature wise Shapley values are computed.
If provided, group wise Shapley values are computed. \code{group} then has length equal to
the number of groups. The list element contains character vectors with the features included
in each of the different groups.}

\item{n_MC_samples}{Positive integer.
Indicating the maximum number of samples to use in the
Monte Carlo integration for every conditional expectation. See also details.}

\item{n_batches}{Positive integer (or NULL).
Specifies how many batches the total number of coalitions should be split into when calculating the
contribution function for each test observation.
The default value is NULL which uses a reasonable trade-off between RAM allocation and computation speed,
which depends on \code{approach} and \code{n_coalitions}.
For models with many features, increasing the number of batches reduces the RAM allocation significantly.
This typically comes with a small increase in computation time.}

\item{seed}{Positive integer.
Specifies the seed before any randomness based code is being run.
If \code{NULL} the seed will be inherited from the calling environment.}

\item{keep_samp_for_vS}{Logical.
Indicates whether the samples used in the Monte Carlo estimation of v_S should be returned
(in \code{internal$output})}

\item{feature_specs}{List. The output from \code{\link[=get_model_specs]{get_model_specs()}} or \code{\link[=get_data_specs]{get_data_specs()}}.
Contains the 3 elements:
\describe{
\item{labels}{Character vector with the names of each feature.}
\item{classes}{Character vector with the classes of each features.}
\item{factor_levels}{Character vector with the levels for any categorical features.}
}}

\item{MSEv_uniform_comb_weights}{Logical. If \code{TRUE} (default), then the function weights the coalitions
uniformly when computing the MSEv criterion. If \code{FALSE}, then the function use the Shapley kernel weights to
weight the coalitions when computing the MSEv criterion. Note that the Shapley kernel weights are replaced by the
sampling frequency when not all coalitions are considered.}

\item{type}{Character.
Either "normal" or "forecast" corresponding to function \code{setup()} is called from,
correspondingly the type of explanation that should be generated.}

\item{horizon}{Numeric.
The forecast horizon to explain. Passed to the \code{predict_model} function.}

\item{y}{Matrix, data.frame/data.table or a numeric vector.
Contains the endogenous variables used to estimate the (conditional) distributions
needed to properly estimate the conditional expectations in the Shapley formula
including the observations to be explained.}

\item{xreg}{Matrix, data.frame/data.table or a numeric vector.
Contains the exogenous variables used to estimate the (conditional) distributions
needed to properly estimate the conditional expectations in the Shapley formula
including the observations to be explained.
As exogenous variables are used contemporaneusly when producing a forecast,
this item should contain nrow(y) + horizon rows.}

\item{train_idx}{Numeric vector
The row indices in data and reg denoting points in time to use when estimating the conditional expectations in
the Shapley value formula.
If \code{train_idx = NULL} (default) all indices not selected to be explained will be used.}

\item{explain_idx}{Numeric vector
The row indices in data and reg denoting points in time to explain.}

\item{explain_y_lags}{Numeric vector.
Denotes the number of lags that should be used for each variable in \code{y} when making a forecast.}

\item{explain_xreg_lags}{Numeric vector.
If \code{xreg != NULL}, denotes the number of lags that should be used for each variable in \code{xreg} when making a forecast.}

\item{group_lags}{Logical.
If \code{TRUE} all lags of each variable are grouped together and explained as a group.
If \code{FALSE} all lags of each variable are explained individually.}

\item{verbose}{An integer specifying the level of verbosity. If \code{0}, \code{shapr} will stay silent.
If \code{1}, it will print information about performance. If \code{2}, some additional information will be printed out.
Use \code{0} (default) for no verbosity, \code{1} for low verbose, and \code{2} for high verbose.
TODO: Make this clearer when we end up fixing this and if they should force a progressr bar.}

\item{adaptive}{TODO: document}

\item{adaptive_arguments}{TODO: document}

\item{shapley_reweighting}{TODO: document}

\item{is_python}{Logical. Indicates whether the function is called from the Python wrapper. Default is FALSE which is
never changed when calling the function via \code{explain()} in R. The parameter is later used to disallow
running the AICc-versions of the empirical as that requires data based optimization.}

\item{...}{Further arguments passed to specific approaches}
}
\description{
check_setup
}
