% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/approach.R, R/approach_categorical.R,
%   R/approach_copula.R, R/approach_ctree.R, R/approach_empirical.R,
%   R/approach_gaussian.R, R/approach_independence.R, R/approach_timeseries.R,
%   R/approach_vaeac.R
\name{setup_approach}
\alias{setup_approach}
\alias{setup_approach.categorical}
\alias{setup_approach.copula}
\alias{setup_approach.ctree}
\alias{setup_approach.empirical}
\alias{setup_approach.gaussian}
\alias{setup_approach.independence}
\alias{setup_approach.timeseries}
\alias{setup_approach.vaeac}
\title{Set up the framework chosen approach}
\usage{
setup_approach(internal, ...)

\method{setup_approach}{categorical}(
  internal,
  categorical.joint_prob_dt = NULL,
  categorical.epsilon = 0.001,
  ...
)

\method{setup_approach}{copula}(internal, ...)

\method{setup_approach}{ctree}(
  internal,
  ctree.mincriterion = 0.95,
  ctree.minsplit = 20,
  ctree.minbucket = 7,
  ctree.sample = TRUE,
  ...
)

\method{setup_approach}{empirical}(
  internal,
  empirical.type = "fixed_sigma",
  empirical.eta = 0.95,
  empirical.fixed_sigma = 0.1,
  empirical.n_samples_aicc = 1000,
  empirical.eval_max_aicc = 20,
  empirical.start_aicc = 0.1,
  empirical.cov_mat = NULL,
  model = NULL,
  predict_model = NULL,
  ...
)

\method{setup_approach}{gaussian}(internal, gaussian.mu = NULL, gaussian.cov_mat = NULL, ...)

\method{setup_approach}{independence}(internal, ...)

\method{setup_approach}{timeseries}(
  internal,
  timeseries.fixed_sigma_vec = 2,
  timeseries.bounds = c(NULL, NULL),
  ...
)

\method{setup_approach}{vaeac}(
  internal,
  vaeac.depth = 3,
  vaeac.width = 32,
  vaeac.latent_dim = 8,
  vaeac.activation_function = torch::nn_relu,
  vaeac.lr = 0.001,
  vaeac.n_vaeacs_initialize = 10,
  vaeac.epochs = 200,
  vaeac.extra_parameters = list(),
  ...
)
}
\arguments{
\item{internal}{Not used.}

\item{...}{\code{approach}-specific arguments. See below.}

\item{categorical.joint_prob_dt}{Data.table. (Optional)
Containing the joint probability distribution for each combination of feature
values.
\code{NULL} means it is estimated from the \code{x_train} and \code{x_explain}.}

\item{categorical.epsilon}{Numeric value. (Optional)
If \code{joint_probability_dt} is not supplied, probabilities/frequencies are
estimated using \code{x_train}. If certain observations occur in \code{x_train} and NOT in \code{x_explain},
then epsilon is used as the proportion of times that these observations occurs in the training data.
In theory, this proportion should be zero, but this causes an error later in the Shapley computation.}

\item{ctree.mincriterion}{Numeric scalar or vector. (default = 0.95)
Either a scalar or vector of length equal to the number of features in the model.
Value is equal to 1 - \eqn{\alpha} where \eqn{\alpha} is the nominal level of the conditional independence tests.
If it is a vector, this indicates which value to use when conditioning on various numbers of features.}

\item{ctree.minsplit}{Numeric scalar. (default = 20)
Determines minimum value that the sum of the left and right daughter nodes required for a split.}

\item{ctree.minbucket}{Numeric scalar. (default = 7)
Determines the minimum sum of weights in a terminal node required for a split}

\item{ctree.sample}{Boolean. (default = TRUE)
If TRUE, then the method always samples \code{n_samples} observations from the leaf nodes (with replacement).
If FALSE and the number of observations in the leaf node is less than \code{n_samples},
the method will take all observations in the leaf.
If FALSE and the number of observations in the leaf node is more than \code{n_samples},
the method will sample \code{n_samples} observations (with replacement).
This means that there will always be sampling in the leaf unless
\code{sample} = FALSE AND the number of obs in the node is less than \code{n_samples}.}

\item{empirical.type}{Character. (default = \code{"fixed_sigma"})
Should be equal to either \code{"independence"},\code{"fixed_sigma"}, \code{"AICc_each_k"} \code{"AICc_full"}.
TODO: Describe better what the methods do here.}

\item{empirical.eta}{Numeric. (default = 0.95)
Needs to be \verb{0 < eta <= 1}.
Represents the minimum proportion of the total empirical weight that data samples should use.
If e.g. \code{eta = .8} we will choose the \code{K} samples with the largest weight so that the sum of the weights
accounts for 80\\% of the total weight.
\code{eta} is the \eqn{\eta} parameter in equation (15) of Aas et al (2021).}

\item{empirical.fixed_sigma}{Positive numeric scalar. (default = 0.1)
Represents the kernel bandwidth in the distance computation used when conditioning on all different combinations.
Only used when \code{empirical.type = "fixed_sigma"}}

\item{empirical.n_samples_aicc}{Positive integer. (default = 1000)
Number of samples to consider in AICc optimization.
Only used for \code{empirical.type} is either \code{"AICc_each_k"} or \code{"AICc_full"}.}

\item{empirical.eval_max_aicc}{Positive integer. (default = 20)
Maximum number of iterations when optimizing the AICc.
Only used for \code{empirical.type} is either \code{"AICc_each_k"} or \code{"AICc_full"}.}

\item{empirical.start_aicc}{Numeric. (default = 0.1)
Start value of the \code{sigma} parameter when optimizing the AICc.
Only used for \code{empirical.type} is either \code{"AICc_each_k"} or \code{"AICc_full"}.}

\item{empirical.cov_mat}{Numeric matrix. (Optional, default = NULL)
Containing the covariance matrix of the data generating distribution used to define the Mahalanobis distance.
\code{NULL} means it is estimated from \code{x_train}.}

\item{model}{Objects.
The model object that ought to be explained.
See the documentation of \code{\link[=explain]{explain()}} for details.}

\item{predict_model}{Function.
The prediction function used when \code{model} is not natively supported.
See the documentation of \code{\link[=explain]{explain()}} for details.}

\item{gaussian.mu}{Numeric vector. (Optional)
Containing the mean of the data generating distribution.
\code{NULL} means it is estimated from the \code{x_train}.}

\item{gaussian.cov_mat}{Numeric matrix. (Optional)
Containing the covariance matrix of the data generating distribution.
\code{NULL} means it is estimated from the \code{x_train}.}

\item{timeseries.fixed_sigma_vec}{Numeric. (Default = 2)
Represents the kernel bandwidth in the distance computation. TODO: What length should it have? 1?}

\item{timeseries.bounds}{Numeric vector of length two. (Default = c(NULL, NULL))
If one or both of these bounds are not NULL, we restrict the sampled time series to be
between these bounds.
This is useful if the underlying time series are scaled between 0 and 1, for example.}

\item{vaeac.depth}{Integer. The number of hidden layers in the neural networks of the masked
encoder, full encoder, and decoder.}

\item{vaeac.width}{Integer. The number of neurons in each hidden layer in the neural networks
of the masked encoder, full encoder, and decoder.}

\item{vaeac.latent_dim}{Integer. The number of dimensions in the latent space.}

\item{vaeac.activation_function}{An \code{\link[torch:nn_module]{torch::nn_module()}} representing an activation
function such as, e.g., \code{\link[torch:nn_relu]{torch::nn_relu()}}, \code{\link[torch:nn_leaky_relu]{torch::nn_leaky_relu()}},
\code{\link[torch:nn_selu]{torch::nn_selu()}}, and \code{\link[torch:nn_sigmoid]{torch::nn_sigmoid()}}.}

\item{vaeac.lr}{Numeric. The learning rate used in the \code{\link[torch:optim_adam]{torch::optim_adam()}} optimizer.}

\item{vaeac.n_vaeacs_initialize}{Integer. The number of different vaeac models to initiate
in the start. Pick the best performing one after \code{vaeac.extra_parameters$epochs_initiation_phase}
epochs (default is \code{2}) and continue training that one.}

\item{vaeac.epochs}{Integer. The number of epochs to train the final vaeac model. This includes
\code{vaeac.extra_parameters$epochs_initiation_phase}, where the default is \code{2}.}

\item{vaeac.extra_parameters}{Named list with extra parameters to the \code{vaeac} approach.
See \code{\link[=vaeac_get_extra_para_default]{vaeac_get_extra_para_default()}} for description of possible additional parameters.}
}
\description{
The different choices of \code{approach} takes different (optional) parameters,
which are forwarded from \code{\link[=explain]{explain()}}.
}
\section{The vaeac approach}{

The \code{vaeac} model consists of three neural network (a full encoder, a masked encoder, and a decoder) based
on the provided \code{vaeac.depth} and \code{vaeac.width}. The encoders map the full and masked input
representations to latent representations, respectively, where the dimension is given by \code{vaeac.latent_dim}.
The latent representations are sent to the decoder to go back to the real feature space and
provide a samplable probabilistic representation, from which the Monte Carlo samples are generated.
We use the \code{vaeac} method at the epoch with the lowest validation error (IWAE) by default, but
other possibilities are available but setting the \code{vaeac.which_vaeac_model} parameter.
}

\author{
Martin Jullum

Lars Henry Berge Olsen
}
