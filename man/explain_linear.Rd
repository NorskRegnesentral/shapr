% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/explain_linear.R
\name{explain_linear}
\alias{explain_linear}
\title{Explain the output of a linear model with  Shapley values}
\usage{
explain_linear(
  model,
  x_explain,
  x_train,
  n_permutations = NULL,
  group = NULL,
  n_batches = NULL,
  seed = 1,
  predict_model = NULL,
  get_model_specs = NULL,
  MSEv_uniform_comb_weights = TRUE,
  timing = TRUE,
  ...
)
}
\arguments{
\item{model}{The model whose predictions we want to explain.
Run \code{\link[=get_supported_models]{get_supported_models()}}
for a table of which models \code{explain} supports natively. Unsupported models
can still be explained by passing \code{predict_model} and (optionally) \code{get_model_specs},
see details for more information.}

\item{x_explain}{A matrix or data.frame/data.table.
Contains the the features, whose predictions ought to be explained.}

\item{x_train}{Matrix or data.frame/data.table.
Contains the data used to estimate the (conditional) distributions for the features
needed to properly estimate the conditional expectations in the Shapley formula.}

\item{group}{List.
If \code{NULL} regular feature wise Shapley values are computed.
If provided, group wise Shapley values are computed. \code{group} then has length equal to
the number of groups. The list element contains character vectors with the features included
in each of the different groups.}

\item{n_batches}{Positive integer (or NULL).
Specifies how many batches the total number of feature combinations should be split into when calculating the
contribution function for each test observation.
The default value is NULL which uses a reasonable trade-off between RAM allocation and computation speed,
which depends on \code{approach} and \code{n_combinations}.
For models with many features, increasing the number of batches reduces the RAM allocation significantly.
This typically comes with a small increase in computation time.}

\item{seed}{Positive integer.
Specifies the seed before any randomness based code is being run.
If \code{NULL} the seed will be inherited from the calling environment.}

\item{predict_model}{Function.
The prediction function used when \code{model} is not natively supported.
(Run \code{\link[=get_supported_models]{get_supported_models()}} for a list of natively supported
models.)
The function must have two arguments, \code{model} and \code{newdata} which specify, respectively, the model
and a data.frame/data.table to compute predictions for. The function must give the prediction as a numeric vector.
\code{NULL} (the default) uses functions specified internally.
Can also be used to override the default function for natively supported model classes.}

\item{get_model_specs}{Function.
An optional function for checking model/data consistency when \code{model} is not natively supported.
(Run \code{\link[=get_supported_models]{get_supported_models()}} for a list of natively supported
models.)
The function takes \code{model} as argument and provides a list with 3 elements:
\describe{
\item{labels}{Character vector with the names of each feature.}
\item{classes}{Character vector with the classes of each features.}
\item{factor_levels}{Character vector with the levels for any categorical features.}
}
If \code{NULL} (the default) internal functions are used for natively supported model classes, and the checking is
disabled for unsupported model classes.
Can also be used to override the default function for natively supported model classes.}

\item{MSEv_uniform_comb_weights}{Logical. If \code{TRUE} (default), then the function weights the combinations
uniformly when computing the MSEv criterion. If \code{FALSE}, then the function use the Shapley kernel weights to
weight the combinations when computing the MSEv criterion. Note that the Shapley kernel weights are replaced by the
sampling frequency when not all combinations are considered.}

\item{timing}{Logical.
Whether the timing of the different parts of the \code{explain()} should saved in the model object.}

\item{...}{Further arguments passed to specific approaches}
}
\description{
Explain the output of a linear model with  Shapley values
}
\author{
Martin Jullum
}
