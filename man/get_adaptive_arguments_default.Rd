% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/setup.R
\name{get_adaptive_arguments_default}
\alias{get_adaptive_arguments_default}
\title{Function to specify arguments of the adaptive estimation procedure}
\usage{
get_adaptive_arguments_default(
  internal,
  initial_n_coalitions = ceiling(min(200, internal$parameters$max_n_coalitions_causal,
    internal$parameters$max_n_coalitions, max(5, internal$parameters$n_features,
    (2^internal$parameters$n_features)/10))),
  fixed_n_coalitions_per_iter = NULL,
  max_iter = 20,
  convergence_tolerance = 0.02,
  reduction_factor_vec = c(seq(0.1, 1, by = 0.1), rep(1, max_iter - 10)),
  n_boot_samps = 100,
  compute_sd = isTRUE(internal$parameters$adaptive),
  max_batch_size = 10,
  min_n_batches = 10,
  saving_path = tempfile("shapr_obj_", fileext = ".rds")
)
}
\arguments{
\item{internal}{List.
Not used directly, but passed through from \code{\link[=explain]{explain()}}.}

\item{initial_n_coalitions}{Integer. Number of coalitions to use in the first estimation iteration.}

\item{fixed_n_coalitions_per_iter}{Integer. Number of \code{n_coalitions} to use in each iteration.
\code{NULL} (default) means setting it based on estimates based on a set convergence threshold.}

\item{max_iter}{Integer. Maximum number of estimation iterations}

\item{convergence_tolerance}{Numeric. The t variable in the convergence threshold formula on page 6 in the paper
Covert and Lee (2021), 'Improving KernelSHAP: Practical Shapley Value Estimation via Linear Regression'
https://arxiv.org/pdf/2012.01536. Smaller values requires more coalitions before convergence is reached.}

\item{reduction_factor_vec}{Numeric vector. The number of \code{n_coalitions} that must be used to reach convergence
in the next iteration is estimated.
The number of \code{n_coalitions} actually used in the next iteration is set to this estimate multiplied by
\code{reduction_factor_vec[i]} for iteration \code{i}.
It is wise to start with smaller numbers to avoid using too many \code{n_coalitions} due to uncertain estimates in
the first iterations.}

\item{n_boot_samps}{Integer. The number of bootstrapped samples (i.e. samples with replacement) from the set of all
coalitions used to estimate the standard deviations of the Shapley value estimates.}

\item{compute_sd}{Logical. Whether to estimate the standard deviations of the Shapley value estimates.}

\item{max_batch_size}{Integer. The maximum number of coalitions to estimate simultaneously within each iteration.
A larger numbers requires more memory, but may have a slight computational advantage.}

\item{min_n_batches}{Integer. The minimum number of batches to split the computation into within each iteration.
Larger numbers gives more frequent progress updates. If parallelization is applied, this should be set no smaller
than the number of parallel workers.}

\item{saving_path}{String.
The path to the directory where the results of the adaptive estimation procedure should be saved.
Defaults to a temporary directory.}
}
\description{
Function to specify arguments of the adaptive estimation procedure
}
\details{
The functions sets default values for the adaptive estimation procedure, according to the function defaults.
If the argument \code{adaptive} of \code{\link[=explain]{explain()}} is FALSE, it sets parameters corresponding to the use of a
non-adaptive estimation procedure
}
\author{
Martin Jullum
}
