<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Shapley value explanations using the regression paradigm • shapr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Shapley value explanations using the regression paradigm">
<meta property="og:description" content="shapr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">shapr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.2.3.9200</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/understanding_shapr.html">General usage of shapr</a>
    </li>
    <li>
      <a href="../articles/understanding_shapr_vaeac.html">Advanced usage of the `vaeac` approach</a>
    </li>
    <li>
      <a href="../articles/understanding_shapr_regression.html">The separate and surrogate regression approches</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Manual</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/NorskRegnesentral/shapr/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Shapley value explanations using the regression
paradigm</h1>
                        <h4 data-toc-skip class="author">Lars Henry
Berge Olsen</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/NorskRegnesentral/shapr/blob/HEAD/vignettes/understanding_shapr_regression.Rmd" class="external-link"><code>vignettes/understanding_shapr_regression.Rmd</code></a></small>
      <div class="hidden name"><code>understanding_shapr_regression.Rmd</code></div>

    </div>

    
    
<!-- # Table of Contents -->
<!-- * [Section 1](#separate) -->
<!-- * [Section 2](#surrogate) -->
<!-- > [The separate regression method class](#separate) -->
<!-- >> [Data pre-processing](#separate_preproc) -->
<!-- >> [Cross-validation](#separate_cv) -->
<!-- >> [Parallelization](#separate_parallelization) -->
<!-- > [The surrogate regression method class](#surrogate) -->
<!-- > [Add new regression methods](#new) -->
<!-- > [Summary figures](#summary) -->
<!-- > [Mixed data](#mixed) -->
<p><a id="intro"></a></p>
<p>This vignette elaborates and demonstrates the regression paradigm
explained in <span class="citation">Olsen et al. (2024)</span>. We
describe how to specify the regression model, how to enable automatic
cross-validation of the model’s hyperparameters, and applying
pre-processing steps to the data before fitting the regression models.
We refer to <span class="citation">Olsen et al. (2024)</span> for when
one should use the different paradigms, method classes, and methods.</p>
<p><span class="citation">Olsen et al. (2024)</span> divides the
regression paradigm into the separate and surrogate regression method
classes. In this vignette, we briefly introduce the two method classes.
For an in-depth explanation, we refer the reader to Sections 3.5 and 3.6
in <span class="citation">Olsen et al. (2024)</span>.</p>
<p>Briefly stated, the regression paradigm uses regression models to
directly estimate the contribution function <span class="math inline">\(v(S) = E[f(\boldsymbol{x})|\boldsymbol{x}_S =
\boldsymbol{x}_S^*]\)</span>. The separate regression method class fits
a separate regression model for each coalition <span class="math inline">\(S\)</span>, while the surrogate regression method
class fits a single regression model to simultaneously predict the
contribution function for all coalitions.</p>
<p>The <code>shapr</code> package supports any regression model from the
popular <code>tidymodels</code> package developed by <span class="citation">Kuhn and Wickham (2020)</span>. The <a href="https://www.tidymodels.org/" class="external-link"><code>tidymodels</code></a> framework
is a collection of packages for modeling and machine learning using <a href="https://www.tidyverse.org/" class="external-link"><code>tidyverse</code></a> principles.
Some packages included in the <code>tidymodels</code> framework are
<code>parsnip</code>, <code>recipes</code>, <code>workflows</code>
<code>tune</code>, and <code>rsample</code>; see the <a href="#setup">setup</a> section below for more examples. Furthermore,
click <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">here</a> to
access the complete list of supported regression models in the
<code>tidymodels</code> package. There are currently 80 supported
models, but we can apply a wide range of pre-processing data steps to
increase this number or add regression models not already implemented in
<code>tidymodels</code>. In the former setting, we can either apply the
linear regression model directly to the data or pre-process the data to
compute principal components (principal component regression), which we
do in the <a href="#separate_preproc">pre-process</a> section. For the
latter setting, we demonstrate how to incorporate the projection pursuit
regression model into the <code>tidymodels</code> framework in the <a href="#new">add new regression methods</a> section.</p>
<p>Note that our framework does not currently support model formulas
with special terms. For example, we do not support
<code><a href="https://parsnip.tidymodels.org/reference/gen_additive_mod.html" class="external-link">parsnip::gen_additive_mod</a></code> (i.e., <code><a href="https://rdrr.io/pkg/mgcv/man/gam.html" class="external-link">mgcv::gam()</a></code>)
as it uses a non-standard notion in its formulas (in this case, the
<code>s(feature, k = 2)</code> function). See
<code>?parsnip::model_formula()</code> for more information. However,
this hurdle is overcome by pre-processing data steps containing spline
functions, which we do in the <a href="#separate_preproc">pre-process</a> section for the separate
regression method class.</p>
<p>In the <a href="#mixed">mixed data</a> section, we demonstrate that
the regression-based methods work on mixed data, too. However, we must
add a pre-processing step for the regression models that do not natively
support categorical data to encode the categorical features.</p>
<p>Note that we use the same data and predictive models in this vignette
as in the main vignette.</p>
<p>See the end of the <a href="#summary">continous data</a> and <a href="#summary_mixed">mixed data</a> sections for summary figures of all
the methods used in this vignette to compute the Shapley value
explanations.</p>
<div class="section level2">
<h2 id="separate">The separate regression method class<a class="anchor" aria-label="anchor" href="#separate"></a>
</h2>
<p>In the <code>regression_separate</code> methods, we train a new
regression model <span class="math inline">\(g_S(\boldsymbol{x}s)\)</span> to estimate the
conditional expectation for each coalition of features.</p>
<p>The idea is to estimate <span class="math inline">\(v(S) =
E[f(\boldsymbol{x})|\boldsymbol{x}_S = \boldsymbol{x}_S^*] =
E[f(\boldsymbol{x}_{\bar{S}},\boldsymbol{x}_S)|\boldsymbol{x}_S=\boldsymbol{x}_S^*]\)</span>
separately for each coalition <span class="math inline">\(S\)</span>
using regression. Let <span class="math inline">\(\mathcal{D} = \{
\boldsymbol{x}^{[i]}, y^{[i]} \}_{i=1}^{N_{\text{train}}}\)</span>
denote the training data, where <span class="math inline">\(\boldsymbol{x}^{[i]}\)</span> is the <span class="math inline">\(i\)</span>th <span class="math inline">\(M\)</span>-dimensional input and <span class="math inline">\(y^{[i]}\)</span> is the associated response. For
each coalition <span class="math inline">\(S \subseteq
\{1,2,\dots,M\}\)</span>, the corresponding training data set is <span class="math display">\[\begin{align*}
            \mathcal{D}_S
            =
            \{\boldsymbol{x}_S^{[i]},
f(\underbrace{\boldsymbol{x}_\bar{S}^{[i]},
\boldsymbol{x}_S^{[i]}}_{\boldsymbol{x}^{[i]}})\}_{i=1}^{N_{\text{train}}}
            =
            \{\boldsymbol{x}_S^{[i]},
\underbrace{f(\boldsymbol{x}^{[i]})}_{z^{[i]}}\}_{i=1}^{N_{\text{train}}}
            =
            \{\boldsymbol{x}_S^{[i]},
z^{[i]}\}_{i=1}^{N_{\text{train}}}.
\end{align*}\]</span></p>
<p>For each data set <span class="math inline">\(\mathcal{D}_S\)</span>,
we train a regression model <span class="math inline">\(g_S(\boldsymbol{x}s)\)</span> with respect to the
mean squared error loss function. That is, we fit a regression model
where the prediction <span class="math inline">\(f(\boldsymbol{x})\)</span> is acting as the
response and the feature subset of coalition <span class="math inline">\(S\)</span>, <span class="math inline">\(\boldsymbol{x}_S\)</span>, is acting as the
available features. The optimal model, with respect to the loss
function, is <span class="math inline">\(g^*_S(\boldsymbol{x}_S) =
E[z|\boldsymbol{x}_S] = E[f(\boldsymbol{x}_\bar{S},
\boldsymbol{x}_S)|\boldsymbol{x}_S]\)</span>, which corresponds to the
contribution function <span class="math inline">\(v(S)\)</span>. The
regression model <span class="math inline">\(g_S\)</span> aims for the
optimal, hence, it resembles/estimates the contribution function, i.e.,
<span class="math inline">\(g_S(\boldsymbol{x}_S) = \hat{v}(S) \approx
v(S) = E[f(\boldsymbol{x}_\bar{S}, \boldsymbol{x}_S) | \boldsymbol{x}_S
= \boldsymbol{x}_S^*]\)</span>.</p>
<div class="section level3">
<h3 id="separate_code">Code<a class="anchor" aria-label="anchor" href="#separate_code"></a>
</h3>
<p>In this supplementary vignette, we use the same data and explain the
same model type as in the main vignette. We train a simple
<code>xgboost</code> model on the <code>airquality</code> dataset and
demonstrate how to use the <code>shapr</code> and the separate
regression method class to explain the individual predictions.</p>
<div class="section level4">
<h4 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h4>
<p>First, we set up the <code>airquality</code> dataset and train an
<code>xgboost</code> model, whose predictions we want to explain using
the Shapley value explanation framework. We import all packages in the
<code>tidymodels</code> framework in the code chunk below, but we could
have specified them directly, too. In this vignette, we use the
following packages in the <code>tidymodels</code> framework:
<code>parsnip</code>, <code>recipes</code>, <code>workflows</code>,
<code>dials</code>, <code>hardhat</code>, <code>tibble</code>,
<code>rlang</code>, and <code>ggplot2</code>. We include the
<code>package::function()</code> notation throughout this vignette to
indicate which package the functions originate from in the
<code>tidymodels</code> framework.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Either use `library(tidymodels)` or separately specify the libraries indicated above</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org" class="external-link">tidymodels</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Other libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost" class="external-link">xgboost</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://norskregnesentral.github.io/shapr/">shapr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Ensure that shapr's functions are prioritzed, otherwise we need to use the `shapr::`</span></span>
<span><span class="co"># prefix when calling explain(). The `conflicted` package is imported by `tidymodels`.</span></span>
<span><span class="fu">conflicted</span><span class="fu">::</span><span class="fu">conflicts_prefer</span><span class="op">(</span><span class="fu">shapr</span><span class="fu">::</span><span class="va"><a href="../reference/explain.html">explain</a></span>, <span class="fu">shapr</span><span class="fu">::</span><span class="va"><a href="../reference/prepare_data.html">prepare_data</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"airquality"</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html" class="external-link">complete.cases</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month"</span><span class="op">)</span></span>
<span><span class="va">y_var</span> <span class="op">&lt;-</span> <span class="st">"Ozone"</span></span>
<span></span>
<span><span class="va">ind_x_explain</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="fu"><a href="https://rdrr.io/r/base/get.html" class="external-link">get</a></span><span class="op">(</span><span class="va">y_var</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">x_explain</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fitting a basic xgboost model to the training data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># Set seed for reproducibility</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">xgboost</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span>,</span>
<span>  label <span class="op">=</span> <span class="va">y_train</span>,</span>
<span>  nround <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Specifying the phi_0, i.e. the expected prediction without any features</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># List to store all the explanation objects</span></span>
<span><span class="va">explanation_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>To make the rest of the vignette easier to follow, we create some
helper functions that plot and summarize the results of the explanation
methods. This code block is optional to understand and can be
skipped.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot the MSEv criterion scores as horizontal bars and add dashed line of one method's score</span></span>
<span><span class="va">plot_MSEv_scores</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">explanation_list</span>, <span class="va">method_line</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">fig</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html" class="external-link">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">rel</a></span><span class="op">(</span><span class="fl">0.95</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">fig</span> <span class="op">&lt;-</span> <span class="va">fig</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html" class="external-link">scale_x_discrete</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/levels.html" class="external-link">levels</a></span><span class="op">(</span><span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">method_line</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">method_line</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">fig</span> <span class="op">&lt;-</span> <span class="va">fig</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span></span>
<span>      yintercept <span class="op">=</span> <span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">MSEv</span><span class="op">[</span><span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span> <span class="op">==</span> <span class="va">method_line</span><span class="op">]</span>,</span>
<span>      linetype <span class="op">=</span> <span class="st">"dashed"</span>,</span>
<span>      color <span class="op">=</span> <span class="st">"black"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">fig</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Extract the MSEv criterion scores and elapsed times</span></span>
<span><span class="va">print_MSEv_scores_and_time</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span></span>
<span>    <span class="va">explanation_list</span>,</span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">explanation</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">explanation</span><span class="op">$</span><span class="va">MSEv</span><span class="op">$</span><span class="va">MSEv</span><span class="op">$</span><span class="va">MSEv</span>, <span class="va">explanation</span><span class="op">$</span><span class="va">timing</span><span class="op">$</span><span class="va">total_time_secs</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"MSEv"</span>, <span class="st">"Time"</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Extract the k best methods in decreasing order</span></span>
<span><span class="va">get_k_best_methods</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">explanation_list</span>, <span class="va">k_best</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">MSEv</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="va">k_best</span><span class="op">)</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>To establish a baseline against which to compare the regression
methods, we will compare them with the Monte Carlo-based
<code>empirical</code> approach with default hyperparameters. In the
last section, we include all Monte Carlo-based methods implemented in
<code>shapr</code> to make an extensive comparison.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the Shapley value explanations using the empirical method</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">MC_empirical</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="linear-regression-model">Linear regression model<a class="anchor" aria-label="anchor" href="#linear-regression-model"></a>
</h4>
<p>Then we compute the Shapley value explanations using a linear
regression model and the separate regression method class.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>A linear model is often not flexible enough to properly model the
contribution function. Thus, it can produce inaccurate Shapley value
explanations. The figure below shows that the <code>empirical</code>
approach outperforms the linear regression model approach quite
significantly concerning the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation
criterion.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/lm-emp-msev-1.png"></p>
</div>
<div class="section level4">
<h4 id="separate_preproc">Pre-processing<a class="anchor" aria-label="anchor" href="#separate_preproc"></a>
</h4>
<p>This section describes how to pre-process the data before fitting the
separate regression models. We demonstrate this for the linear
regression model, but we can apply this pre-processing to other
regression methods.</p>
<p>The <code>recipe</code> package in the <code>tidymodels</code>
framework contains many functions to pre-process the data before fitting
the model, for example, normalization, interaction, encodings, and
transformations (e.g., log, splines, pls, pca). Click <a href="https://recipes.tidymodels.org/reference/index.html" class="external-link">here</a> to
access a complete list of all available functions. The list also
contains functions for helping us select which features to apply the
functions to, e.g., <code><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">recipes::all_predictors()</a></code>,
<code><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">recipes::all_numeric_predictors()</a></code>, and
<code><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">recipes::all_factor_predictors()</a></code> apply the functions to all
features, only the numerical features, and only the factor features,
respectively. We can also specify the names of the features to which the
functions are applied. However, as the included features change in each
coalition, we need to check that the feature we want to apply the
function to is present in the dataset. We give an example of this
below.</p>
<p>First, we demonstrate how to compute the principal components and use
(up to) the first two components for each separate linear regression
model. We write “up to” as we can only compute a single principal
component for the singleton coalitions, i.e., the feature itself. This
regression model is called principal component regression.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_pcr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_pca.html" class="external-link">step_pca</a></span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric_predictors</a></span><span class="op">(</span><span class="op">)</span>, num_comp <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>Second, we apply a pre-processing step that computes the basis
expansions of the features using natural splines with two degrees of
freedom. This is similar to fitting a generalized additive model.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_ns.html" class="external-link">step_ns</a></span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric_predictors</a></span><span class="op">(</span><span class="op">)</span>, deg_free <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>Finally, we provide an example where we include interactions between
the features <code>Solar.R</code> and <code>Wind</code>, log-transform
<code>Solar.R</code>, convert <code>Wind</code> to be between 0 and 1
and then take the square root, include polynomials of the third degree
for <code>Temp</code>, and apply the Box-Cox transformation to
<code>Month</code>. These transformations are only applied when the
features are present for the different separate models.</p>
<p>Furthermore, we stress that the purpose of this example is to
highlight the framework’s flexibility, NOT that the transformations
below are reasonable.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example function of how to apply step functions from the recipes package to specific features</span></span>
<span><span class="va">regression.recipe_func</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Get the names of the present features</span></span>
<span>  <span class="va">feature_names</span> <span class="op">&lt;-</span> <span class="va">recipe</span><span class="op">$</span><span class="va">var_info</span><span class="op">$</span><span class="va">variable</span><span class="op">[</span><span class="va">recipe</span><span class="op">$</span><span class="va">var_info</span><span class="op">$</span><span class="va">role</span> <span class="op">==</span> <span class="st">"predictor"</span><span class="op">]</span></span>
<span></span>
<span>  <span class="co"># If Solar.R and Wind is present, then we add the interaction between them</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/all.html" class="external-link">all</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_interact.html" class="external-link">step_interact</a></span><span class="op">(</span><span class="va">recipe</span>, terms <span class="op">=</span> <span class="op">~</span> <span class="va">Solar.R</span><span class="op">:</span><span class="va">Wind</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># If Solar.R is present, then log transform it</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Solar.R"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_log.html" class="external-link">step_log</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Solar.R</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># If Wind is present, then scale it to be between 0 and 1 and then sqrt transform it</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Wind"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_sqrt.html" class="external-link">step_sqrt</a></span><span class="op">(</span><span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_range.html" class="external-link">step_range</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Wind</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># If Temp is present, then expand it using orthogonal polynomials of degree 3</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Temp"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_poly.html" class="external-link">step_poly</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Temp</span>, degree <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># If Month is present, then Box-Cox transform it</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Month"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_BoxCox.html" class="external-link">step_BoxCox</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Month</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Finally we normalize all features (not needed as LM does this internally)</span></span>
<span>  <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_normalize.html" class="external-link">step_normalize</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric_predictors</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Compute the Shapley values using the pre-processing steps defined above</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_reicpe_example</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="va">regression.recipe_func</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>We can examine the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation scores,
and we see that the method using natural splines significantly
outperforms the other methods.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/preproc-plot-1.png"></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      MSEv Time</span></span>
<span><span class="co">#&gt; MC_empirical       179.43 2.22</span></span>
<span><span class="co">#&gt; sep_lm             745.21 0.77</span></span>
<span><span class="co">#&gt; sep_pcr            784.91 1.32</span></span>
<span><span class="co">#&gt; sep_splines        165.13 1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example 687.45 1.74</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="other-regression-models">Other regression models<a class="anchor" aria-label="anchor" href="#other-regression-models"></a>
</h4>
<p>In the following example, we use a decision tree model instead of the
simple linear regression model.</p>
<p>The <code>tidymodels</code> framework supports several
implementations of the decision tree model. We use
<code>set_engine("rpart")</code> to specify that we want to use the
implementation in the <code>rpart</code> package, and we use
<code>set_mode("regression")</code> to specify that we are doing
regression. The <code>tidymodels</code> framework uses the default
hyperparameter values set in <code>rpart</code> when we do not specify
them. By searching for “decision tree” in the <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">list of tidymodels</a>,
we see that the default hyperparameter values for the <a href="https://parsnip.tidymodels.org//reference/details_decision_tree_rpart.html" class="external-link"><code>decision_tree_rpart</code></a>
model are <code>tree_depth = 30</code>, <code>min_n = 2</code>, and
<code>cost_complexity = 0.01</code>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Decision tree with specified parameters (stumps)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_stump</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    min_n <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Decision tree with default parameters</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_default</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>We can also set
<code>regression.model = parsnip::decision_tree(tree_depth = 1, min_n = 2, cost_complexity = 0.01) %&gt;% parsnip::set_engine("rpart") %&gt;% parsnip::set_mode("regression")</code>
if we want to use the pipe function (<code>%&gt;%</code>).</p>
<p>We can now compare the two new methods. The decision tree with
default parameters outperforms the linear model approach concerning the
<span class="math inline">\(\operatorname{MSE}_v\)</span> criterion and
is on the same level as the empirical approach. We obtained a worse
method by using stumps, i.e., trees with depth one.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/decision-tree-plot-1.png"></p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      MSEv Time</span></span>
<span><span class="co">#&gt; MC_empirical       179.43 2.22</span></span>
<span><span class="co">#&gt; sep_lm             745.21 0.77</span></span>
<span><span class="co">#&gt; sep_pcr            784.91 1.32</span></span>
<span><span class="co">#&gt; sep_splines        165.13 1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example 687.45 1.74</span></span>
<span><span class="co">#&gt; sep_tree_stump     218.05 1.03</span></span>
<span><span class="co">#&gt; sep_tree_default   177.68 0.89</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="separate_cv">Cross-validation<a class="anchor" aria-label="anchor" href="#separate_cv"></a>
</h4>
<p>Another option is to use cross-validation to tune the
hyperparameters. To do this, we need to specify three things:</p>
<ol style="list-style-type: decimal">
<li>In <code>regression.model</code>, we need to specify which
parameters to tune in the model. We do this by setting the parameter
equal to <code><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">hardhat::tune()</a></code>. For example., if we want to tune
the <code>tree_depth</code> parameter in the
<code><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">parsnip::decision_tree</a></code> model while using default parameters
for the other parameters, then we set
<code>parsnip::decision_tree(tree_depth = hardhat::tune())</code>.</li>
<li>In <code>regression.tune_values</code>, we must provide either a
data.frame (can also be a data.table or tibble) containing the possible
hyperparameter values or a function that takes in the training data for
each combination/coalition and outputs a data.frame containing the
possible hyperparameter values. The latter allows us to use different
hyperparameter values for different coalition sizes, which is essential
if a hyperparameter’s domain changes with the coalition size. For
example, see the example below where we want to tune the
<code>mtry</code> parameter in <code>ranger</code> (random forest). The
column names of <code>regression.tune_values</code> (or the output if it
is a function) must match the tuneable hyperparameters specified in
<code>regression.model</code>. For the example above,
<code>regression.tune_values</code> must be a one-column data.frame with
the column name <code>tree_depth</code>. We can either manually specify
the hyperparameter values or use the <code>dials</code> package, e.g.,
<code>dials::grid_regular(dials::tree_depth(), levels = 5)</code>. Or it
can be a function that outputs a data.frame on the same form.</li>
<li>Specifying the <code>regression.vfold_cv_para</code> parameter is
optional. If used, then <code>regression.vfold_cv_para</code> must be a
list specifying the parameters to send to the cross-validation function
<code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">rsample::vfold_cv()</a></code>. Use <code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">?rsample::vfold_cv</a></code> to
see the default parameters. The names of the objects in the
<code>regression.vfold_cv_para</code> list must match the parameter
names in <code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">rsample::vfold_cv()</a></code>. For example, if we want
5-fold cross-validation, we set
<code>regression.vfold_cv_para = list(v = 5)</code>.</li>
</ol>
<p>First, let us look at some ways to specify
<code>regression.tune_values</code>. Note that <code>dials</code> have
several other grid functions, e.g., <code><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">dials::grid_random()</a></code>
and <code><a href="https://dials.tidymodels.org/reference/grid_max_entropy.html" class="external-link">dials::grid_latin_hypercube()</a></code>.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Possible ways to define the `regression.tune_values` object.</span></span>
<span><span class="co"># function(x) dials::grid_regular(dials::tree_depth(), levels = 4)</span></span>
<span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">tree_depth</a></span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/data.table.html" class="external-link">data.table</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Can also use data.frame or tibble</span></span>
<span></span>
<span><span class="co"># For several features</span></span>
<span><span class="co"># function(x) dials::grid_regular(dials::tree_depth(), dials::cost_complexity(), levels = 3)</span></span>
<span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">tree_depth</a></span><span class="op">(</span><span class="op">)</span>, <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">cost_complexity</a></span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.05</span>, <span class="fl">0.01</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We will now demonstrate how to use cross-validation to fine-tune the
separate decision tree regression method. In the following examples, we
consider two versions. In the first example, we use cross-validation to
tune the <code>tree_depth</code> parameter using the
<code><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">dials::grid_regular()</a></code> function. In the second example, we
tune both the <code>tree_depth</code> and <code>cost_complexity</code>
parameters, but we will manually specify the possible hyperparameter
values this time.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Decision tree with cross validated depth (default values other parameters)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">tree_depth</a></span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Use trees with cross-validation on the depth and cost complexity. Manually set the values.</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_cv_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>We also include one example with a random forest model where the
tunable hyperparameter <code>mtry</code> depends on the coalition size.
Thus, <code>regression.tune_values</code> must be a function that
returns a data.frame where the hyperparameter values for
<code>mtry</code> will change based on the coalition size. If we do not
let <code>regression.tune_values</code> be a function, then
<code>tidymodels</code> will crash for any <code>mtry</code> higher than
1. Furthermore, by setting <code>verbose = 2</code>, we receive messages
about which batch and coalition/combination that <code>shapr</code>
processes and the results of the cross-validation procedure. Note that
the tested hyperparameter value combinations change based on the
coalition size.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Using random forest with default parameters</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">1</span>, <span class="co"># One batch to get printouts in chronological order</span></span>
<span>  verbose <span class="op">=</span> <span class="fl">2</span>, <span class="co"># To get printouts</span></span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Starting 'setup_approach.regression_separate'.</span></span>
<span><span class="co">#&gt; When using `approach = 'regression_separate'` the `explanation$timing$timing_secs` object </span></span>
<span><span class="co">#&gt;  can be missleading as `setup_computation` does not contain the training times of the </span></span>
<span><span class="co">#&gt;  regression models as they are trained on the fly in `compute_vS`. This is to reduce memory </span></span>
<span><span class="co">#&gt;  usage and to improve efficency.</span></span>
<span><span class="co">#&gt; Done with 'setup_approach.regression_separate'.</span></span>
<span><span class="co">#&gt; Working on batch 1 of 1 in `prepare_data.regression_separate()`.</span></span>
<span><span class="co">#&gt; Working on combination with id 2 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 3 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 750  rmse = 34.85  rmse_std_err = 2.99</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 400  rmse = 34.95  rmse_std_err = 3.05</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 50   rmse = 34.99  rmse_std_err = 2.81</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 3 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 3 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 50   rmse = 27.48  rmse_std_err = 1.50</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 750  rmse = 27.52  rmse_std_err = 1.29</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 400  rmse = 27.74  rmse_std_err = 1.30</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 4 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 3 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 400  rmse = 23.60  rmse_std_err = 3.17</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 750  rmse = 23.63  rmse_std_err = 3.17</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 50   rmse = 24.24  rmse_std_err = 3.37</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 5 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 3 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 400  rmse = 33.31  rmse_std_err = 2.81</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 750  rmse = 33.34  rmse_std_err = 2.81</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 50   rmse = 33.41  rmse_std_err = 2.87</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 6 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 6 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 50   rmse = 21.25  rmse_std_err = 2.24</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 400  rmse = 21.69  rmse_std_err = 2.38</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 750  rmse = 21.81  rmse_std_err = 2.40</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 400  rmse = 22.38  rmse_std_err = 2.11</span></span>
<span><span class="co">#&gt; #5: mtry = 2  trees = 750  rmse = 22.68  rmse_std_err = 2.04</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 50   rmse = 22.91  rmse_std_err = 1.97</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 7 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 6 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 2  trees = 50   rmse = 22.18  rmse_std_err = 2.93</span></span>
<span><span class="co">#&gt; #2: mtry = 2  trees = 400  rmse = 22.28  rmse_std_err = 2.74</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 750  rmse = 22.31  rmse_std_err = 2.90</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 750  rmse = 22.35  rmse_std_err = 2.76</span></span>
<span><span class="co">#&gt; #5: mtry = 1  trees = 400  rmse = 22.40  rmse_std_err = 2.80</span></span>
<span><span class="co">#&gt; #6: mtry = 1  trees = 50   rmse = 22.62  rmse_std_err = 2.71</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 8 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 6 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 50   rmse = 29.35  rmse_std_err = 2.17</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 400  rmse = 29.45  rmse_std_err = 2.37</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 750  rmse = 29.57  rmse_std_err = 2.32</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 750  rmse = 30.43  rmse_std_err = 2.21</span></span>
<span><span class="co">#&gt; #5: mtry = 2  trees = 400  rmse = 30.49  rmse_std_err = 2.18</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 50   rmse = 30.51  rmse_std_err = 2.19</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 9 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 6 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 750  rmse = 18.61  rmse_std_err = 1.56</span></span>
<span><span class="co">#&gt; #2: mtry = 2  trees = 400  rmse = 18.63  rmse_std_err = 1.56</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 400  rmse = 18.80  rmse_std_err = 1.55</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 750  rmse = 19.00  rmse_std_err = 1.70</span></span>
<span><span class="co">#&gt; #5: mtry = 1  trees = 50   rmse = 19.02  rmse_std_err = 1.86</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 50   rmse = 19.50  rmse_std_err = 1.72</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 10 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 6 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 400  rmse = 23.61  rmse_std_err = 1.61</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 50   rmse = 23.72  rmse_std_err = 1.49</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 750  rmse = 23.79  rmse_std_err = 1.64</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 750  rmse = 23.86  rmse_std_err = 0.83</span></span>
<span><span class="co">#&gt; #5: mtry = 2  trees = 400  rmse = 23.91  rmse_std_err = 0.80</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 50   rmse = 24.74  rmse_std_err = 0.68</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 11 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 6 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 400  rmse = 22.99  rmse_std_err = 4.29</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 750  rmse = 23.08  rmse_std_err = 4.33</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 50   rmse = 23.16  rmse_std_err = 4.28</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 50   rmse = 23.80  rmse_std_err = 3.70</span></span>
<span><span class="co">#&gt; #5: mtry = 2  trees = 400  rmse = 23.85  rmse_std_err = 3.72</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 750  rmse = 24.07  rmse_std_err = 3.79</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 12 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 9 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 50   rmse = 16.86  rmse_std_err = 2.19</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 400  rmse = 16.90  rmse_std_err = 1.83</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 750  rmse = 16.91  rmse_std_err = 1.93</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 50   rmse = 17.47  rmse_std_err = 1.47</span></span>
<span><span class="co">#&gt; #5: mtry = 2  trees = 750  rmse = 17.53  rmse_std_err = 1.77</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 400  rmse = 17.82  rmse_std_err = 1.67</span></span>
<span><span class="co">#&gt; #7: mtry = 3  trees = 50   rmse = 18.03  rmse_std_err = 1.84</span></span>
<span><span class="co">#&gt; #8: mtry = 3  trees = 750  rmse = 18.47  rmse_std_err = 1.91</span></span>
<span><span class="co">#&gt; #9: mtry = 3  trees = 400  rmse = 18.49  rmse_std_err = 1.82</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 13 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 9 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 50   rmse = 19.27  rmse_std_err = 2.13</span></span>
<span><span class="co">#&gt; #2: mtry = 2  trees = 750  rmse = 19.80  rmse_std_err = 1.59</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 750  rmse = 20.03  rmse_std_err = 1.95</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 400  rmse = 20.21  rmse_std_err = 1.59</span></span>
<span><span class="co">#&gt; #5: mtry = 3  trees = 50   rmse = 20.42  rmse_std_err = 1.64</span></span>
<span><span class="co">#&gt; #6: mtry = 1  trees = 400  rmse = 20.49  rmse_std_err = 2.13</span></span>
<span><span class="co">#&gt; #7: mtry = 2  trees = 50   rmse = 20.59  rmse_std_err = 1.26</span></span>
<span><span class="co">#&gt; #8: mtry = 3  trees = 400  rmse = 20.61  rmse_std_err = 1.68</span></span>
<span><span class="co">#&gt; #9: mtry = 3  trees = 750  rmse = 20.85  rmse_std_err = 1.74</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 14 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 9 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 750  rmse = 21.96  rmse_std_err = 3.12</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 400  rmse = 22.36  rmse_std_err = 2.96</span></span>
<span><span class="co">#&gt; #3: mtry = 1  trees = 50   rmse = 22.53  rmse_std_err = 3.01</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 750  rmse = 22.59  rmse_std_err = 2.53</span></span>
<span><span class="co">#&gt; #5: mtry = 2  trees = 400  rmse = 22.76  rmse_std_err = 2.39</span></span>
<span><span class="co">#&gt; #6: mtry = 2  trees = 50   rmse = 22.80  rmse_std_err = 2.41</span></span>
<span><span class="co">#&gt; #7: mtry = 3  trees = 400  rmse = 23.19  rmse_std_err = 2.26</span></span>
<span><span class="co">#&gt; #8: mtry = 3  trees = 750  rmse = 23.42  rmse_std_err = 2.07</span></span>
<span><span class="co">#&gt; #9: mtry = 3  trees = 50   rmse = 23.69  rmse_std_err = 2.22</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Working on combination with id 15 of 16.</span></span>
<span><span class="co">#&gt; Results of the 5-fold cross validation (top 9 best configurations):</span></span>
<span><span class="co">#&gt; #1: mtry = 1  trees = 400  rmse = 18.33  rmse_std_err = 2.07</span></span>
<span><span class="co">#&gt; #2: mtry = 1  trees = 750  rmse = 18.59  rmse_std_err = 2.25</span></span>
<span><span class="co">#&gt; #3: mtry = 2  trees = 750  rmse = 18.78  rmse_std_err = 1.59</span></span>
<span><span class="co">#&gt; #4: mtry = 2  trees = 400  rmse = 18.81  rmse_std_err = 1.58</span></span>
<span><span class="co">#&gt; #5: mtry = 3  trees = 50   rmse = 18.93  rmse_std_err = 1.53</span></span>
<span><span class="co">#&gt; #6: mtry = 3  trees = 400  rmse = 19.11  rmse_std_err = 1.57</span></span>
<span><span class="co">#&gt; #7: mtry = 3  trees = 750  rmse = 19.17  rmse_std_err = 1.71</span></span>
<span><span class="co">#&gt; #8: mtry = 2  trees = 50   rmse = 19.18  rmse_std_err = 1.33</span></span>
<span><span class="co">#&gt; #9: mtry = 1  trees = 50   rmse = 19.94  rmse_std_err = 2.02</span></span>
<span><span class="co">#&gt; </span></span></code></pre></div>
<p>We can look at the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation
criterion, and we see that cross-validation improves both the decision
tree and the random forest methods. The two cross-validated decision
tree methods are comparable, but the second version outperforms the
first version by a small margin. This comparison is somewhat unfair for
the <code>empirical</code> approach, which also has hyperparameters we
could potentially tune. However, <code>shapr</code> does not currently
provide a function to do this automatically. In the figure below, we
include a vertical line at the <span class="math inline">\(\operatorname{MSE}_v\)</span> score of the
<code>empirical</code> method for easier comparison.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/dt-cv-plot-1.png"></p>
<p>Furthermore, we must consider that cross-validation drastically
increases the elapsed time (seconds) and determine if the increased
precision is worth the extra computational time. We also see that the
complex random forest method performs significantly worse than the
simple decision tree method. This result indicates that even though we
do hyperparameter tuning, we still overfit the data.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical       179.43  2.22</span></span>
<span><span class="co">#&gt; sep_lm             745.21  0.77</span></span>
<span><span class="co">#&gt; sep_pcr            784.91  1.32</span></span>
<span><span class="co">#&gt; sep_splines        165.13  1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example 687.45  1.74</span></span>
<span><span class="co">#&gt; sep_tree_stump     218.05  1.03</span></span>
<span><span class="co">#&gt; sep_tree_default   177.68  0.89</span></span>
<span><span class="co">#&gt; sep_tree_cv        169.96 17.31</span></span>
<span><span class="co">#&gt; sep_tree_cv_2      166.17 35.01</span></span>
<span><span class="co">#&gt; sep_rf             210.99  1.58</span></span>
<span><span class="co">#&gt; sep_rf_cv          212.88 38.41</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="separate_parallelization">Parallelization<a class="anchor" aria-label="anchor" href="#separate_parallelization"></a>
</h4>
<p>The <code>future</code> package can train the separate regression
models in parallel. More specifically, we parallelize both the training
step (when we fit the models) and the prediction step (when we compute
<span class="math inline">\(v(S)\)</span>). In the main vignette, we
also explain how to enable progress bars.</p>
<p>In the code chunk below, we consider four regression-based methods.
The first method uses <code>xgboost</code> models with default
hyperparameter values, while the remaining three use cross-validation to
tune the number of trees. The second and third methods specify the same
potential hyperparameter values, but we run the former sequentially
while the latter is run in parallel to speed up the computations. The
fourth model is run in parallel but also tunes the depth of the trees
and not only the number of trees.</p>
<p>A small side note: If we set <code>verbose = 2</code>, we can see
which <code>tree</code> value <code>shapr</code> chooses for each
coalition. We would then see that the values 25, 50, 100, and 500 are
never chosen. Thus, we can remove these values without influencing the
result and instead do a finer grid search among the lower values. We do
this in the fourth method.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Regular xgboost with default parameters</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Cross validate the number of trees</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span></span>
<span>    <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">15</span>, <span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Cross validate the number of trees in parallel on two threads</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/multisession.html" class="external-link">multisession</a></span>, workers <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost_cv_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span></span>
<span>    <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">15</span>, <span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Use a finer grid of low values for `trees` and also tune `tree_depth`</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/multisession.html" class="external-link">multisession</a></span>, workers <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="co"># Change to 4 threads due to more complex CV</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost_cv_2_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">10</span>, <span class="fl">12</span>, <span class="fl">15</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/sequential.html" class="external-link">sequential</a></span><span class="op">)</span> <span class="co"># To return to non-parallel computation</span></span></code></pre></div>
<p>Looking at the elapsed time, we see that the parallel version with
two workers is faster than the sequential version. Note that the elapsed
time of the parallel version is not reduced by a factor of two as the
creation of the parallel processes creates some additional overhead,
which is significant in this small example. However, parallelization
will yield considerable relative time improvements in more complex
situations. E.g., in settings with (more) training observations with
more features (i.e., more coalitions to compute) and situations with
more time-consuming cross-validation (i.e., more folds, hyperparameters
to tune, or hyperparameter values to consider). Furthermore, we see that
conducting the cross-validation has lowered the <span class="math inline">\(\operatorname{MSE}_v\)</span>criterion
drastically. Finally, note that we obtain the same value whether we run
the cross-validation in parallel or sequentially.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  2.22</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.77</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  1.32</span></span>
<span><span class="co">#&gt; sep_splines          165.13  1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.74</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.03</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.89</span></span>
<span><span class="co">#&gt; sep_tree_cv          169.96 17.31</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        166.17 35.01</span></span>
<span><span class="co">#&gt; sep_rf               210.99  1.58</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.88 38.41</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.99</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       164.69 20.72</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   164.69 17.53</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 146.51 21.94</span></span></code></pre></div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="surrogate">The surrogate regression method class<a class="anchor" aria-label="anchor" href="#surrogate"></a>
</h2>
<p>Since the <code>regression_separate</code> methods train a new
regression model <span class="math inline">\(g_S(\boldsymbol{x}_S)\)</span> for each coalition
<span class="math inline">\(S \subseteq \{1,2,\dots,M\}\)</span>, a
total of <span class="math inline">\(2^M-2\)</span> models has to be
trained, which can be time-consuming for slowly fitted models. The minus
two corresponds to the empty and grand coalitions.</p>
<p>The <code>regression_surrogate</code> method class builds on the
ideas from the <code>regression_separate</code> class, but instead of
fitting a new regression model for each coalition, we train a single
regression model <span class="math inline">\(g(\tilde{\boldsymbol{x}}_S)\)</span> for all
coalitions <span class="math inline">\(S \subseteq
\{1,2,\dots,M\}\)</span> (except the empty and grand coalitions), where
<span class="math inline">\(\tilde{\boldsymbol{x}}_S\)</span> is an
augmented version of <span class="math inline">\(\boldsymbol{x}_S\)</span>. See Section 3.6.1 in
<span class="citation">Olsen et al. (2024)</span> for more details and
examples.</p>
<p>We can also apply all the examples above for the separate regression
method class to the surrogate regression method class.</p>
<div class="section level3">
<h3 id="surrogate_code">Code<a class="anchor" aria-label="anchor" href="#surrogate_code"></a>
</h3>
<p>We demonstrate the surrogate method class using several regression
models below. More specifically, we use linear regression, random forest
(with and without (some) cross-validation), and <code>xgboost</code>
(with and without (some) cross-validation).</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the Shapley value explanations using a surrogate linear regression model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using xgboost with default parameters as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using xgboost with parameters tuned by cross-validation as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span>, <span class="fl">25</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using random forest with default parameters as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span></span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x_explain</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    levels <span class="op">=</span> <span class="fl">6</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<div class="section level4">
<h4 id="surrogate_parallelization">Parallelization<a class="anchor" aria-label="anchor" href="#surrogate_parallelization"></a>
</h4>
<p>The code chunk below demonstrates how to run the surrogate regression
method class in parallel using the <code>future</code> package. The
setup procedure is identical to the one we specified for <a href="#separate_parallelization">separate regression method class</a>.
The training step of the surrogate regression model can be run in
parallel if we tune some of its hyperparameters. We parallelize the
cross-validation procedure in the training step; hence, we apply no
parallelization in the training step of a surrogate model with specified
hyperparameters. Furthermore, we parallelize the prediction step (when
we compute <span class="math inline">\(v(S)\)</span>) in the same way as
for the separate regression method class. Note that parallelization will
introduce some overhead, which can cause it to be slower than running
the code sequentially for smaller problems.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Cross validate the number of trees in parallel on four threads</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/multisession.html" class="external-link">multisession</a></span>, workers <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span></span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x_explain</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    levels <span class="op">=</span> <span class="fl">6</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/sequential.html" class="external-link">sequential</a></span><span class="op">)</span> <span class="co"># To return to non-parallel computation</span></span>
<span></span>
<span><span class="co"># Check that we get identical Shapley value explanations</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span></span>
<span>  <span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv</span><span class="op">$</span><span class="va">shapley_values</span>,</span>
<span>  <span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv_par</span><span class="op">$</span><span class="va">shapley_values</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
<p>By looking at the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation criterion
and the elapsed time, we see that the surrogate methods (except the
linear regression model) outperform <code>empirical</code> but are not
on the same level as the best separate regression methods. Furthermore,
parallelization (4 cores) decreased the elapsed time while obtaining the
same <span class="math inline">\(\operatorname{MSE}_v\)</span> score.
The identical scores mean that the separate models are identical and
independent of whether they were run sequentially or in parallel.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  2.22</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.77</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  1.32</span></span>
<span><span class="co">#&gt; sep_splines          165.13  1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.74</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.03</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.89</span></span>
<span><span class="co">#&gt; sep_tree_cv          169.96 17.31</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        166.17 35.01</span></span>
<span><span class="co">#&gt; sep_rf               210.99  1.58</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.88 38.41</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.99</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       164.69 20.72</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   164.69 17.53</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 146.51 21.94</span></span>
<span><span class="co">#&gt; sur_lm               649.61  0.31</span></span>
<span><span class="co">#&gt; sur_xgboost          169.92  0.26</span></span>
<span><span class="co">#&gt; sur_xgboost_cv       169.87  2.37</span></span>
<span><span class="co">#&gt; sur_rf               195.10  0.52</span></span>
<span><span class="co">#&gt; sur_rf_cv            171.84 30.55</span></span>
<span><span class="co">#&gt; sur_rf_cv_par        171.84 33.24</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods.</span></span>
<span><span class="co"># Include vertical line corresponding to the MSEv of the empirical method.</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/surrogate-plot-1.png"></p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="new">Add new regression methods<a class="anchor" aria-label="anchor" href="#new"></a>
</h2>
<p>Even though the <code>tidymodels</code> framework contains many <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">models</a>, we might
want to add additional methods. In the following section, we demonstrate
how to add the projection pursuit regression (PPR) model as a new method
that can be used by <code>shapr</code> to compute the Shapley value
explanations, both as a separate and surrogate method.</p>
<p>We use the <code><a href="https://rdrr.io/r/stats/ppr.html" class="external-link">ppr()</a></code> implementation in the
<code>stats</code> package to fit the PPR model. The model has several
hyperparameters that can be tuned, but the main hyperparameter is the
number of terms <code>nterms</code>. The following is based on the <a href="https://www.tidymodels.org/learn/develop/models/" class="external-link"><code>tidymodels</code>
guide</a> on adding new regression models. We refer to that guide for
more details and explanations of the code below.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Step 1: register the model, modes, and arguments</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_new_model</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"ppr_reg"</span><span class="op">)</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_model_mode</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"ppr_reg"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_model_engine</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"ppr_reg"</span>, mode <span class="op">=</span> <span class="st">"regression"</span>, eng <span class="op">=</span> <span class="st">"ppr"</span><span class="op">)</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_dependency</a></span><span class="op">(</span><span class="st">"ppr_reg"</span>, eng <span class="op">=</span> <span class="st">"ppr"</span>, pkg <span class="op">=</span> <span class="st">"stats"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># If your function has several parameters, then we add one of these functions for each parameter</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_model_arg</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  original <span class="op">=</span> <span class="st">"nterms"</span>, <span class="co"># The original parameter name used in stats::ppr</span></span>
<span>  parsnip <span class="op">=</span> <span class="st">"num_terms"</span>, <span class="co"># Change parameter name to match tidymodels' name convention</span></span>
<span>  func <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>pkg <span class="op">=</span> <span class="st">"dials"</span>, fun <span class="op">=</span> <span class="st">"num_terms"</span><span class="op">)</span>, <span class="co"># list(pkg = "stats", fun = "ppr"),</span></span>
<span>  has_submodel <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 2: create the model function</span></span>
<span><span class="va">ppr_reg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mode</span> <span class="op">=</span> <span class="st">"regression"</span>, <span class="va">engine</span> <span class="op">=</span> <span class="st">"ppr"</span>, <span class="va">num_terms</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Check for correct mode</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">mode</span> <span class="op">!=</span> <span class="st">"regression"</span><span class="op">)</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/abort.html" class="external-link">abort</a></span><span class="op">(</span><span class="st">"`mode` should be 'regression'"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Check for correct engine</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">engine</span> <span class="op">!=</span> <span class="st">"ppr"</span><span class="op">)</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/abort.html" class="external-link">abort</a></span><span class="op">(</span><span class="st">"`engine` should be 'ppr'"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Capture the arguments in quosures</span></span>
<span>  <span class="va">args</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/enquo.html" class="external-link">enquo</a></span><span class="op">(</span><span class="va">num_terms</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Save some empty slots for future parts of the specification</span></span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">new_model_spec</a></span><span class="op">(</span></span>
<span>    <span class="st">"ppr_reg"</span>,</span>
<span>    args <span class="op">=</span> <span class="va">args</span>,</span>
<span>    eng_args <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    mode <span class="op">=</span> <span class="va">mode</span>,</span>
<span>    method <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    engine <span class="op">=</span> <span class="va">engine</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Step 3: add a fit module</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_fit</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>  value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    interface <span class="op">=</span> <span class="st">"formula"</span>,</span>
<span>    protect <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"formula"</span>, <span class="st">"data"</span>, <span class="st">"weights"</span><span class="op">)</span>,</span>
<span>    func <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>pkg <span class="op">=</span> <span class="st">"stats"</span>, fun <span class="op">=</span> <span class="st">"ppr"</span><span class="op">)</span>,</span>
<span>    defaults <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_encoding</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>  options <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    predictor_indicators <span class="op">=</span> <span class="st">"traditional"</span>,</span>
<span>    compute_intercept <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    remove_intercept <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    allow_sparse_x <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 4: add modules for prediction</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_pred</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"numeric"</span>,</span>
<span>  value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    pre <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    post <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    func <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="st">"predict"</span><span class="op">)</span>,</span>
<span>    args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      object <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/substitute.html" class="external-link">quote</a></span><span class="op">(</span><span class="va">object</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span>,</span>
<span>      newdata <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/substitute.html" class="external-link">quote</a></span><span class="op">(</span><span class="va">new_data</span><span class="op">)</span>,</span>
<span>      type <span class="op">=</span> <span class="st">"numeric"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 5: add tuning function (used by tune::tune_grid())</span></span>
<span><span class="va">tunable.ppr_reg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>    name <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"num_terms"</span><span class="op">)</span>,</span>
<span>    call_info <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>pkg <span class="op">=</span> <span class="cn">NULL</span>, fun <span class="op">=</span> <span class="st">"num_terms"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    source <span class="op">=</span> <span class="st">"model_spec"</span>,</span>
<span>    component <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>    component_id <span class="op">=</span> <span class="st">"main"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Step 6: add updating function (used by tune::finalize_workflow())</span></span>
<span><span class="va">update.ppr_reg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">object</span>, <span class="va">parameters</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">num_terms</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/is_installed.html" class="external-link">check_installed</a></span><span class="op">(</span><span class="st">"parsnip"</span><span class="op">)</span></span>
<span>  <span class="va">eng_args</span> <span class="op">&lt;-</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">update_engine_parameters</a></span><span class="op">(</span><span class="va">object</span><span class="op">$</span><span class="va">eng_args</span>, fresh <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span>  <span class="va">args</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/enquo.html" class="external-link">enquo</a></span><span class="op">(</span><span class="va">num_terms</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">args</span> <span class="op">&lt;-</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">update_main_parameters</a></span><span class="op">(</span><span class="va">args</span>, <span class="va">parameters</span><span class="op">)</span></span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">new_model_spec</a></span><span class="op">(</span></span>
<span>    <span class="st">"ppr_reg"</span>,</span>
<span>    args <span class="op">=</span> <span class="va">args</span>,</span>
<span>    eng_args <span class="op">=</span> <span class="va">eng_args</span>,</span>
<span>    mode <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">mode</span>,</span>
<span>    method <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    engine <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">engine</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>We can now use the PPR model to compute the Shapley value
explanations. We can use it as a separate and surrogate regression
method, and we can either set the number of terms <code>num_terms</code>
to a specific value or use cross-validation to tune the hyperparameter.
We do all four combinations below.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># PPR separate with specified number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_ppr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># PPR separate with cross-validated number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_ppr_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/num_comp.html" class="external-link">num_terms</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># PPR surrogate with specified number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_ppr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># PPR surrogate with cross-validated number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_ppr_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/num_comp.html" class="external-link">num_terms</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span></code></pre></div>
<p>We can then compare the <span class="math inline">\(\operatorname{MSE}_v\)</span> and some of the
Shapley value explanations. We see that conducting cross-validation
improves the evaluation criterion, but also increase the running
time.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  2.22</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.77</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  1.32</span></span>
<span><span class="co">#&gt; sep_splines          165.13  1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.74</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.03</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.89</span></span>
<span><span class="co">#&gt; sep_tree_cv          169.96 17.31</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        166.17 35.01</span></span>
<span><span class="co">#&gt; sep_rf               210.99  1.58</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.88 38.41</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.99</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       164.69 20.72</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   164.69 17.53</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 146.51 21.94</span></span>
<span><span class="co">#&gt; sur_lm               649.61  0.31</span></span>
<span><span class="co">#&gt; sur_xgboost          169.92  0.26</span></span>
<span><span class="co">#&gt; sur_xgboost_cv       169.87  2.37</span></span>
<span><span class="co">#&gt; sur_rf               195.10  0.52</span></span>
<span><span class="co">#&gt; sur_rf_cv            171.84 30.55</span></span>
<span><span class="co">#&gt; sur_rf_cv_par        171.84 33.24</span></span>
<span><span class="co">#&gt; sep_ppr              327.23  1.41</span></span>
<span><span class="co">#&gt; sep_ppr_cv           269.74 15.46</span></span>
<span><span class="co">#&gt; sur_ppr              395.42  0.29</span></span>
<span><span class="co">#&gt; sur_ppr_cv           415.62  1.86</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/ppr-plot-1.png"></p>
</div>
<div class="section level2">
<h2 id="summary">Summary figures<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<p>In this section, we compute the Shapley value explanations for the
Monte Carlo-based methods in the <code>shapr</code> package and compare
the results with all the regression-based methods above. The purpose of
this vignette is to demonstrate the rich possibilities that the
regression paradigm and the <code>tidymodels</code> framework adds to
the <code>shapr</code> package.</p>
<p>In the code chunk below, we compute the Shapley value explanations
using the different Monte Carlo-based methods.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list_MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the independence method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_independence</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"independence"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Copy the Shapley value explanations for the empirical method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_empirical</span> <span class="op">&lt;-</span> <span class="va">explanation_list</span><span class="op">$</span><span class="va">MC_empirical</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the gaussian method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_gaussian</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"gaussian"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the copula method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_copula</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"copula"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the ctree method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_ctree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"ctree"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the vaeac method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_vaeac</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"vaeac"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  vaeac.epochs <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Combine the two explanations lists</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">MC_empirical</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="va">explanation_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">explanation_list_MC</span>, <span class="va">explanation_list</span><span class="op">)</span></span></code></pre></div>
<p>We then compare the compare the regression and Monte Carlo-based
methods by plotting the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation
criterion. We continue with include a vertical line corresponding to the
<span class="math inline">\(\operatorname{MSE}_v\)</span> of the
<code>MC_empirical</code> method to make the comparison easier.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_independence      206.92  0.50</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  2.22</span></span>
<span><span class="co">#&gt; MC_gaussian          245.19  0.49</span></span>
<span><span class="co">#&gt; MC_copula            247.29  0.46</span></span>
<span><span class="co">#&gt; MC_ctree             191.82  1.72</span></span>
<span><span class="co">#&gt; MC_vaeac             141.88 72.61</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.77</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  1.32</span></span>
<span><span class="co">#&gt; sep_splines          165.13  1.09</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.74</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.03</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.89</span></span>
<span><span class="co">#&gt; sep_tree_cv          169.96 17.31</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        166.17 35.01</span></span>
<span><span class="co">#&gt; sep_rf               210.99  1.58</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.88 38.41</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.99</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       164.69 20.72</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   164.69 17.53</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 146.51 21.94</span></span>
<span><span class="co">#&gt; sur_lm               649.61  0.31</span></span>
<span><span class="co">#&gt; sur_xgboost          169.92  0.26</span></span>
<span><span class="co">#&gt; sur_xgboost_cv       169.87  2.37</span></span>
<span><span class="co">#&gt; sur_rf               195.10  0.52</span></span>
<span><span class="co">#&gt; sur_rf_cv            171.84 30.55</span></span>
<span><span class="co">#&gt; sur_rf_cv_par        171.84 33.24</span></span>
<span><span class="co">#&gt; sep_ppr              327.23  1.41</span></span>
<span><span class="co">#&gt; sep_ppr_cv           269.74 15.46</span></span>
<span><span class="co">#&gt; sur_ppr              395.42  0.29</span></span>
<span><span class="co">#&gt; sur_ppr_cv           415.62  1.86</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="co"># Include vertical line corresponding to the MSEv of the MC_empirical method</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/MSEv-sum-1.png"></p>
<p>The <code>vaeac</code> approach is the best-performing method
according to the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation
criterion, while the <code>sep_xgboost_cv_2_par</code> is the
best-performing regression-based method. However, we should note that
the <code>vaeac</code> method is much slower and that the difference
between the <span class="math inline">\(\operatorname{MSE}_v\)</span>
values is minuscule and inside the confidence intervals.</p>
<p>We can also order the methods to more easily look at the order of the
methods according to the <span class="math inline">\(\operatorname{MSE}_v\)</span> criterion.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">order</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list</span>, k <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/MSEv-sum-2-1.png"></p>
<p>We can also examine the different Shapley value explanations for the
first six explicands (two at a time), and we still sort the methods from
best to worst. Most methods agree in the general directions, especially
for the most important features (the features with the largest absolute
Shapley values), but there are some differences for the less important
features. These tendencies/discrepancies are often more visible for the
methods with poor/larger <span class="math inline">\(\operatorname{MSE}_v\)</span> values.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/SV-sum-1.png"></p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/SV-sum-2.png"></p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">6</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/SV-sum-3.png"></p>
<p>Here, we focus on the five best methods (and
<code>MC_empricial</code>) to make it easier to analyze the individual
Shapley value explanations, and we see a quite strong agreement between
the different methods.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract the 5 best methods (and empirical)</span></span>
<span><span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="st">"MC_empirical"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">best_methods</span><span class="op">)</span> <span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">best_methods</span>, <span class="st">"MC_empirical"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">best_methods</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/SV-sum-2-1.png"></p>
</div>
<div class="section level2">
<h2 id="mixed">Mixed data<a class="anchor" aria-label="anchor" href="#mixed"></a>
</h2>
<p>In this section, we replicate and extend the mixed data example from
the main vignette by demonstrating the separate and surrogate regression
methods. Of the Monte Carlo-based methods, only the
<code>independence</code> (not recommended), <code>ctree</code>, and
<code>vaeac</code> methods support mixed data. We can divide the
regression models into two groups based on whether the model can handle
categorical features by default or if we need to apply pre-processing of
the categorical features. By pre-processing, we mean that we need to
convert the categorical features into numerical values using, for
example, dummy features. We demonstrate this below using the
<code>regression.recipe_func</code> function.</p>
<div class="section level3">
<h3 id="mixed-data-setup">Mixed data: setup<a class="anchor" aria-label="anchor" href="#mixed-data-setup"></a>
</h3>
<p>First, we copy the setup from the main vignette.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># convert the month variable to a factor</span></span>
<span><span class="va">data_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">[</span>, <span class="va">Month_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">Month</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">data_train_cat</span> <span class="op">&lt;-</span> <span class="va">data_cat</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span><span class="va">data_explain_cat</span> <span class="op">&lt;-</span> <span class="va">data_cat</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x_var_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month_factor"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_train_cat</span> <span class="op">&lt;-</span> <span class="va">data_train_cat</span><span class="op">[</span>, <span class="va">..x_var_cat</span><span class="op">]</span></span>
<span><span class="va">x_explain_cat</span> <span class="op">&lt;-</span> <span class="va">data_explain_cat</span><span class="op">[</span>, <span class="va">..x_var_cat</span><span class="op">]</span></span>
<span></span>
<span><span class="va">p0_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fitting an lm model here as xgboost does not handle categorical features directly</span></span>
<span><span class="va">formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">y_var</span>, <span class="st">" ~ "</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">x_var_cat</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">formula</span>, <span class="va">data_train_cat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We could also consider other models such as random forest which supports mixed data</span></span>
<span><span class="co"># model_cat &lt;- ranger(formula, data_train_cat)</span></span>
<span></span>
<span><span class="co"># List to store the explanations for this mixed data setup</span></span>
<span><span class="va">explanation_list_mixed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="mixed-data-monte-carlo-based-methods">Mixed data: Monte Carlo-based methods<a class="anchor" aria-label="anchor" href="#mixed-data-monte-carlo-based-methods"></a>
</h3>
<p>Second, we compute the explanations using the Monte Carlo-based
methods.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">MC_independence</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"independence"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">MC_ctree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"ctree"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">MC_vaeac</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"vaeac"</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="mixed-data-separate-regression-methods">Mixed data: separate regression methods<a class="anchor" aria-label="anchor" href="#mixed-data-separate-regression-methods"></a>
</h3>
<p>Third, we compute the Shapley value explanations using separate
regression methods. We use many of the same regression models as we did
above for the continuous data examples.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Standard linear regression</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Linear regression where we have added splines to the numerical features</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_ns</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span>, deg_free <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Decision tree with default parameters</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_tree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use trees with cross-validation on the depth and cost complexity. Manually set the values.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Random forest with default hyperparameters. Do NOT need to use dummy features.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Random forest with cross validated hyperparameters.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Xgboost with default hyperparameters, but we have to dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Xgboost with cross validated hyperparameters and we dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span>, <span class="fl">25</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="mixed-data-surrogate-regression-methods">Mixed data: surrogate regression methods<a class="anchor" aria-label="anchor" href="#mixed-data-surrogate-regression-methods"></a>
</h3>
<p>Fourth, we compute the Shapley value explanations using surrogate
regression methods. We use the same regression models as we did above
for separate regression method class.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Standard linear regression</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Linear regression where we have added splines to the numerical features</span></span>
<span><span class="co"># NOTE, that we remove the augmented mask variables to avoid a rank-deficient fit</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_ns</span><span class="op">(</span><span class="va">recipe</span>, <span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">starts_with</span><span class="op">(</span><span class="st">"mask_"</span><span class="op">)</span>, deg_free <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Decision tree with default parameters</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_tree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use trees with cross-validation on the depth and cost complexity. Manually set the values.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Random forest with default hyperparameters. Do NOT need to use dummy features.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Random forest with cross validated hyperparameters.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>mtry <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">250</span>, <span class="fl">500</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Xgboost with default hyperparameters, but we have to dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Xgboost with cross validated hyperparameters and we dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span>, <span class="fl">25</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="summary_mixed">Mixed data: summary<a class="anchor" aria-label="anchor" href="#summary_mixed"></a>
</h3>
<p>Fifth, and finally, we compare the results. The surrogate random
forest model performs well and outperforms the cross-validated version,
but note the wide confidence interval. We see that several of the
regression-based methods outperform the Monte Carlo-based methods. More
specifically, three separate regression methods and three surrogate
regression methods.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">)</span></span>
<span><span class="co">#&gt;                   MSEv   Time</span></span>
<span><span class="co">#&gt; MC_independence 641.82   0.69</span></span>
<span><span class="co">#&gt; MC_ctree        554.50   2.36</span></span>
<span><span class="co">#&gt; MC_vaeac        629.43 147.26</span></span>
<span><span class="co">#&gt; sep_lm          550.06   1.53</span></span>
<span><span class="co">#&gt; sep_splines     541.36   1.80</span></span>
<span><span class="co">#&gt; sep_tree        753.84   0.84</span></span>
<span><span class="co">#&gt; sep_tree_cv     756.27  41.75</span></span>
<span><span class="co">#&gt; sep_rf          521.79   1.10</span></span>
<span><span class="co">#&gt; sep_rf_cv       609.58  51.42</span></span>
<span><span class="co">#&gt; sep_xgboost     792.17   1.13</span></span>
<span><span class="co">#&gt; sep_xgboost_cv  595.98  26.29</span></span>
<span><span class="co">#&gt; sur_lm          610.61   0.51</span></span>
<span><span class="co">#&gt; sur_splines     596.86   0.55</span></span>
<span><span class="co">#&gt; sur_tree        677.04   0.38</span></span>
<span><span class="co">#&gt; sur_tree_cv     789.37   3.34</span></span>
<span><span class="co">#&gt; sur_rf          414.15   0.55</span></span>
<span><span class="co">#&gt; sur_rf_cv       533.06  15.50</span></span>
<span><span class="co">#&gt; sur_xgboost     606.92   0.40</span></span>
<span><span class="co">#&gt; sur_xgboost_cv  429.06   3.05</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="co"># Include vertical line corresponding to the MSEv of the empirical method.</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list_mixed</span>, method_line <span class="op">=</span> <span class="st">"MC_ctree"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/mixed-plot-1.png"></p>
<p>The best-performing methods are the surrogate random forest and
xgboost with cross-validation methods. The Monte Carlo-based methods
perform worse, with <code>ctree</code> being the best, with a
seventh-place overall ranking.</p>
<p>We can also order the methods to more easily look at the order of the
methods according to the <span class="math inline">\(\operatorname{MSE}_v\)</span> criterion.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">order</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list_mixed</span>, k <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, method_line <span class="op">=</span> <span class="st">"MC_ctree"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/mixed-plot-2-1.png"></p>
<p>We also look at some of the Shapley value explanations and see that
many methods produce similar explanations.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/mixed-plot-3-1.png"></p>
<p>We can also focus on the Shapley value explanations for the best five
methods according to the <span class="math inline">\(\operatorname{MSE}_v\)</span> criterion. We also
include the <code>ctree</code> method, the best-performing Monte
Carlo-based method.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list_mixed</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="st">"MC_ctree"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">best_methods</span><span class="op">)</span> <span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">best_methods</span>, <span class="st">"MC_ctree"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">[</span><span class="va">best_methods</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression/mixed-plot-4-1.png"></p>
</div>
</div>
<div class="section level2">
<h2 id="regression-arguments-as-strings">Regression arguments as strings<a class="anchor" aria-label="anchor" href="#regression-arguments-as-strings"></a>
</h2>
<p>In this section, we demonstrate that the
<code>regression.model</code>, <code>regression.tune_values</code>, and
<code>regression.recipe_func</code> parameters can be provided as
strings. This is a property which is convenient if the
<code><a href="../reference/explain.html">explain()</a></code> function is called from Python. That is, the user
only has to specify strings containing R code instead of having to deal
with creating the R objects in Python. In the code chunk below, we see
that we obtain identical <span class="math inline">\(\operatorname{MSE}_v\)</span> scores for the
string and non-string versions.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list_str</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::linear_reg()"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_pcr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::linear_reg()"</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="st">"function(regression_recipe) {</span></span>
<span><span class="st">    return(recipes::step_pca(regression_recipe, recipes::all_numeric_predictors(), num_comp = 2))</span></span>
<span><span class="st">  }"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="st">"function(regression_recipe) {</span></span>
<span><span class="st">    return(recipes::step_ns(regression_recipe, recipes::all_numeric_predictors(), deg_free = 2))</span></span>
<span><span class="st">  }"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::decision_tree(</span></span>
<span><span class="st">    tree_depth = hardhat::tune(), engine = 'rpart', mode = 'regression'</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="st">"dials::grid_regular(dials::tree_depth(), levels = 4)"</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation</span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">1</span>, <span class="co"># As we used this for the non-string version</span></span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::rand_forest(</span></span>
<span><span class="st">    mtry = hardhat::tune(), trees = hardhat::tune(), engine = 'ranger', mode = 'regression'</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="st">"function(x) {</span></span>
<span><span class="st">      dials::grid_regular(dials::mtry(c(1, ncol(x))), dials::trees(c(50, 750)), levels = 3)</span></span>
<span><span class="st">    }"</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation as the surrogate model</span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sur_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::rand_forest(</span></span>
<span><span class="st">    mtry = hardhat::tune(), trees = hardhat::tune(), engine = 'ranger', mode = 'regression'</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="st">"dials::grid_regular(</span></span>
<span><span class="st">    dials::mtry(c(1, ncol(x_explain))),</span></span>
<span><span class="st">    dials::trees(c(50, 750)),</span></span>
<span><span class="st">    levels = 6</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span></span>
<span><span class="co"># See that the evaluation scores match the non-string versions.</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list_str</span><span class="op">)</span></span>
<span><span class="co">#&gt;               MSEv  Time</span></span>
<span><span class="co">#&gt; sep_lm      745.21  1.14</span></span>
<span><span class="co">#&gt; sep_pcr     784.91  1.19</span></span>
<span><span class="co">#&gt; sep_splines 165.13  1.15</span></span>
<span><span class="co">#&gt; sep_tree_cv 169.96 20.65</span></span>
<span><span class="co">#&gt; sep_rf_cv   212.88 39.29</span></span>
<span><span class="co">#&gt; sur_rf_cv   171.84 30.51</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">explanation_list_str</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;               MSEv  Time</span></span>
<span><span class="co">#&gt; sep_lm      745.21  0.77</span></span>
<span><span class="co">#&gt; sep_pcr     784.91  1.32</span></span>
<span><span class="co">#&gt; sep_splines 165.13  1.09</span></span>
<span><span class="co">#&gt; sep_tree_cv 169.96 17.31</span></span>
<span><span class="co">#&gt; sep_rf_cv   212.88 38.41</span></span>
<span><span class="co">#&gt; sur_rf_cv   171.84 30.55</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="vignette-summary">Vignette summary<a class="anchor" aria-label="anchor" href="#vignette-summary"></a>
</h2>
<p>This vignette demonstrates the rich possibilities that the regression
paradigm and the <code>tidymodels</code> framework add to the
<code>shapr</code> package. We have seen that regression-based methods
are on par with or outperform the Monte Carlo-based methods regarding
the <span class="math inline">\(\operatorname{MSE}_v\)</span> evaluation
criterion. Furthermore, we have seen that the regression-based methods
are relatively computationally fast and that parallelization can be used
to speed up the computations.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-tidymodels" class="csl-entry">
Kuhn, Max, and Hadley Wickham. 2020. <em>Tidymodels: A Collection of
Packages for Modeling and Machine Learning Using Tidyverse
Principles.</em> <a href="https://www.tidymodels.org" class="external-link">https://www.tidymodels.org</a>.
</div>
<div id="ref-olsen2024comparative" class="csl-entry">
Olsen, Lars Henry Berge, Ingrid Kristine Glad, Martin Jullum, and
Kjersti Aas. 2024. <span>“A Comparative Study of Methods for Estimating
Model-Agnostic Shapley Value Explanations.”</span> <em>Data Mining and
Knowledge Discovery</em>, 1–48.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Nikolai Sellereite, Martin Jullum, Lars Henry Berge Olsen, Annabelle Redelmeier, Jon Lachmann, Norsk Regnesentral.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.8.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
