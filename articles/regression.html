<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Shapley value explanations using the regression paradigm ‚Ä¢ shapr</title>
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Shapley value explanations using the regression paradigm">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">shapr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.2.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-vignettes" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Vignettes</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-vignettes">
<li><a class="dropdown-item" href="../articles/general_usage.html">General usage of shapr</a></li>
    <li><a class="dropdown-item" href="../articles/vaeac.html">Advanced usage of the `vaeac` approach</a></li>
    <li><a class="dropdown-item" href="../articles/regression.html">The separate and surrogate regression approches</a></li>
    <li><a class="dropdown-item" href="../articles/asymmetric_causal.html">Asymmetric and Causal Shapley values</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">News</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Manual</a></li>
<li class="nav-item"><a class="nav-link" href="../shaprpy.html">Python</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/NorskRegnesentral/shapr/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Shapley value explanations using the regression paradigm</h1>
                        <h4 data-toc-skip class="author">Lars Henry
Berge Olsen</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/NorskRegnesentral/shapr/blob/master/vignettes/regression.Rmd" class="external-link"><code>vignettes/regression.Rmd</code></a></small>
      <div class="d-none name"><code>regression.Rmd</code></div>
    </div>

    
    
<p>This vignette elaborates and demonstrates the regression paradigm
explained in <span class="citation">Olsen et al. (2024)</span>. We
describe how to specify the regression model, how to enable automatic
cross-validation of the model‚Äôs hyperparameters, and applying
pre-processing steps to the data before fitting the regression models.
We refer to <span class="citation">Olsen et al. (2024)</span> for when
one should use the different paradigms, method classes, and methods.</p>
<p><span class="citation">Olsen et al. (2024)</span> divides the
regression paradigm into the separate and surrogate regression method
classes. In this vignette, we briefly introduce the two method classes.
For an in-depth explanation, we refer the reader to Sections 3.5 and 3.6
in <span class="citation">Olsen et al. (2024)</span>.</p>
<p>Briefly stated, the regression paradigm uses regression models to
directly estimate the contribution function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo>=</mo><msubsup><mi>ùê±</mi><mi>S</mi><mo>*</mo></msubsup><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">v(S) = E[f(\boldsymbol{x})|\boldsymbol{x}_S = \boldsymbol{x}_S^*]</annotation></semantics></math>.
The separate regression method class fits a separate regression model
for each coalition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>,
while the surrogate regression method class fits a single regression
model to simultaneously predict the contribution function for all
coalitions.</p>
<p>The <code>shapr</code> package supports any regression model from the
popular <code>tidymodels</code> package developed by <span class="citation">Kuhn and Wickham (2020)</span>. The <a href="https://www.tidymodels.org/" class="external-link"><code>tidymodels</code></a> framework
is a collection of packages for modeling and machine learning using <a href="https://www.tidyverse.org/" class="external-link"><code>tidyverse</code></a> principles.
Some packages included in the <code>tidymodels</code> framework are
<code>parsnip</code>, <code>recipes</code>, <code>workflows</code>
<code>tune</code>, and <code>rsample</code>; see the <a href="#setup">setup</a> section below for more examples. Furthermore,
click <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">here</a> to
access the complete list of supported regression models in the
<code>tidymodels</code> package. There are currently 80 supported
models, but the framework also allows adding regression models not
already implemented in <code>tidymodels</code>. It is also possible to
apply a wide range of pre-processing data steps. For instance, we can
either apply the linear regression model directly to the data or
pre-process the data to compute principal components (principal
component regression) before fitting the linear regression to the first
few eigenvectors (processed features), see the <a href="#separate_preproc">pre-process</a> section for an example. In the
<a href="#new">add new regression methods</a> section, we demonstrate
how to incorporate the projection pursuit regression model into the
<code>tidymodels</code> framework.</p>
<p>Note that our framework does not currently support model formulas
with special terms. For example, we do not support
<code><a href="https://parsnip.tidymodels.org/reference/gen_additive_mod.html" class="external-link">parsnip::gen_additive_mod</a></code> (i.e., <code><a href="https://rdrr.io/pkg/mgcv/man/gam.html" class="external-link">mgcv::gam()</a></code>)
as it uses a non-standard notion in its formulas (in this case, the
<code>s(feature, k = 2)</code> function). See
<code>?parsnip::model_formula()</code> for more information. However,
this hurdle is overcome by pre-processing data steps containing spline
functions, which we showcase in the <a href="#separate_preproc">pre-process</a> section for the separate
regression method class.</p>
<p>In the <a href="#mixed">mixed data</a> section, we demonstrate that
the regression-based methods work on mixed data, too. However, we must
add a pre-processing step for the regression models that do not natively
support categorical data to encode the categorical features.</p>
<p>We use the same data and predictive models in this vignette as in the
general usage.</p>
<p>See the end of the <a href="#summary_figures">continious data</a> and
<a href="#summary_mixed">mixed data</a> sections for summary figures of
all the methods used in this vignette to compute the Shapley value
explanations.</p>
<div class="section level2">
<h2 id="separate">The separate regression method class<a class="anchor" aria-label="anchor" href="#separate"></a>
</h2>
<p>In the <code>regression_separate</code> methods, we train a new
regression model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>S</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê±</mi><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g_S(\boldsymbol{x}s)</annotation></semantics></math>
to estimate the conditional expectation for each coalition of
features.</p>
<p>The idea is to estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê±</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo>=</mo><msubsup><mi>ùê±</mi><mi>S</mi><mo>*</mo></msubsup><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ùê±</mi><mover><mi>S</mi><mo accent="true">‚Äæ</mo></mover></msub><mo>,</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo>=</mo><msubsup><mi>ùê±</mi><mi>S</mi><mo>*</mo></msubsup><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">v(S) = E[f(\boldsymbol{x})|\boldsymbol{x}_S = \boldsymbol{x}_S^*] = E[f(\boldsymbol{x}_{\bar{S}},\boldsymbol{x}_S)|\boldsymbol{x}_S=\boldsymbol{x}_S^*]</annotation></semantics></math>
separately for each coalition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
using regression. Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùíü</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msup><mi>ùê±</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>,</mo><msup><mi>y</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mtext mathvariant="normal">train</mtext></msub></msubsup></mrow><annotation encoding="application/x-tex">\mathcal{D} = \{ \boldsymbol{x}^{[i]}, y^{[i]} \}_{i=1}^{N_{\text{train}}}</annotation></semantics></math>
denote the training data, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ùê±</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><annotation encoding="application/x-tex">\boldsymbol{x}^{[i]}</annotation></semantics></math>
is the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>th
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-dimensional
input and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>y</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><annotation encoding="application/x-tex">y^{[i]}</annotation></semantics></math>
is the associated response. For each coalition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>‚äÜ</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>M</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">S \subseteq \{1,2,\dots,M\}</annotation></semantics></math>,
the corresponding training data set is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>ùíü</mi><mi>S</mi></msub><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msubsup><mi>ùê±</mi><mi>S</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msubsup><mo>,</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><munder><munder><mrow><msubsup><mi>ùê±</mi><mover><mi>S</mi><mo accent="true">‚Äæ</mo></mover><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msubsup><mo>,</mo><msubsup><mi>ùê±</mi><mi>S</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msubsup></mrow><mo accent="true">‚èü</mo></munder><msup><mi>ùê±</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup></munder><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mtext mathvariant="normal">train</mtext></msub></msubsup><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msubsup><mi>ùê±</mi><mi>S</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msubsup><mo>,</mo><munder><munder><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ùê±</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="true">‚èü</mo></munder><msup><mi>z</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup></munder><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mtext mathvariant="normal">train</mtext></msub></msubsup><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msubsup><mi>ùê±</mi><mi>S</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msubsup><mo>,</mo><msup><mi>z</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>i</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><msubsup><mo stretchy="false" form="postfix">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>N</mi><mtext mathvariant="normal">train</mtext></msub></msubsup><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*}
            \mathcal{D}_S
            =
            \{\boldsymbol{x}_S^{[i]}, f(\underbrace{\boldsymbol{x}_\bar{S}^{[i]}, \boldsymbol{x}_S^{[i]}}_{\boldsymbol{x}^{[i]}})\}_{i=1}^{N_{\text{train}}}
            =
            \{\boldsymbol{x}_S^{[i]}, \underbrace{f(\boldsymbol{x}^{[i]})}_{z^{[i]}}\}_{i=1}^{N_{\text{train}}}
            =
            \{\boldsymbol{x}_S^{[i]}, z^{[i]}\}_{i=1}^{N_{\text{train}}}.
\end{align*}</annotation></semantics></math></p>
<p>For each data set
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùíü</mi><mi>S</mi></msub><annotation encoding="application/x-tex">\mathcal{D}_S</annotation></semantics></math>,
we train a regression model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>S</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê±</mi><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g_S(\boldsymbol{x}s)</annotation></semantics></math>
with respect to the mean squared error loss function. That is, we fit a
regression model where the prediction
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê±</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(\boldsymbol{x})</annotation></semantics></math>
is acting as the response and the feature subset of coalition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùê±</mi><mi>S</mi></msub><annotation encoding="application/x-tex">\boldsymbol{x}_S</annotation></semantics></math>,
is acting as the available features. The optimal model, with respect to
the loss function, is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>g</mi><mi>S</mi><mo>*</mo></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>z</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ùê±</mi><mover><mi>S</mi><mo accent="true">‚Äæ</mo></mover></msub><mo>,</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">g^*_S(\boldsymbol{x}_S) = E[z|\boldsymbol{x}_S] = E[f(\boldsymbol{x}_\bar{S}, \boldsymbol{x}_S)|\boldsymbol{x}_S]</annotation></semantics></math>,
which corresponds to the contribution function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">v(S)</annotation></semantics></math>.
The regression model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>g</mi><mi>S</mi></msub><annotation encoding="application/x-tex">g_S</annotation></semantics></math>
aims for the optimal, hence, it resembles/estimates the contribution
function, i.e.,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>S</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mover><mi>v</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚âà</mo><mi>v</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ùê±</mi><mover><mi>S</mi><mo accent="true">‚Äæ</mo></mover></msub><mo>,</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo>=</mo><msubsup><mi>ùê±</mi><mi>S</mi><mo>*</mo></msubsup><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">g_S(\boldsymbol{x}_S) = \hat{v}(S) \approx v(S) = E[f(\boldsymbol{x}_\bar{S}, \boldsymbol{x}_S) | \boldsymbol{x}_S = \boldsymbol{x}_S^*]</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="separate_code">Code<a class="anchor" aria-label="anchor" href="#separate_code"></a>
</h3>
<p>In this supplementary vignette, we use the same data and explain the
same model type as in the general usage. We train a simple
<code>xgboost</code> model on the <code>airquality</code> dataset and
demonstrate how to use the <code>shapr</code> and the separate
regression method class to explain the individual predictions.</p>
<div class="section level4">
<h4 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h4>
<p>First, we set up the <code>airquality</code> dataset and train an
<code>xgboost</code> model, whose predictions we want to explain using
the Shapley value explanation framework. We import all packages in the
<code>tidymodels</code> framework in the code chunk below, but we could
have specified them directly, too. In this vignette, we use the
following packages in the <code>tidymodels</code> framework:
<code>parsnip</code>, <code>recipes</code>, <code>workflows</code>,
<code>dials</code>, <code>hardhat</code>, <code>tibble</code>,
<code>rlang</code>, and <code>ggplot2</code>. We include the
<code>package::function()</code> notation throughout this vignette to
indicate which package the functions originate from in the
<code>tidymodels</code> framework.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Either use `library(tidymodels)` or separately specify the libraries indicated above</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org" class="external-link">tidymodels</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://norskregnesentral.github.io/shapr/">shapr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Ensure that shapr's functions are prioritzed, otherwise we need to use the `shapr::`</span></span>
<span><span class="co"># prefix when calling explain(). The `conflicted` package is imported by `tidymodels`.</span></span>
<span><span class="fu">conflicted</span><span class="fu">::</span><span class="fu">conflicts_prefer</span><span class="op">(</span><span class="fu">shapr</span><span class="fu">::</span><span class="va"><a href="../reference/explain.html">explain</a></span>, <span class="fu">shapr</span><span class="fu">::</span><span class="va"><a href="../reference/prepare_data.html">prepare_data</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Other libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost" class="external-link">xgboost</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"airquality"</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/data.table/man/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html" class="external-link">complete.cases</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month"</span><span class="op">)</span></span>
<span><span class="va">y_var</span> <span class="op">&lt;-</span> <span class="st">"Ozone"</span></span>
<span></span>
<span><span class="va">ind_x_explain</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="fu"><a href="https://rdrr.io/r/base/get.html" class="external-link">get</a></span><span class="op">(</span><span class="va">y_var</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">x_explain</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fitting a basic xgboost model to the training data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># Set seed for reproducibility</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">xgboost</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span>,</span>
<span>  label <span class="op">=</span> <span class="va">y_train</span>,</span>
<span>  nround <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Specifying the phi_0, i.e. the expected prediction without any features</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># List to store all the explanation objects</span></span>
<span><span class="va">explanation_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>To make the rest of the vignette easier to follow, we create some
helper functions that plot and summarize the results of the explanation
methods. This code block is optional to understand and can be
skipped.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot the MSEv criterion scores as horizontal bars and add dashed line of one method's score</span></span>
<span><span class="va">plot_MSEv_scores</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">explanation_list</span>, <span class="va">method_line</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">fig</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html" class="external-link">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">rel</a></span><span class="op">(</span><span class="fl">0.95</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">fig</span> <span class="op">&lt;-</span> <span class="va">fig</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html" class="external-link">scale_x_discrete</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/levels.html" class="external-link">levels</a></span><span class="op">(</span><span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">method_line</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">method_line</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">fig</span> <span class="op">&lt;-</span> <span class="va">fig</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span></span>
<span>      yintercept <span class="op">=</span> <span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">MSEv</span><span class="op">[</span><span class="va">fig</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span> <span class="op">==</span> <span class="va">method_line</span><span class="op">]</span>,</span>
<span>      linetype <span class="op">=</span> <span class="st">"dashed"</span>,</span>
<span>      color <span class="op">=</span> <span class="st">"black"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">fig</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Extract the MSEv criterion scores and elapsed times</span></span>
<span><span class="va">print_MSEv_scores_and_time</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span></span>
<span>    <span class="va">explanation_list</span>,</span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">explanation</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">explanation</span><span class="op">$</span><span class="va">MSEv</span><span class="op">$</span><span class="va">MSEv</span><span class="op">$</span><span class="va">MSEv</span>, <span class="va">explanation</span><span class="op">$</span><span class="va">timing</span><span class="op">$</span><span class="va">total_time_secs</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>  <span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"MSEv"</span>, <span class="st">"Time"</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Extract the k best methods in decreasing order</span></span>
<span><span class="va">get_k_best_methods</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">explanation_list</span>, <span class="va">k_best</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">res</span><span class="op">$</span><span class="va">MSEv</span><span class="op">)</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="va">k_best</span><span class="op">)</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>To establish a baseline against which to compare the regression
methods, we will compare them with the Monte Carlo-based
<code>empirical</code> approach with default hyperparameters. In the
last section, we include all Monte Carlo-based methods implemented in
<code>shapr</code> to make an extensive comparison.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the Shapley value explanations using the empirical method</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">MC_empirical</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:36 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: empirical</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7864f7b70f7.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="linear-regression-model">Linear regression model<a class="anchor" aria-label="anchor" href="#linear-regression-model"></a>
</h4>
<p>Then we compute the Shapley value explanations using a linear
regression model and the separate regression method class.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:40 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78629466589.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>A linear model is often not flexible enough to properly model the
contribution function. Thus, it can produce inaccurate Shapley value
explanations. The figure below shows that the <code>empirical</code>
approach outperforms the linear regression model approach quite
significantly concerning the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation criterion.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2Flm-emp-msev-1.png"></p>
</div>
<div class="section level4">
<h4 id="separate_preproc">Pre-processing<a class="anchor" aria-label="anchor" href="#separate_preproc"></a>
</h4>
<p>This section describes how to pre-process the data before fitting the
separate regression models. We demonstrate this for the linear
regression model, but we can apply this pre-processing to other
regression methods.</p>
<p>The <code>recipe</code> package in the <code>tidymodels</code>
framework contains many functions to pre-process the data before fitting
the model, for example, normalization, interaction, encodings, and
transformations (e.g., log, splines, pls, pca). Click <a href="https://recipes.tidymodels.org/reference/index.html" class="external-link">here</a> to
access a complete list of all available functions. The list also
contains functions for helping us select which features to apply the
functions to, e.g., <code><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">recipes::all_predictors()</a></code>,
<code><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">recipes::all_numeric_predictors()</a></code>, and
<code><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">recipes::all_factor_predictors()</a></code> apply the functions to all
features, only the numerical features, and only the factor features,
respectively. We can also specify the names of the features to which the
functions are applied. However, as the included features change in each
coalition, we need to check that the feature we want to apply the
function to is present in the dataset. We give an example of this
below.</p>
<p>First, we demonstrate how to compute the principal components and use
(up to) the first two components for each separate linear regression
model. We write ‚Äúup to‚Äù as we can only compute a single principal
component for the singleton coalitions, i.e., the feature itself. This
regression model is called principal component regression.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_pcr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_pca.html" class="external-link">step_pca</a></span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric_predictors</a></span><span class="op">(</span><span class="op">)</span>, num_comp <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:41 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78667333f80.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>Second, we apply a pre-processing step that computes the basis
expansions of the features using natural splines with two degrees of
freedom. This is similar to fitting a generalized additive model.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_ns.html" class="external-link">step_ns</a></span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric_predictors</a></span><span class="op">(</span><span class="op">)</span>, deg_free <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:42 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78652874079.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>Finally, we provide an example where we include interactions between
the features <code>Solar.R</code> and <code>Wind</code>, log-transform
<code>Solar.R</code>, convert <code>Wind</code> to be between 0 and 1
and then take the square root, include polynomials of the third degree
for <code>Temp</code>, and apply the Box-Cox transformation to
<code>Month</code>. These transformations are only applied when the
features are present for the different separate models.</p>
<p>Furthermore, we stress that the purpose of this example is to
highlight the framework‚Äôs flexibility, <em>not</em> that the
transformations below are reasonable.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Example function of how to apply step functions from the recipes package to specific features</span></span>
<span><span class="va">regression.recipe_func</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Get the names of the present features</span></span>
<span>  <span class="va">feature_names</span> <span class="op">&lt;-</span> <span class="va">recipe</span><span class="op">$</span><span class="va">var_info</span><span class="op">$</span><span class="va">variable</span><span class="op">[</span><span class="va">recipe</span><span class="op">$</span><span class="va">var_info</span><span class="op">$</span><span class="va">role</span> <span class="op">==</span> <span class="st">"predictor"</span><span class="op">]</span></span>
<span></span>
<span>  <span class="co"># If Solar.R and Wind is present, then we add the interaction between them</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/all.html" class="external-link">all</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_interact.html" class="external-link">step_interact</a></span><span class="op">(</span><span class="va">recipe</span>, terms <span class="op">=</span> <span class="op">~</span> <span class="va">Solar.R</span><span class="op">:</span><span class="va">Wind</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># If Solar.R is present, then log transform it</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Solar.R"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_log.html" class="external-link">step_log</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Solar.R</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># If Wind is present, then scale it to be between 0 and 1 and then sqrt transform it</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Wind"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_sqrt.html" class="external-link">step_sqrt</a></span><span class="op">(</span><span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_range.html" class="external-link">step_range</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Wind</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># If Temp is present, then expand it using orthogonal polynomials of degree 3</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Temp"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_poly.html" class="external-link">step_poly</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Temp</span>, degree <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># If Month is present, then Box-Cox transform it</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="st">"Month"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">feature_names</span><span class="op">)</span> <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_BoxCox.html" class="external-link">step_BoxCox</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="va">Month</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Finally we normalize all features (not needed as LM does this internally)</span></span>
<span>  <span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/step_normalize.html" class="external-link">step_normalize</a></span><span class="op">(</span><span class="va">recipe</span>, <span class="fu">recipes</span><span class="fu">::</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric_predictors</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Compute the Shapley values using the pre-processing steps defined above</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_reicpe_example</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="va">regression.recipe_func</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:43 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7862f1e5e2d.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>We can examine the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation scores, and we see that the method using natural splines
significantly outperforms the other methods.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2Fpreproc-plot-1.png"></p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      MSEv Time</span></span>
<span><span class="co">#&gt; MC_empirical       179.43 3.35</span></span>
<span><span class="co">#&gt; sep_lm             745.21 0.75</span></span>
<span><span class="co">#&gt; sep_pcr            784.91 0.88</span></span>
<span><span class="co">#&gt; sep_splines        165.13 0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example 687.45 1.25</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="other-regression-models">Other regression models<a class="anchor" aria-label="anchor" href="#other-regression-models"></a>
</h4>
<p>In the following example, we use a decision tree model instead of the
simple linear regression model.</p>
<p>The <code>tidymodels</code> framework supports several
implementations of the decision tree model. We use
<code>set_engine("rpart")</code> to specify that we want to use the
implementation in the <code>rpart</code> package, and we use
<code>set_mode("regression")</code> to specify that we are doing
regression. The <code>tidymodels</code> framework uses the default
hyperparameter values set in <code>rpart</code> when we do not specify
them. By searching for ‚Äúdecision tree‚Äù in the <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">list of tidymodels</a>,
we see that the default hyperparameter values for the <a href="https://parsnip.tidymodels.org//reference/details_decision_tree_rpart.html" class="external-link"><code>decision_tree_rpart</code></a>
model are <code>tree_depth = 30</code>, <code>min_n = 2</code>, and
<code>cost_complexity = 0.01</code>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Decision tree with specified parameters (stumps)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_stump</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fl">1</span>,</span>
<span>    min_n <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:44 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786b5a978d.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Decision tree with default parameters</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_default</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:45 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7867004239c.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>We can also set
<code>regression.model = parsnip::decision_tree(tree_depth = 1, min_n = 2, cost_complexity = 0.01) %&gt;% parsnip::set_engine("rpart") %&gt;% parsnip::set_mode("regression")</code>
if we want to use the pipe function (<code>%&gt;%</code>).</p>
<p>We can now compare the two new methods. The decision tree with
default parameters outperforms the linear model approach concerning the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
criterion and is on the same level as the empirical approach. We
obtained a worse method by using stumps, i.e., trees with depth one.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2Fdecision-tree-plot-1.png"></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      MSEv Time</span></span>
<span><span class="co">#&gt; MC_empirical       179.43 3.35</span></span>
<span><span class="co">#&gt; sep_lm             745.21 0.75</span></span>
<span><span class="co">#&gt; sep_pcr            784.91 0.88</span></span>
<span><span class="co">#&gt; sep_splines        165.13 0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example 687.45 1.25</span></span>
<span><span class="co">#&gt; sep_tree_stump     218.05 1.00</span></span>
<span><span class="co">#&gt; sep_tree_default   177.68 0.73</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="separate_cv">Cross-validation<a class="anchor" aria-label="anchor" href="#separate_cv"></a>
</h4>
<p>Another option is to use cross-validation to tune the
hyperparameters. To do this, we need to specify three things:</p>
<ol style="list-style-type: decimal">
<li>In <code>regression.model</code>, we need to specify which
parameters to tune in the model. We do this by setting the parameter
equal to <code><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">hardhat::tune()</a></code>. For example., if we want to tune
the <code>tree_depth</code> parameter in the
<code><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">parsnip::decision_tree</a></code> model while using default parameters
for the other parameters, then we set
<code>parsnip::decision_tree(tree_depth = hardhat::tune())</code>.</li>
<li>In <code>regression.tune_values</code>, we must provide either a
data.frame (can also be a data.table or tibble) containing the possible
hyperparameter values or a function that takes in the training data for
each combination/coalition and outputs a data.frame containing the
possible hyperparameter values. The latter allows us to use different
hyperparameter values for different coalition sizes, which is essential
if a hyperparameter‚Äôs domain changes with the coalition size. For
example, see the example below where we want to tune the
<code>mtry</code> parameter in <code>ranger</code> (random forest). The
column names of <code>regression.tune_values</code> (or the output if it
is a function) must match the tunable hyperparameters specified in
<code>regression.model</code>. For the example above,
<code>regression.tune_values</code> must be a one-column data.frame with
the column name <code>tree_depth</code>. We can either manually specify
the hyperparameter values or use the <code>dials</code> package, e.g.,
<code>dials::grid_regular(dials::tree_depth(), levels = 5)</code>. Or it
can be a function that outputs a data.frame on the same form.</li>
<li>Specifying the <code>regression.vfold_cv_para</code> parameter is
optional. If used, then <code>regression.vfold_cv_para</code> must be a
list specifying the parameters to send to the cross-validation function
<code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">rsample::vfold_cv()</a></code>. Use <code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">?rsample::vfold_cv</a></code> to
see the default parameters. The names of the objects in the
<code>regression.vfold_cv_para</code> list must match the parameter
names in <code><a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">rsample::vfold_cv()</a></code>. For example, if we want
5-fold cross-validation, we set
<code>regression.vfold_cv_para = list(v = 5)</code>.</li>
</ol>
<p>First, let us look at some ways to specify
<code>regression.tune_values</code>. Note that <code>dials</code> have
several other grid functions, e.g., <code><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">dials::grid_random()</a></code>
and <code><a href="https://dials.tidymodels.org/reference/grid_max_entropy.html" class="external-link">dials::grid_latin_hypercube()</a></code>.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Possible ways to define the `regression.tune_values` object.</span></span>
<span><span class="co"># function(x) dials::grid_regular(dials::tree_depth(), levels = 4)</span></span>
<span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">tree_depth</a></span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/data.table/man/data.table.html" class="external-link">data.table</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Can also use data.frame or tibble</span></span>
<span></span>
<span><span class="co"># For several features</span></span>
<span><span class="co"># function(x) dials::grid_regular(dials::tree_depth(), dials::cost_complexity(), levels = 3)</span></span>
<span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">tree_depth</a></span><span class="op">(</span><span class="op">)</span>, <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">cost_complexity</a></span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.05</span>, <span class="fl">0.01</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We will now demonstrate how to use cross-validation to fine-tune the
separate decision tree regression method. In the following examples, we
consider two versions. In the first example, we use cross-validation to
tune the <code>tree_depth</code> parameter using the
<code><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">dials::grid_regular()</a></code> function. In the second example, we
tune both the <code>tree_depth</code> and <code>cost_complexity</code>
parameters, but we will manually specify the possible hyperparameter
values this time.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Decision tree with cross validated depth (default values other parameters)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">tree_depth</a></span><span class="op">(</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7862e01b595.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Use trees with cross-validation on the depth and cost complexity. Manually set the values.</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_tree_cv_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:43:59 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78615cc7432.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>We also include one example with a random forest model where the
tunable hyperparameter <code>mtry</code> depends on the coalition size.
Thus, <code>regression.tune_values</code> must be a function that
returns a data.frame where the hyperparameter values for
<code>mtry</code> will change based on the coalition size. If we do not
let <code>regression.tune_values</code> be a function, then
<code>tidymodels</code> will crash for any <code>mtry</code> higher than
1. Furthermore, by setting letting
<code>"vS_details" %in% verbose</code>, we receive get messages with the
results of the cross-validation procedure ran within <code>shapr</code>.
Note that the tested hyperparameter value combinations change based on
the coalition size.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Using random forest with default parameters</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:44:24 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7863390470d.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  verbose <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"basic"</span>,<span class="st">"vS_details"</span><span class="op">)</span>, <span class="co"># To get printouts</span></span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:44:26 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7865f901637.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Additional details about the regression model</span></span>
<span><span class="co">#&gt; Random Forest Model Specification (regression)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Main Arguments: mtry = hardhat::tune() trees = hardhat::tune()</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Computational engine: ranger</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Extra info about the tuning of the regression model ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 6 best configs for  v(1 4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 50 rmse = 28.43 rmse_std_err = 3.02</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 750 rmse = 28.76 rmse_std_err = 2.57</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 400 rmse = 28.80 rmse_std_err = 2.64</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 50 rmse = 29.27 rmse_std_err = 2.29</span></span>
<span><span class="co">#&gt; #5: mtry = 2 trees = 400 rmse = 29.42 rmse_std_err = 2.40</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 750 rmse = 29.46 rmse_std_err = 2.20</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 6 best configs for  v(2 4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 50 rmse = 21.12 rmse_std_err = 0.73</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 750 rmse = 21.21 rmse_std_err = 0.66</span></span>
<span><span class="co">#&gt; #3: mtry = 2 trees = 400 rmse = 21.27 rmse_std_err = 1.02</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 750 rmse = 21.31 rmse_std_err = 1.01</span></span>
<span><span class="co">#&gt; #5: mtry = 1 trees = 400 rmse = 21.34 rmse_std_err = 0.69</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 50 rmse = 21.65 rmse_std_err = 0.94</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 6 best configs for  v(1 3) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 50 rmse = 21.34 rmse_std_err = 3.18</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 400 rmse = 21.56 rmse_std_err = 3.13</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 750 rmse = 21.68 rmse_std_err = 3.13</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 50 rmse = 21.79 rmse_std_err = 3.10</span></span>
<span><span class="co">#&gt; #5: mtry = 2 trees = 750 rmse = 21.85 rmse_std_err = 2.98</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 400 rmse = 21.89 rmse_std_err = 2.97</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 6 best configs for  v(3 4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 750 rmse = 22.94 rmse_std_err = 4.33</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 400 rmse = 23.13 rmse_std_err = 4.23</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 50 rmse = 23.43 rmse_std_err = 4.13</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 400 rmse = 23.86 rmse_std_err = 3.77</span></span>
<span><span class="co">#&gt; #5: mtry = 2 trees = 750 rmse = 24.00 rmse_std_err = 3.78</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 50 rmse = 24.57 rmse_std_err = 4.08</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 6 best configs for  v(2 3) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 2 trees = 50 rmse = 17.46 rmse_std_err = 2.26</span></span>
<span><span class="co">#&gt; #2: mtry = 2 trees = 750 rmse = 17.53 rmse_std_err = 2.43</span></span>
<span><span class="co">#&gt; #3: mtry = 2 trees = 400 rmse = 17.64 rmse_std_err = 2.38</span></span>
<span><span class="co">#&gt; #4: mtry = 1 trees = 750 rmse = 17.80 rmse_std_err = 2.09</span></span>
<span><span class="co">#&gt; #5: mtry = 1 trees = 50 rmse = 17.81 rmse_std_err = 1.79</span></span>
<span><span class="co">#&gt; #6: mtry = 1 trees = 400 rmse = 17.89 rmse_std_err = 2.13</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 3 best configs for  v(3) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 50 rmse = 22.55 rmse_std_err = 4.68</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 400 rmse = 22.59 rmse_std_err = 4.63</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 750 rmse = 22.64 rmse_std_err = 4.65</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 6 best configs for  v(1 2) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 400 rmse = 21.57 rmse_std_err = 2.25</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 750 rmse = 21.59 rmse_std_err = 2.29</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 50 rmse = 22.38 rmse_std_err = 2.10</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 400 rmse = 22.54 rmse_std_err = 2.09</span></span>
<span><span class="co">#&gt; #5: mtry = 2 trees = 750 rmse = 22.65 rmse_std_err = 2.09</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 50 rmse = 23.12 rmse_std_err = 2.23</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 3 best configs for  v(4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 750 rmse = 32.14 rmse_std_err = 4.32</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 400 rmse = 32.21 rmse_std_err = 4.31</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 50 rmse = 32.21 rmse_std_err = 4.25</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 3 best configs for  v(1) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 50 rmse = 30.34 rmse_std_err = 3.40</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 750 rmse = 30.53 rmse_std_err = 3.31</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 400 rmse = 30.63 rmse_std_err = 3.32</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 3 best configs for  v(2) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 750 rmse = 26.62 rmse_std_err = 2.33</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 400 rmse = 26.72 rmse_std_err = 2.29</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 50 rmse = 26.97 rmse_std_err = 2.24</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 9 best configs for  v(1 2 4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 2 trees = 750 rmse = 19.81 rmse_std_err = 1.53</span></span>
<span><span class="co">#&gt; #2: mtry = 2 trees = 400 rmse = 19.85 rmse_std_err = 1.64</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 750 rmse = 19.93 rmse_std_err = 1.93</span></span>
<span><span class="co">#&gt; #4: mtry = 1 trees = 400 rmse = 20.18 rmse_std_err = 1.90</span></span>
<span><span class="co">#&gt; #5: mtry = 2 trees = 50 rmse = 20.41 rmse_std_err = 1.56</span></span>
<span><span class="co">#&gt; #6: mtry = 3 trees = 50 rmse = 20.69 rmse_std_err = 1.54</span></span>
<span><span class="co">#&gt; #7: mtry = 3 trees = 750 rmse = 20.74 rmse_std_err = 1.69</span></span>
<span><span class="co">#&gt; #8: mtry = 3 trees = 400 rmse = 20.77 rmse_std_err = 1.76</span></span>
<span><span class="co">#&gt; #9: mtry = 1 trees = 50 rmse = 20.79 rmse_std_err = 1.89</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 9 best configs for  v(1 2 3) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 2 trees = 400 rmse = 16.16 rmse_std_err = 2.75</span></span>
<span><span class="co">#&gt; #2: mtry = 3 trees = 400 rmse = 16.30 rmse_std_err = 2.80</span></span>
<span><span class="co">#&gt; #3: mtry = 2 trees = 750 rmse = 16.41 rmse_std_err = 2.79</span></span>
<span><span class="co">#&gt; #4: mtry = 3 trees = 750 rmse = 16.43 rmse_std_err = 2.82</span></span>
<span><span class="co">#&gt; #5: mtry = 3 trees = 50 rmse = 16.52 rmse_std_err = 2.52</span></span>
<span><span class="co">#&gt; #6: mtry = 1 trees = 750 rmse = 16.69 rmse_std_err = 3.15</span></span>
<span><span class="co">#&gt; #7: mtry = 2 trees = 50 rmse = 16.89 rmse_std_err = 2.76</span></span>
<span><span class="co">#&gt; #8: mtry = 1 trees = 400 rmse = 16.98 rmse_std_err = 2.93</span></span>
<span><span class="co">#&gt; #9: mtry = 1 trees = 50 rmse = 17.69 rmse_std_err = 3.16</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 9 best configs for  v(1 3 4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 1 trees = 400 rmse = 21.88 rmse_std_err = 4.33</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 750 rmse = 21.96 rmse_std_err = 4.38</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 50 rmse = 22.03 rmse_std_err = 4.07</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 400 rmse = 22.65 rmse_std_err = 4.11</span></span>
<span><span class="co">#&gt; #5: mtry = 2 trees = 750 rmse = 22.72 rmse_std_err = 4.09</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 50 rmse = 22.89 rmse_std_err = 3.97</span></span>
<span><span class="co">#&gt; #7: mtry = 3 trees = 400 rmse = 23.38 rmse_std_err = 3.80</span></span>
<span><span class="co">#&gt; #8: mtry = 3 trees = 750 rmse = 23.50 rmse_std_err = 3.77</span></span>
<span><span class="co">#&gt; #9: mtry = 3 trees = 50 rmse = 23.88 rmse_std_err = 3.64</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Top 9 best configs for  v(2 3 4) (using 5-fold CV) </span></span>
<span><span class="co">#&gt; #1: mtry = 3 trees = 50 rmse = 17.96 rmse_std_err = 1.34</span></span>
<span><span class="co">#&gt; #2: mtry = 1 trees = 50 rmse = 17.97 rmse_std_err = 2.40</span></span>
<span><span class="co">#&gt; #3: mtry = 1 trees = 750 rmse = 18.63 rmse_std_err = 1.99</span></span>
<span><span class="co">#&gt; #4: mtry = 2 trees = 400 rmse = 18.76 rmse_std_err = 1.42</span></span>
<span><span class="co">#&gt; #5: mtry = 1 trees = 400 rmse = 18.79 rmse_std_err = 2.14</span></span>
<span><span class="co">#&gt; #6: mtry = 2 trees = 750 rmse = 18.80 rmse_std_err = 1.49</span></span>
<span><span class="co">#&gt; #7: mtry = 3 trees = 750 rmse = 19.12 rmse_std_err = 1.68</span></span>
<span><span class="co">#&gt; #8: mtry = 3 trees = 400 rmse = 19.14 rmse_std_err = 1.65</span></span>
<span><span class="co">#&gt; #9: mtry = 2 trees = 50 rmse = 19.33 rmse_std_err = 1.67</span></span></code></pre></div>
<p>We can look at the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation criterion, and we see that cross-validation improves both the
decision tree and the random forest methods. The two cross-validated
decision tree methods are comparable, but the second version outperforms
the first version by a small margin. This comparison is somewhat unfair
for the <code>empirical</code> approach, which also has hyperparameters
we could potentially tune. However, <code>shapr</code> does not
currently provide a function to do this automatically. In the figure
below, we include a vertical line at the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
score of the <code>empirical</code> method for easier comparison.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2Fdt-cv-plot-1.png"></p>
<p>Furthermore, we must consider that cross-validation drastically
increases the elapsed time (seconds) and determine if the increased
precision is worth the extra computational time. We also see that the
complex random forest method performs significantly worse than the
simple decision tree method. This result indicates that even though we
do hyperparameter tuning, we still overfit the data.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                      MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical       179.43  3.35</span></span>
<span><span class="co">#&gt; sep_lm             745.21  0.75</span></span>
<span><span class="co">#&gt; sep_pcr            784.91  0.88</span></span>
<span><span class="co">#&gt; sep_splines        165.13  0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example 687.45  1.25</span></span>
<span><span class="co">#&gt; sep_tree_stump     218.05  1.00</span></span>
<span><span class="co">#&gt; sep_tree_default   177.68  0.73</span></span>
<span><span class="co">#&gt; sep_tree_cv        222.71 12.35</span></span>
<span><span class="co">#&gt; sep_tree_cv_2      219.45 25.59</span></span>
<span><span class="co">#&gt; sep_rf             217.00  1.23</span></span>
<span><span class="co">#&gt; sep_rf_cv          212.64 30.98</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="separate_parallelization">Parallelization<a class="anchor" aria-label="anchor" href="#separate_parallelization"></a>
</h4>
<p>The <code>future</code> package can train the separate regression
models in parallel. More specifically, we parallelize both the training
step (when we fit the models) and the prediction step (when we compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">v(S)</annotation></semantics></math>).
In the general usage, we also explain how to enable progress bars.</p>
<p>In the code chunk below, we consider four regression-based methods.
The first method uses <code>xgboost</code> models with default
hyperparameter values, while the remaining three use cross-validation to
tune the number of trees. The second and third methods specify the same
potential hyperparameter values, but we run the former sequentially
while the latter is run in parallel to speed up the computations. The
fourth model is run in parallel but also tunes the depth of the trees
and not only the number of trees.</p>
<p>A small side note: If we let <code>"vS_details" %in% verbose</code>,
we can see which <code>tree</code> value <code>shapr</code> chooses for
each coalition. We would then see that the values 25, 50, 100, and 500
are never chosen. Thus, we can remove these values without influencing
the result and instead do a finer grid search among the lower values. We
do this in the fourth method.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Regular xgboost with default parameters</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:44:57 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78636583f25.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Cross validate the number of trees</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span></span>
<span>    <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">15</span>, <span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:44:58 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786931fb90.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Cross validate the number of trees in parallel on two threads</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/multisession.html" class="external-link">multisession</a></span>, workers <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost_cv_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span></span>
<span>    <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">15</span>, <span class="fl">25</span>, <span class="fl">50</span>, <span class="fl">100</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786491f190d.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Use a finer grid of low values for `trees` and also tune `tree_depth`</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/multisession.html" class="external-link">multisession</a></span>, workers <span class="op">=</span> <span class="fl">4</span><span class="op">)</span> <span class="co"># Change to 4 threads due to more complex CV</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_xgboost_cv_2_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">10</span>, <span class="fl">12</span>, <span class="fl">15</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:26 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78652904b76.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/sequential.html" class="external-link">sequential</a></span><span class="op">)</span> <span class="co"># To return to non-parallel computation</span></span></code></pre></div>
<p>Looking at the elapsed time, we see that the parallel version with
two workers is faster than the sequential version. Note that the elapsed
time of the parallel version is not reduced by a factor of two as the
creation of the parallel processes creates some additional overhead,
which is significant in this small example. However, parallelization
will yield considerable relative time improvements in more complex
situations. E.g., in settings with (more) training observations with
more features (i.e., more coalitions to compute) and situations with
more time-consuming cross-validation (i.e., more folds, hyperparameters
to tune, or hyperparameter values to consider). Furthermore, we see that
conducting the cross-validation has lowered the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>criterion
drastically. Finally, note that we obtain the same value whether we run
the cross-validation in parallel or sequentially.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  3.35</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.75</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  0.88</span></span>
<span><span class="co">#&gt; sep_splines          165.13  0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.25</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.00</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.73</span></span>
<span><span class="co">#&gt; sep_tree_cv          222.71 12.35</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        219.45 25.59</span></span>
<span><span class="co">#&gt; sep_rf               217.00  1.23</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.64 30.98</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.86</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       169.83 14.60</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   169.83 12.33</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 153.13 13.99</span></span></code></pre></div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="surrogate">The surrogate regression method class<a class="anchor" aria-label="anchor" href="#surrogate"></a>
</h2>
<p>Since the <code>regression_separate</code> methods train a new
regression model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>S</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>ùê±</mi><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g_S(\boldsymbol{x}_S)</annotation></semantics></math>
for each coalition
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>‚äÜ</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>M</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">S \subseteq \{1,2,\dots,M\}</annotation></semantics></math>,
a total of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>M</mi></msup><mo>‚àí</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2^M-2</annotation></semantics></math>
models has to be trained, which can be time-consuming for slowly fitted
models. The minus two corresponds to the empty and grand coalitions.</p>
<p>The <code>regression_surrogate</code> method class builds on the
ideas from the <code>regression_separate</code> class, but instead of
fitting a new regression model for each coalition, we train a single
regression model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>ùê±</mi><mo accent="true">ÃÉ</mo></mover><mi>S</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g(\tilde{\boldsymbol{x}}_S)</annotation></semantics></math>
for all coalitions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>‚äÜ</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>M</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">S \subseteq \{1,2,\dots,M\}</annotation></semantics></math>
(except the empty and grand coalitions), where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>ùê±</mi><mo accent="true">ÃÉ</mo></mover><mi>S</mi></msub><annotation encoding="application/x-tex">\tilde{\boldsymbol{x}}_S</annotation></semantics></math>
is an augmented version of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ùê±</mi><mi>S</mi></msub><annotation encoding="application/x-tex">\boldsymbol{x}_S</annotation></semantics></math>.
See Section 3.6.1 in <span class="citation">Olsen et al. (2024)</span>
for more details and examples.</p>
<p>We can also apply all the examples above for the separate regression
method class to the surrogate regression method class.</p>
<div class="section level3">
<h3 id="surrogate_code">Code<a class="anchor" aria-label="anchor" href="#surrogate_code"></a>
</h3>
<p>We demonstrate the surrogate method class using several regression
models below. More specifically, we use linear regression, random forest
(with and without (some) cross-validation), and <code>xgboost</code>
(with and without (some) cross-validation).</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Compute the Shapley value explanations using a surrogate linear regression model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:40 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7867d8c7486.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using xgboost with default parameters as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:41 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78660457178.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using xgboost with parameters tuned by cross-validation as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span>, <span class="fl">25</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:41 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7865d9b9594.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using random forest with default parameters as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:43 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78658adae63.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation as the surrogate model</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span></span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x_explain</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    levels <span class="op">=</span> <span class="fl">6</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:45:44 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78642356367.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<div class="section level4">
<h4 id="surrogate_parallelization">Parallelization<a class="anchor" aria-label="anchor" href="#surrogate_parallelization"></a>
</h4>
<p>The code chunk below demonstrates how to run the surrogate regression
method class in parallel using the <code>future</code> package. The
setup procedure is identical to the one we specified for <a href="#separate_parallelization">separate regression method class</a>.
The training step of the surrogate regression model can be run in
parallel if we tune some of its hyperparameters. We parallelize the
cross-validation procedure in the training step; hence, we apply no
parallelization in the training step of a surrogate model with specified
hyperparameters. Furthermore, we parallelize the prediction step (when
we compute
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">v(S)</annotation></semantics></math>)
in the same way as for the separate regression method class. Note that
parallelization will introduce some overhead, which can cause it to be
slower than running the code sequentially for smaller problems.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Cross validate the number of trees in parallel on four threads</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/multisession.html" class="external-link">multisession</a></span>, workers <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span></span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x_explain</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    levels <span class="op">=</span> <span class="fl">6</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:12 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7866c6710c6.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="fu">future</span><span class="fu">::</span><span class="va"><a href="https://future.futureverse.org/reference/sequential.html" class="external-link">sequential</a></span><span class="op">)</span> <span class="co"># To return to non-parallel computation</span></span>
<span></span>
<span><span class="co"># Check that we get identical Shapley value explanations</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/all.equal.html" class="external-link">all.equal</a></span><span class="op">(</span></span>
<span>  <span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv</span><span class="op">$</span><span class="va">shapley_values_est</span>,</span>
<span>  <span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_rf_cv_par</span><span class="op">$</span><span class="va">shapley_values_est</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span></code></pre></div>
<p>By looking at the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation criterion and the elapsed time, we see that the surrogate
methods (except the linear regression model) outperform
<code>empirical</code> but are not on the same level as the best
separate regression methods. Furthermore, parallelization (4 cores)
decreased the elapsed time while obtaining the same
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
score. The identical scores mean that the separate models are identical
and independent of whether they were run sequentially or in
parallel.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  3.35</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.75</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  0.88</span></span>
<span><span class="co">#&gt; sep_splines          165.13  0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.25</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.00</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.73</span></span>
<span><span class="co">#&gt; sep_tree_cv          222.71 12.35</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        219.45 25.59</span></span>
<span><span class="co">#&gt; sep_rf               217.00  1.23</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.64 30.98</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.86</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       169.83 14.60</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   169.83 12.33</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 153.13 13.99</span></span>
<span><span class="co">#&gt; sur_lm               649.61  0.42</span></span>
<span><span class="co">#&gt; sur_xgboost          169.92  0.44</span></span>
<span><span class="co">#&gt; sur_xgboost_cv       169.87  2.01</span></span>
<span><span class="co">#&gt; sur_rf               201.23  0.69</span></span>
<span><span class="co">#&gt; sur_rf_cv            172.09 27.44</span></span>
<span><span class="co">#&gt; sur_rf_cv_par        172.09 20.81</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods.</span></span>
<span><span class="co"># Include vertical line corresponding to the MSEv of the empirical method.</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2Fsurrogate-plot-1.png"></p>
</div>
</div>
</div>
<div class="section level2">
<h2 id="new">Add new regression methods<a class="anchor" aria-label="anchor" href="#new"></a>
</h2>
<p>Even though the <code>tidymodels</code> framework contains many <a href="https://www.tidymodels.org/find/parsnip/" class="external-link">models</a>, we might
want to add additional methods. In the following section, we demonstrate
how to add the projection pursuit regression (PPR) model as a new method
that can be used by <code>shapr</code> to compute the Shapley value
explanations, both as a separate and surrogate method.</p>
<p>We use the <code><a href="https://rdrr.io/r/stats/ppr.html" class="external-link">ppr()</a></code> implementation in the
<code>stats</code> package to fit the PPR model. The model has several
hyperparameters that can be tuned, but the main hyperparameter is the
number of terms <code>nterms</code>. The following is based on the <a href="https://www.tidymodels.org/learn/develop/models/" class="external-link"><code>tidymodels</code>
guide</a> on adding new regression models. We refer to that guide for
more details and explanations of the code below.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Step 1: register the model, modes, and arguments</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_new_model</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"ppr_reg"</span><span class="op">)</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_model_mode</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"ppr_reg"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_model_engine</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"ppr_reg"</span>, mode <span class="op">=</span> <span class="st">"regression"</span>, eng <span class="op">=</span> <span class="st">"ppr"</span><span class="op">)</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_dependency</a></span><span class="op">(</span><span class="st">"ppr_reg"</span>, eng <span class="op">=</span> <span class="st">"ppr"</span>, pkg <span class="op">=</span> <span class="st">"stats"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># If your function has several parameters, then we add one of these functions for each parameter</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_model_arg</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  original <span class="op">=</span> <span class="st">"nterms"</span>, <span class="co"># The original parameter name used in stats::ppr</span></span>
<span>  parsnip <span class="op">=</span> <span class="st">"num_terms"</span>, <span class="co"># Change parameter name to match tidymodels' name convention</span></span>
<span>  func <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>pkg <span class="op">=</span> <span class="st">"dials"</span>, fun <span class="op">=</span> <span class="st">"num_terms"</span><span class="op">)</span>, <span class="co"># list(pkg = "stats", fun = "ppr"),</span></span>
<span>  has_submodel <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 2: create the model function</span></span>
<span><span class="va">ppr_reg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">mode</span> <span class="op">=</span> <span class="st">"regression"</span>, <span class="va">engine</span> <span class="op">=</span> <span class="st">"ppr"</span>, <span class="va">num_terms</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># Check for correct mode</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">mode</span> <span class="op">!=</span> <span class="st">"regression"</span><span class="op">)</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/abort.html" class="external-link">abort</a></span><span class="op">(</span><span class="st">"`mode` should be 'regression'"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Check for correct engine</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">engine</span> <span class="op">!=</span> <span class="st">"ppr"</span><span class="op">)</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/abort.html" class="external-link">abort</a></span><span class="op">(</span><span class="st">"`engine` should be 'ppr'"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Capture the arguments in quosures</span></span>
<span>  <span class="va">args</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/enquo.html" class="external-link">enquo</a></span><span class="op">(</span><span class="va">num_terms</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># Save some empty slots for future parts of the specification</span></span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">new_model_spec</a></span><span class="op">(</span></span>
<span>    <span class="st">"ppr_reg"</span>,</span>
<span>    args <span class="op">=</span> <span class="va">args</span>,</span>
<span>    eng_args <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    mode <span class="op">=</span> <span class="va">mode</span>,</span>
<span>    method <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    engine <span class="op">=</span> <span class="va">engine</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Step 3: add a fit module</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_fit</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>  value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    interface <span class="op">=</span> <span class="st">"formula"</span>,</span>
<span>    protect <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"formula"</span>, <span class="st">"data"</span>, <span class="st">"weights"</span><span class="op">)</span>,</span>
<span>    func <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>pkg <span class="op">=</span> <span class="st">"stats"</span>, fun <span class="op">=</span> <span class="st">"ppr"</span><span class="op">)</span>,</span>
<span>    defaults <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_encoding</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>  options <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    predictor_indicators <span class="op">=</span> <span class="st">"traditional"</span>,</span>
<span>    compute_intercept <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    remove_intercept <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    allow_sparse_x <span class="op">=</span> <span class="cn">FALSE</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 4: add modules for prediction</span></span>
<span><span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/set_new_model.html" class="external-link">set_pred</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>  eng <span class="op">=</span> <span class="st">"ppr"</span>,</span>
<span>  mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"numeric"</span>,</span>
<span>  value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    pre <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    post <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    func <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="st">"predict"</span><span class="op">)</span>,</span>
<span>    args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      object <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/substitute.html" class="external-link">quote</a></span><span class="op">(</span><span class="va">object</span><span class="op">$</span><span class="va">fit</span><span class="op">)</span>,</span>
<span>      newdata <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/substitute.html" class="external-link">quote</a></span><span class="op">(</span><span class="va">new_data</span><span class="op">)</span>,</span>
<span>      type <span class="op">=</span> <span class="st">"numeric"</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Step 5: add tuning function (used by tune::tune_grid())</span></span>
<span><span class="va">tunable.ppr_reg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>    name <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"num_terms"</span><span class="op">)</span>,</span>
<span>    call_info <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>pkg <span class="op">=</span> <span class="cn">NULL</span>, fun <span class="op">=</span> <span class="st">"num_terms"</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    source <span class="op">=</span> <span class="st">"model_spec"</span>,</span>
<span>    component <span class="op">=</span> <span class="st">"ppr_reg"</span>,</span>
<span>    component_id <span class="op">=</span> <span class="st">"main"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Step 6: add updating function (used by tune::finalize_workflow())</span></span>
<span><span class="va">update.ppr_reg</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">object</span>, <span class="va">parameters</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">num_terms</span> <span class="op">=</span> <span class="cn">NULL</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/is_installed.html" class="external-link">check_installed</a></span><span class="op">(</span><span class="st">"parsnip"</span><span class="op">)</span></span>
<span>  <span class="va">eng_args</span> <span class="op">&lt;-</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">update_engine_parameters</a></span><span class="op">(</span><span class="va">object</span><span class="op">$</span><span class="va">eng_args</span>, fresh <span class="op">=</span> <span class="cn">TRUE</span>, <span class="va">...</span><span class="op">)</span></span>
<span>  <span class="va">args</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">rlang</span><span class="fu">::</span><span class="fu"><a href="https://rlang.r-lib.org/reference/enquo.html" class="external-link">enquo</a></span><span class="op">(</span><span class="va">num_terms</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">args</span> <span class="op">&lt;-</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">update_main_parameters</a></span><span class="op">(</span><span class="va">args</span>, <span class="va">parameters</span><span class="op">)</span></span>
<span>  <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/add_on_exports.html" class="external-link">new_model_spec</a></span><span class="op">(</span></span>
<span>    <span class="st">"ppr_reg"</span>,</span>
<span>    args <span class="op">=</span> <span class="va">args</span>,</span>
<span>    eng_args <span class="op">=</span> <span class="va">eng_args</span>,</span>
<span>    mode <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">mode</span>,</span>
<span>    method <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>    engine <span class="op">=</span> <span class="va">object</span><span class="op">$</span><span class="va">engine</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>We can now use the PPR model to compute the Shapley value
explanations. We can use it as a separate and surrogate regression
method, and we can either set the number of terms <code>num_terms</code>
to a specific value or use cross-validation to tune the hyperparameter.
We do all four combinations below.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># PPR separate with specified number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_ppr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:33 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7863200c7e2.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># PPR separate with cross-validated number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sep_ppr_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/num_comp.html" class="external-link">num_terms</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:34 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7865e9cc51b.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># PPR surrogate with specified number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_ppr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:44 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786796408ed.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># PPR surrogate with cross-validated number of terms</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">sur_ppr_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">ppr_reg</span><span class="op">(</span>num_terms <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/num_comp.html" class="external-link">num_terms</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">8</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:45 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7863ebffc8.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
<p>We can then compare the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
and some of the Shapley value explanations. We see that conducting
cross-validation improves the evaluation criterion, but also increase
the running time.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv  Time</span></span>
<span><span class="co">#&gt; MC_empirical         179.43  3.35</span></span>
<span><span class="co">#&gt; sep_lm               745.21  0.75</span></span>
<span><span class="co">#&gt; sep_pcr              784.91  0.88</span></span>
<span><span class="co">#&gt; sep_splines          165.13  0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45  1.25</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05  1.00</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68  0.73</span></span>
<span><span class="co">#&gt; sep_tree_cv          222.71 12.35</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        219.45 25.59</span></span>
<span><span class="co">#&gt; sep_rf               217.00  1.23</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.64 30.98</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72  0.86</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       169.83 14.60</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   169.83 12.33</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 153.13 13.99</span></span>
<span><span class="co">#&gt; sur_lm               649.61  0.42</span></span>
<span><span class="co">#&gt; sur_xgboost          169.92  0.44</span></span>
<span><span class="co">#&gt; sur_xgboost_cv       169.87  2.01</span></span>
<span><span class="co">#&gt; sur_rf               201.23  0.69</span></span>
<span><span class="co">#&gt; sur_rf_cv            172.09 27.44</span></span>
<span><span class="co">#&gt; sur_rf_cv_par        172.09 20.81</span></span>
<span><span class="co">#&gt; sep_ppr              327.23  0.76</span></span>
<span><span class="co">#&gt; sep_ppr_cv           246.28 10.24</span></span>
<span><span class="co">#&gt; sur_ppr              395.42  0.39</span></span>
<span><span class="co">#&gt; sur_ppr_cv           415.62  1.57</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2Fppr-plot-1.png"></p>
</div>
<div class="section level2">
<h2 id="summary_figures">Summary figures<a class="anchor" aria-label="anchor" href="#summary_figures"></a>
</h2>
<p>In this section, we compute the Shapley value explanations for the
Monte Carlo-based methods in the <code>shapr</code> package and compare
the results with all the regression-based methods above. The purpose of
this vignette is to demonstrate the rich possibilities that the
regression paradigm and the <code>tidymodels</code> framework adds to
the <code>shapr</code> package.</p>
<p>In the code chunk below, we compute the Shapley value explanations
using the different Monte Carlo-based methods.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list_MC</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the independence method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_independence</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"independence"</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:47 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: independence</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7862f2f3856.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Copy the Shapley value explanations for the empirical method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_empirical</span> <span class="op">&lt;-</span> <span class="va">explanation_list</span><span class="op">$</span><span class="va">MC_empirical</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the gaussian method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_gaussian</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"gaussian"</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:48 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: gaussian</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78626579ea5.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the copula method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_copula</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"copula"</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:48 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: copula</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78623a24f70.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the ctree method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_ctree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"ctree"</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:49 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: ctree</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78622c601b8.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Compute the Shapley value explanations using the vaeac method</span></span>
<span><span class="va">explanation_list_MC</span><span class="op">$</span><span class="va">MC_vaeac</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"vaeac"</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  vaeac.epochs <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:46:50 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: vaeac</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7863c7421dd.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Combine the two explanations lists</span></span>
<span><span class="va">explanation_list</span><span class="op">$</span><span class="va">MC_empirical</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="va">explanation_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">explanation_list_MC</span>, <span class="va">explanation_list</span><span class="op">)</span></span></code></pre></div>
<p>We then compare the compare the regression and Monte Carlo-based
methods by plotting the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation criterion. We continue with include a vertical line
corresponding to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
of the <code>MC_empirical</code> method to make the comparison
easier.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span></span>
<span><span class="co">#&gt;                        MSEv   Time</span></span>
<span><span class="co">#&gt; MC_independence      206.92   0.63</span></span>
<span><span class="co">#&gt; MC_empirical         179.43   3.35</span></span>
<span><span class="co">#&gt; MC_gaussian          235.15   0.47</span></span>
<span><span class="co">#&gt; MC_copula            237.35   0.53</span></span>
<span><span class="co">#&gt; MC_ctree             190.82   1.90</span></span>
<span><span class="co">#&gt; MC_vaeac             145.06 125.93</span></span>
<span><span class="co">#&gt; sep_lm               745.21   0.75</span></span>
<span><span class="co">#&gt; sep_pcr              784.91   0.88</span></span>
<span><span class="co">#&gt; sep_splines          165.13   0.89</span></span>
<span><span class="co">#&gt; sep_reicpe_example   687.45   1.25</span></span>
<span><span class="co">#&gt; sep_tree_stump       218.05   1.00</span></span>
<span><span class="co">#&gt; sep_tree_default     177.68   0.73</span></span>
<span><span class="co">#&gt; sep_tree_cv          222.71  12.35</span></span>
<span><span class="co">#&gt; sep_tree_cv_2        219.45  25.59</span></span>
<span><span class="co">#&gt; sep_rf               217.00   1.23</span></span>
<span><span class="co">#&gt; sep_rf_cv            212.64  30.98</span></span>
<span><span class="co">#&gt; sep_xgboost          197.72   0.86</span></span>
<span><span class="co">#&gt; sep_xgboost_cv       169.83  14.60</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_par   169.83  12.33</span></span>
<span><span class="co">#&gt; sep_xgboost_cv_2_par 153.13  13.99</span></span>
<span><span class="co">#&gt; sur_lm               649.61   0.42</span></span>
<span><span class="co">#&gt; sur_xgboost          169.92   0.44</span></span>
<span><span class="co">#&gt; sur_xgboost_cv       169.87   2.01</span></span>
<span><span class="co">#&gt; sur_rf               201.23   0.69</span></span>
<span><span class="co">#&gt; sur_rf_cv            172.09  27.44</span></span>
<span><span class="co">#&gt; sur_rf_cv_par        172.09  20.81</span></span>
<span><span class="co">#&gt; sep_ppr              327.23   0.76</span></span>
<span><span class="co">#&gt; sep_ppr_cv           246.28  10.24</span></span>
<span><span class="co">#&gt; sur_ppr              395.42   0.39</span></span>
<span><span class="co">#&gt; sur_ppr_cv           415.62   1.57</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="co"># Include vertical line corresponding to the MSEv of the MC_empirical method</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2FMSEv-sum-1.png"></p>
<p>The <code>vaeac</code> approach is the best-performing method
according to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation criterion, while the <code>sep_xgboost_cv_2_par</code> is the
best-performing regression-based method. However, we should note that
the <code>vaeac</code> method is much slower and that the difference
between the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
values is minuscule and inside the confidence intervals.</p>
<p>We can also order the methods to more easily look at the order of the
methods according to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
criterion.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">order</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list</span>, k <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, method_line <span class="op">=</span> <span class="st">"MC_empirical"</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2FMSEv-sum-2-1.png"></p>
<p>We can also examine the different Shapley value explanations for the
first six explicands (two at a time), and we still sort the methods from
best to worst. Most methods agree in the general directions, especially
for the most important features (the features with the largest absolute
Shapley values), but there are some differences for the less important
features. These tendencies/discrepancies are often more visible for the
methods with poor/larger
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
values.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2FSV-sum-1.png"></p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2FSV-sum-2.png"></p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">6</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2FSV-sum-3.png"></p>
<p>Here, we focus on the five best methods (and
<code>MC_empricial</code>) to make it easier to analyze the individual
Shapley value explanations, and we see a quite strong agreement between
the different methods.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Extract the 5 best methods (and empirical)</span></span>
<span><span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="st">"MC_empirical"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">best_methods</span><span class="op">)</span> <span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">best_methods</span>, <span class="st">"MC_empirical"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="va">best_methods</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<p><img src="figure_regression%2FSV-sum-2-1.png"></p>
</div>
<div class="section level2">
<h2 id="mixed">Mixed data<a class="anchor" aria-label="anchor" href="#mixed"></a>
</h2>
<p>In this section, we replicate and extend the mixed data example from
the general usage by demonstrating the separate and surrogate regression
methods. Of the Monte Carlo-based methods, only the
<code>independence</code> (not recommended), <code>ctree</code>, and
<code>vaeac</code> methods support mixed data. We can divide the
regression models into two groups based on whether the model can handle
categorical features by default or if we need to apply pre-processing of
the categorical features. By pre-processing, we mean that we need to
convert the categorical features into numerical values using, for
example, dummy features. We demonstrate this below using the
<code>regression.recipe_func</code> function.</p>
<div class="section level3">
<h3 id="mixed-data-setup">Mixed data: setup<a class="anchor" aria-label="anchor" href="#mixed-data-setup"></a>
</h3>
<p>First, we copy the setup from the general usage.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># convert the month variable to a factor</span></span>
<span><span class="va">data_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/data.table/man/copy.html" class="external-link">copy</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">[</span>, <span class="va">Month_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">Month</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">data_train_cat</span> <span class="op">&lt;-</span> <span class="va">data_cat</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span><span class="va">data_explain_cat</span> <span class="op">&lt;-</span> <span class="va">data_cat</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x_var_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month_factor"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_train_cat</span> <span class="op">&lt;-</span> <span class="va">data_train_cat</span><span class="op">[</span>, <span class="va">..x_var_cat</span><span class="op">]</span></span>
<span><span class="va">x_explain_cat</span> <span class="op">&lt;-</span> <span class="va">data_explain_cat</span><span class="op">[</span>, <span class="va">..x_var_cat</span><span class="op">]</span></span>
<span></span>
<span><span class="va">p0_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fitting an lm model here as xgboost does not handle categorical features directly</span></span>
<span><span class="va">formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">y_var</span>, <span class="st">" ~ "</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">x_var_cat</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">model_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">formula</span>, <span class="va">data_train_cat</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We could also consider other models such as random forest which supports mixed data</span></span>
<span><span class="co"># model_cat &lt;- ranger(formula, data_train_cat)</span></span>
<span></span>
<span><span class="co"># List to store the explanations for this mixed data setup</span></span>
<span><span class="va">explanation_list_mixed</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="mixed-data-monte-carlo-based-methods">Mixed data: Monte Carlo-based methods<a class="anchor" aria-label="anchor" href="#mixed-data-monte-carlo-based-methods"></a>
</h3>
<p>Second, we compute the explanations using the Monte Carlo-based
methods.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">MC_independence</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"independence"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:49:00 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: independence</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786590644b4.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">MC_ctree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"ctree"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:49:01 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: ctree</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786424cf108.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">MC_vaeac</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"vaeac"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:49:03 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: vaeac</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7865c8607f1.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="mixed-data-separate-regression-methods">Mixed data: separate regression methods<a class="anchor" aria-label="anchor" href="#mixed-data-separate-regression-methods"></a>
</h3>
<p>Third, we compute the Shapley value explanations using separate
regression methods. We use many of the same regression models as we did
above for the continuous data examples.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Standard linear regression</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:52:26 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7865611779c.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Linear regression where we have added splines to the numerical features</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_ns</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span>, deg_free <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:52:27 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78640377130.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Decision tree with default parameters</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_tree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:52:28 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7864f9416f9.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Use trees with cross-validation on the depth and cost complexity. Manually set the values.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:52:29 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78668483482.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Random forest with default hyperparameters. Do NOT need to use dummy features.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:52:55 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786c6b8fb0.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Random forest with cross validated hyperparameters.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/grid_regular.html" class="external-link">grid_regular</a></span><span class="op">(</span><span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/mtry.html" class="external-link">mtry</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, <span class="fu">dials</span><span class="fu">::</span><span class="fu"><a href="https://dials.tidymodels.org/reference/trees.html" class="external-link">trees</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>, levels <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span>    <span class="op">}</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:52:56 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786296095ce.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Xgboost with default hyperparameters, but we have to dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:53:36 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78654cd396d.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Xgboost with cross validated hyperparameters and we dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sep_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span>, <span class="fl">25</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:53:37 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78626ab5001.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="mixed-data-surrogate-regression-methods">Mixed data: surrogate regression methods<a class="anchor" aria-label="anchor" href="#mixed-data-surrogate-regression-methods"></a>
</h3>
<p>Fourth, we compute the Shapley value explanations using surrogate
regression methods. We use the same regression models as we did above
for separate regression method class.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Standard linear regression</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:03:49 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f66caf9e9.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Linear regression where we have added splines to the numerical features</span></span>
<span><span class="co"># NOTE, that we remove the augmented mask variables to avoid a rank-deficient fit</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_ns</span><span class="op">(</span><span class="va">recipe</span>, <span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">starts_with</span><span class="op">(</span><span class="st">"mask_"</span><span class="op">)</span>, deg_free <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:03:50 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f28c0612c.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Decision tree with default parameters</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_tree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"rpart"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:03:51 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345ff402e18.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Use trees with cross-validation on the depth and cost complexity. Manually set the values.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="external-link">decision_tree</a></span><span class="op">(</span></span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    cost_complexity <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"rpart"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, cost_complexity <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:03:51 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f159364cb.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Random forest with default hyperparameters. Do NOT need to use dummy features.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:03:53 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f15d81edf.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Random forest with cross validated hyperparameters.</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="external-link">rand_forest</a></span><span class="op">(</span></span>
<span>    mtry <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>, engine <span class="op">=</span> <span class="st">"ranger"</span>, mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>mtry <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span>, trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">250</span>, <span class="fl">500</span>, <span class="fl">750</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:03:54 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f5bb38b48.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Xgboost with default hyperparameters, but we have to dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_xgboost</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span>engine <span class="op">=</span> <span class="st">"xgboost"</span>, mode <span class="op">=</span> <span class="st">"regression"</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:04:09 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f7f5cabf0.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Xgboost with cross validated hyperparameters and we dummy encode the factors</span></span>
<span><span class="va">explanation_list_mixed</span><span class="op">$</span><span class="va">sur_xgboost_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/boost_tree.html" class="external-link">boost_tree</a></span><span class="op">(</span></span>
<span>    trees <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    tree_depth <span class="op">=</span> <span class="fu">hardhat</span><span class="fu">::</span><span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html" class="external-link">tune</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    engine <span class="op">=</span> <span class="st">"xgboost"</span>,</span>
<span>    mode <span class="op">=</span> <span class="st">"regression"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">regression_recipe</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu">step_dummy</span><span class="op">(</span><span class="va">regression_recipe</span>, <span class="fu">all_factor_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html" class="external-link">expand.grid</a></span><span class="op">(</span>trees <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">15</span>, <span class="fl">25</span><span class="op">)</span>, tree_depth <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 23:04:10 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;lm&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmppO00aE/shapr_obj_1c345f339560be.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="summary_mixed">Mixed data: summary<a class="anchor" aria-label="anchor" href="#summary_mixed"></a>
</h3>
<p>Fifth, and finally, we compare the results. The surrogate random
forest model performs well and outperforms the cross-validated version,
but note the wide confidence interval. We see that several of the
regression-based methods outperform the Monte Carlo-based methods. More
specifically, three separate regression methods and three surrogate
regression methods.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Print the MSEv scores and the elapsed time (in seconds) for the different methods</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">)</span></span>
<span><span class="co">#&gt;                   MSEv   Time</span></span>
<span><span class="co">#&gt; MC_independence 641.82   0.86</span></span>
<span><span class="co">#&gt; MC_ctree        555.58   1.74</span></span>
<span><span class="co">#&gt; MC_vaeac        629.56 202.40</span></span>
<span><span class="co">#&gt; sep_lm          550.06   1.19</span></span>
<span><span class="co">#&gt; sep_splines     541.36   0.91</span></span>
<span><span class="co">#&gt; sep_tree        753.84   0.78</span></span>
<span><span class="co">#&gt; sep_tree_cv     756.27  26.22</span></span>
<span><span class="co">#&gt; sep_rf          518.27   1.18</span></span>
<span><span class="co">#&gt; sep_rf_cv       619.81  40.17</span></span>
<span><span class="co">#&gt; sep_xgboost     792.17   1.05</span></span>
<span><span class="co">#&gt; sep_xgboost_cv  595.98  18.70</span></span>
<span><span class="co">#&gt; sur_lm          610.61   0.45</span></span>
<span><span class="co">#&gt; sur_splines     596.86   0.43</span></span>
<span><span class="co">#&gt; sur_tree        677.04   0.47</span></span>
<span><span class="co">#&gt; sur_tree_cv     789.37   2.40</span></span>
<span><span class="co">#&gt; sur_rf          407.76   0.76</span></span>
<span><span class="co">#&gt; sur_rf_cv       520.63  15.18</span></span>
<span><span class="co">#&gt; sur_xgboost     606.92   0.47</span></span>
<span><span class="co">#&gt; sur_xgboost_cv  429.06   2.08</span></span>
<span></span>
<span><span class="co"># Compare the MSEv criterion of the different explanation methods</span></span>
<span><span class="co"># Include vertical line corresponding to the MSEv of the empirical method.</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list_mixed</span>, method_line <span class="op">=</span> <span class="st">"MC_ctree"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in MSEv_check_explanation_list(explanation_list): The object/objects 'sur_lm', 'sur_splines', 'sur_tree', 'sur_tree_cv', 'sur_rf', 'sur_rf_cv', 'sur_xgboost', 'sur_xgboost_cv' in `explanation_list` has/have a different `x_explain` than 'MC_independence'. Cannot compare them.</span></span></code></pre></div>
<p>The best-performing methods are the surrogate random forest and
xgboost with cross-validation methods. The Monte Carlo-based methods
perform worse, with <code>ctree</code> being the best, with a
seventh-place overall ranking.</p>
<p>We can also order the methods to more easily look at the order of the
methods according to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
criterion.</p>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">order</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list_mixed</span>, k <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu">plot_MSEv_scores</span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, method_line <span class="op">=</span> <span class="st">"MC_ctree"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in MSEv_check_explanation_list(explanation_list): The object/objects 'sep_rf', 'sep_splines', 'sep_lm', 'MC_ctree', 'sep_xgboost_cv', 'sep_rf_cv', 'MC_vaeac', 'MC_independence', 'sep_tree', 'sep_tree_cv', 'sep_xgboost' in `explanation_list` has/have a different `x_explain` than 'sur_rf'. Cannot compare them.</span></span></code></pre></div>
<p>We also look at some of the Shapley value explanations and see that
many methods produce similar explanations.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">[</span><span class="va">order</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, facet_ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in plot_SV_several_approaches(explanation_list_mixed[order], index_explicands = c(1, : The object/objects 'sep_rf', 'sep_splines', 'sep_lm', 'MC_ctree', 'sep_xgboost_cv', 'sep_rf_cv', 'MC_vaeac', 'MC_independence', 'sep_tree', 'sep_tree_cv', 'sep_xgboost' in `explanation_list` has/have a different `x_explain` than 'sur_rf'. Cannot compare them.</span></span></code></pre></div>
<p>We can also focus on the Shapley value explanations for the best five
methods according to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
criterion. We also include the <code>ctree</code> method, the
best-performing Monte Carlo-based method.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu">get_k_best_methods</span><span class="op">(</span><span class="va">explanation_list_mixed</span>, k <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="st">"MC_ctree"</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="va">best_methods</span><span class="op">)</span> <span class="va">best_methods</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">best_methods</span>, <span class="st">"MC_ctree"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/plot_SV_several_approaches.html">plot_SV_several_approaches</a></span><span class="op">(</span><span class="va">explanation_list_mixed</span><span class="op">[</span><span class="va">best_methods</span><span class="op">]</span>, index_explicands <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="co">#&gt; Error in plot_SV_several_approaches(explanation_list_mixed[best_methods], : The object/objects 'sep_rf', 'sep_splines', 'MC_ctree' in `explanation_list` has/have a different `x_explain` than 'sur_rf'. Cannot compare them.</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="regression-arguments-as-strings">Regression arguments as strings<a class="anchor" aria-label="anchor" href="#regression-arguments-as-strings"></a>
</h2>
<p>In this section, we demonstrate that the
<code>regression.model</code>, <code>regression.tune_values</code>, and
<code>regression.recipe_func</code> parameters can be provided as
strings. This is a property which is convenient if the
<code><a href="../reference/explain.html">explain()</a></code> function is called from Python through the
associated <code>shaprpy</code> Python library. That is, the user only
has to specify strings containing R code instead of having to deal with
creating the R objects in Python. In the code chunk below, we see that
we obtain identical
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
scores for the string and non-string versions.</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_list_str</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::linear_reg()"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:54:19 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7868fc9a14.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_pcr</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::linear_reg()"</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="st">"function(regression_recipe) {</span></span>
<span><span class="st">    return(recipes::step_pca(regression_recipe, recipes::all_numeric_predictors(), num_comp = 2))</span></span>
<span><span class="st">  }"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:54:20 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa786726ad1cd.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_splines</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="fu">parsnip</span><span class="fu">::</span><span class="fu"><a href="https://parsnip.tidymodels.org/reference/linear_reg.html" class="external-link">linear_reg</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  regression.recipe_func <span class="op">=</span> <span class="st">"function(regression_recipe) {</span></span>
<span><span class="st">    return(recipes::step_ns(regression_recipe, recipes::all_numeric_predictors(), deg_free = 2))</span></span>
<span><span class="st">  }"</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:54:20 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78619d633f2.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_tree_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::decision_tree(</span></span>
<span><span class="st">    tree_depth = hardhat::tune(), engine = 'rpart', mode = 'regression'</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="st">"dials::grid_regular(dials::tree_depth(), levels = 4)"</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:54:21 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa78654748ae9.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation</span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sep_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_separate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::rand_forest(</span></span>
<span><span class="st">    mtry = hardhat::tune(), trees = hardhat::tune(), engine = 'ranger', mode = 'regression'</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.tune_values <span class="op">=</span></span>
<span>    <span class="st">"function(x) {</span></span>
<span><span class="st">      dials::grid_regular(dials::mtry(c(1, ncol(x))), dials::trees(c(50, 750)), levels = 3)</span></span>
<span><span class="st">    }"</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:54:34 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_separate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7864275697e.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># Using random forest with parameters tuned by cross-validation as the surrogate model</span></span>
<span><span class="va">explanation_list_str</span><span class="op">$</span><span class="va">sur_rf_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  phi0 <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"regression_surrogate"</span>,</span>
<span>  regression.model <span class="op">=</span> <span class="st">"parsnip::rand_forest(</span></span>
<span><span class="st">    mtry = hardhat::tune(), trees = hardhat::tune(), engine = 'ranger', mode = 'regression'</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.tune_values <span class="op">=</span> <span class="st">"dials::grid_regular(</span></span>
<span><span class="st">    dials::mtry(c(1, ncol(x_explain))),</span></span>
<span><span class="st">    dials::trees(c(50, 750)),</span></span>
<span><span class="st">    levels = 6</span></span>
<span><span class="st">  )"</span>,</span>
<span>  regression.vfold_cv_para <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: Feature classes extracted from the model contains NA.</span></span>
<span><span class="co">#&gt; Assuming feature classes from the data are correct.</span></span>
<span><span class="co">#&gt; Success with message:</span></span>
<span><span class="co">#&gt; max_n_coalitions is NULL or larger than or 2^n_features = 16, </span></span>
<span><span class="co">#&gt; and is therefore set to 2^n_features = 16.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Starting `shapr::explain()` at 2024-11-21 13:55:05 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; ‚Ä¢ Model class: &lt;xgb.Booster&gt;</span></span>
<span><span class="co">#&gt; ‚Ä¢ Approach: regression_surrogate</span></span>
<span><span class="co">#&gt; ‚Ä¢ Iterative estimation: FALSE</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of feature-wise Shapley values: 4</span></span>
<span><span class="co">#&gt; ‚Ä¢ Number of observations to explain: 20</span></span>
<span><span class="co">#&gt; ‚Ä¢ Computations (temporary) saved at: '/tmp/RtmpgQii3E/shapr_obj_1aa7867814a029.rds'</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ‚Ñπ Using 16 of 16 coalitions.</span></span>
<span></span>
<span><span class="co"># See that the evaluation scores match the non-string versions.</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list_str</span><span class="op">)</span></span>
<span><span class="co">#&gt;               MSEv  Time</span></span>
<span><span class="co">#&gt; sep_lm      745.21  0.70</span></span>
<span><span class="co">#&gt; sep_pcr     784.91  0.92</span></span>
<span><span class="co">#&gt; sep_splines 165.13  0.92</span></span>
<span><span class="co">#&gt; sep_tree_cv 222.71 12.96</span></span>
<span><span class="co">#&gt; sep_rf_cv   212.64 30.79</span></span>
<span><span class="co">#&gt; sur_rf_cv   172.09 26.96</span></span>
<span><span class="fu">print_MSEv_scores_and_time</span><span class="op">(</span><span class="va">explanation_list</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">explanation_list_str</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;               MSEv  Time</span></span>
<span><span class="co">#&gt; sep_lm      745.21  0.75</span></span>
<span><span class="co">#&gt; sep_pcr     784.91  0.88</span></span>
<span><span class="co">#&gt; sep_splines 165.13  0.89</span></span>
<span><span class="co">#&gt; sep_tree_cv 222.71 12.35</span></span>
<span><span class="co">#&gt; sep_rf_cv   212.64 30.98</span></span>
<span><span class="co">#&gt; sur_rf_cv   172.09 27.44</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<p>This vignette demonstrates the rich possibilities that the regression
paradigm and the <code>tidymodels</code> framework add to the
<code>shapr</code> package. We have seen that regression-based methods
are on par with or outperform the Monte Carlo-based methods regarding
the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>MSE</mo><mi>v</mi></msub><annotation encoding="application/x-tex">\operatorname{MSE}_v</annotation></semantics></math>
evaluation criterion. Furthermore, we have seen that the
regression-based methods are relatively computationally fast and that
parallelization can be used to speed up the computations.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-tidymodels" class="csl-entry">
Kuhn, Max, and Hadley Wickham. 2020. <em>Tidymodels: A Collection of
Packages for Modeling and Machine Learning Using Tidyverse
Principles.</em> <a href="https://www.tidymodels.org" class="external-link">https://www.tidymodels.org</a>.
</div>
<div id="ref-olsen2024comparative" class="csl-entry">
Olsen, Lars Henry Berge, Ingrid Kristine Glad, Martin Jullum, and
Kjersti Aas. 2024. <span>‚ÄúA Comparative Study of Methods for Estimating
Model-Agnostic Shapley Value Explanations.‚Äù</span> <em>Data Mining and
Knowledge Discovery</em>, 1‚Äì48.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Martin Jullum, Lars Henry Berge Olsen, Annabelle Redelmeier, Jon Lachmann, Nikolai Sellereite, Norsk Regnesentral.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
