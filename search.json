[{"path":"https://norskregnesentral.github.io/shapr/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (https://www.contributor-covenant.org), version 1.0.0, available https://contributor-covenant.org/version/1/0/0/.","code":""},{"path":"https://norskregnesentral.github.io/shapr/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to shapr","title":"Contributing to shapr","text":"outlines propose change shapr.","code":""},{"path":"https://norskregnesentral.github.io/shapr/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to shapr","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES: edit roxygen comment .R file R/. : edit .Rd file man/.","code":""},{"path":"https://norskregnesentral.github.io/shapr/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"Contributing to shapr","text":"make substantial pull request, always file issue make sure someone team agrees ‚Äôs problem. ‚Äôve found bug, create associated issue illustrate bug minimal reprex.","code":""},{"path":"https://norskregnesentral.github.io/shapr/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"","what":"Pull request process","title":"Contributing to shapr","text":"recommend create Git branch pull request (PR). Look CircleCI build status making changes. README contain badges continuous integration services used package. New code follow tidyverse style guide. can use styler package apply styles, please don‚Äôt restyle code nothing PR. use roxygen2 documentation. use testthat. Contributions test cases included easier accept. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://norskregnesentral.github.io/shapr/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to shapr","text":"Please note shapr project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://norskregnesentral.github.io/shapr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2019 Norsk Regnesentral Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"Vignette","dir":"Articles","previous_headings":"","what":"Overview","title":"Asymmetric and causal Shapley value explanations","text":"vignette elaborates demonstrates asymmetric causal Shapley value frameworks introduced Frye, Rowat, Feige (2020) Heskes et al. (2020), respectively. also consider marginal conditional Shapley value frameworks, see Lundberg Lee (2017) Aas, Jullum, L√∏land (2021), respectively. demonstrate frameworks bike sharing dataset UCI Machine Learning Repository. setup based CauSHAPley package, code supplement Heskes et al. (2020) paper. CauSHAPley package based old version shapr restricted gaussian approach (see section 6 Heskes et al. (2020) details). extended causal Shapley value framework work Monte Carlo-based approaches (independence (recommended), empirical, gaussian, copula, ctree, vaeac categorical), extension asymmetric Shapley value framework works Monte Carlo regression-based approaches. generalization uttermost importance, many real-world data sets far Gaussian distribution, , compared CauSHAPley, implementation can utilize shapr‚Äôs new features, batch computation, parallelization iterative computation feature-wise group-wise Shapley values. main differences marginal, conditional, causal Shapley value frameworks sample/generate Monte Carlo samples marginal distribution, (conventional) observational conditional distribution, interventional conditional distribution, respectively. Asymmetric means consider possible coalitions, rather coalitions respect causal ordering.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"AsymSV","dir":"Articles","previous_headings":"","what":"Asymmetric conditional Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"Asymmetric (conditional) Shapley values proposed Frye, Rowat, Feige (2020) way incorporate causal knowledge real world computing Shapley value explanations using feature combinations/coalitions consistent (partial) causal ordering. See figure schematic overview causal ordering going use examples vignette. figure, see causal ordering consists three components: œÑ1={X1}\\tau_1 = \\{X_1\\}, œÑ2={X2,X3}\\tau_2 = \\{X_2, X_3\\}, œÑ3={X4,X5,X6,X7}\\tau_3 = \\{X_4, X_5, X_6, X_7\\}. See code section features represent. elaborate, instead considering 2M2^M possible coalitions, MM number features, asymmetric Shapley values consider subset coalitions respects causal ordering. causal ordering, means asymmetric Shapley value explanation framework skips coalitions X2X_2 included X1X_1, X1X_1 ancestor X2X_2. skew explanations towards distal/root causes, see Section 3.2 Frye, Rowat, Feige (2020). can use approaches shapr, Monte Carlo-based regression-based methods, compute asymmetric Shapley values. asymmetric Shapley value explanation framework change compute contribution functions v(S)v(S), rather coalitions SS used compute Shapley value explanations. means number coalitions longer O(2M)O(2^M), rather O(2œÑ0)O(2^{\\tau_0}), œÑ0=maxi|œÑi|\\tau_0 = \\operatorname{max}_i |\\tau_i| number features (|œÑi||\\tau_i|) largest component causal ordering. Furthermore, asymmetric Shapley values support groups features, causal ordering must given group level instead feature level. asymmetric Shapley value framework also supports sampling coalitions sampling done set coalitions respect causal ordering. Finally, remark asymmetric conditional Shapley values equivalent asymmetric causal Shapley values (see ) use coalitions respecting causal ordering assuming dependencies within chain components induced mutual interactions. Schematic overview causal ordering used vignette.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"CausSV","dir":"Articles","previous_headings":"","what":"Causal Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"Causal Shapley values proposed Heskes et al. (2020) way explain total effect features prediction taking account causal relationships adapting sampling procedure shapr. precisely, propose employ Pearl‚Äôs -calculus circumvent independence assumption, made Lundberg Lee (2017), without sacrificing desirable properties Shapley value framework. causal Shapley value explanation framework can also separate contribution direct indirect effects, makes principally different marginal conditional Shapley values. framework also provides direct robust way incorporate causal knowledge, compared asymmetric Shapley value explanation framework. compute causal Shapley values, specify (partial) causal ordering make assumption confounding component. Together, form causal chain graph contains directed undirected edges. features treated equal footing linked together undirected edges become part chain component. Edges chain components directed represent causal relationships. figure , causal ordering , addition made assumption confounding second component, confounding first third components. allows us correctly distinguish dependencies due confounding mutual interactions. , figure, dependencies chain component œÑ2\\tau_2 assumed result common confounder, œÑ3\\tau_3 mutual interactions, mutual interactions œÑ1\\tau_1 singleton. Computing effect intervention depends interpret generative process leads feature dependencies within component. result marginalizing common confounder, intervention particular feature break dependency features, denote set chain components ùíØconfounding\\mathcal{T}_{\\text{confounding}}. components mutual feature interactions, setting value feature affects distribution variables within component. denote set components ùíØconfounding¬Ø\\mathcal{T}_{\\,\\overline{\\text{confounding}}}. Heskes et al. (2020) described expectation intervention needed compute causal Shapley values can translated expectation observation, using interventional formula causal chain graphs: P(XùíÆ‚Äæ‚à£(XùíÆ=xùíÆ))=‚àèœÑ‚ààùíØconfoundingP(XœÑ‚à©ùíÆ‚Äæ‚à£Xpa(œÑ)‚à©ùíÆ‚Äæ,xpa(œÑ)‚à©ùíÆ)√ó‚àèœÑ‚ààùíØconfounding¬ØP(XœÑ‚à©ùíÆ‚Äæ‚à£Xpa(œÑ)‚à©ùíÆ‚Äæ,xpa(œÑ)‚à©ùíÆ,xœÑ‚à©ùíÆ).\\begin{align} \\label{eq:} P(X_{\\bar{\\mathcal{S}}} \\mid (X_\\mathcal{S} = x_\\mathcal{S})) = & \\prod_{\\tau \\\\mathcal{T}_{\\,\\text{confounding}}} P(X_{\\tau \\cap \\bar{\\mathcal{S}}} \\mid X_{\\text{pa}(\\tau) \\cap \\bar{\\mathcal{S}}}, x_{\\text{pa}(\\tau) \\cap \\mathcal{S}}) \\times \\tag{1} \\\\ & \\quad \\prod_{\\tau \\\\mathcal{T}_{\\,\\overline{\\text{confounding}}}} P(X_{\\tau \\cap \\bar{\\mathcal{S}}} \\mid X_{\\text{pa}(\\tau) \\cap \\bar{\\mathcal{S}}}, x_{\\text{pa}(\\tau) \\cap \\mathcal{S}}, x_{\\tau \\cap \\mathcal{S}}). \\end{align} , Monte Carlo-based approaches shapr can used compute conditional distributions/observational expectations. marginals estimated training data approaches except gaussian, use marginals Gaussian distribution instead. specific causal chain graphs, causal Shapley value framework simplifies symmetric conditional, asymmetric conditional, marginal Shapley values; see Corollaries 1 3 supplement Heskes et al. (2020). Schematic overview causal chain graph used vignette.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"MarginaSV","dir":"Articles","previous_headings":"","what":"Marginal Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"Causal Shapley values equivalent marginal Shapley values MM features combined single component œÑ=‚Ñ≥={1,2,...,M}\\tau = \\mathcal{M} = \\{1,2,...,M\\} dependencies induced confounding. pa(œÑ)=‚àÖ\\text{pa}(\\tau) = \\emptyset, P(XùíÆ‚Äæ‚à£(XùíÆ=xùíÆ))P(X_{\\bar{\\mathcal{S}}} \\mid (X_\\mathcal{S} = x_\\mathcal{S})) Equation () simplifies P(XùíÆ‚Äæ‚à£(XùíÆ=xùíÆ))=P(XùíÆ‚Äæ)P(X_{\\bar{\\mathcal{S}}} \\mid (X_\\mathcal{S} = x_\\mathcal{S})) = P(X_{\\bar{\\mathcal{S}}}), specified Lundberg Lee (2017). Monte Carlo samples marginals generated sampling training data, except gaussian approach use marginals estimated multivariate Gaussian distribution. means approaches, using independence approach conditional Shapley value explanation framework.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"ConditionalSV","dir":"Articles","previous_headings":"","what":"Symmetric conditional Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"Causal Shapley values equivalent symmetric conditional Shapley values MM features combined single component œÑ=‚Ñ≥={1,2,...,M}\\tau = \\mathcal{M} = \\{1,2,...,M\\} dependencies induced mutual interaction. pa(œÑ)=‚àÖ\\text{pa}(\\tau) = \\emptyset, P(XùíÆ‚Äæ‚à£(XùíÆ=xùíÆ))P(X_{\\bar{\\mathcal{S}}} \\mid (X_\\mathcal{S} = x_\\mathcal{S})) Equation () simplifies P(XùíÆ‚Äæ‚à£(XùíÆ=xùíÆ))=P(XùíÆ‚Äæ‚à£XùíÆ=xùíÆ)P(X_{\\bar{\\mathcal{S}}} \\mid (X_\\mathcal{S} = x_\\mathcal{S})) = P(X_{\\bar{\\mathcal{S}}} \\mid X_\\mathcal{S} = x_\\mathcal{S}), specified Aas, Jullum, L√∏land (2021). Symmetric means consider coalitions.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"overview","dir":"Articles","previous_headings":"Code example","what":"Overview","title":"Asymmetric and causal Shapley value explanations","text":"demonstrate frameworks bike sharing dataset UCI Machine Learning Repository. let features number days since January 2011 (trend), two cyclical variables representing season (cosyear, sinyear), temperature (temp), feeling temperature (atemp), wind speed (windspeed), humidity (hum). first three features considered potential cause four weather-related features. bike rental strongly seasonal shows upward trend, illustrated figure . bike data split randomly training (80%) test/explicand (20%) set. train XGBoost model 100 rounds default hyperparameters act model want explain. table , highlight Shapley value explanation frameworks introduced access changing arguments asymmetric, ordering, confounding shapr::explain(). Note symmetric conditional Shapley values default version; .e., default asymmetric = FALSE, ordering = NULL, confounding = NULL.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"code-setup","dir":"Articles","previous_headings":"Code example","what":"Code setup","title":"Asymmetric and causal Shapley value explanations","text":"First, load needed libraries, set training/explicand data, plot data, train xgboost model.    going use causal_ordering confounding illustrated figures . causal_ordering, can either provide index feature feature names. Thus, following two versions causal_ordering produce equivalent results. Furthermore, assume confounding second component (.e., season effect weather) confounding third component (.e., know model intricate relations weather features). make rest vignette easier follow, create helper functions plot summarize results explanation methods. code block optional understand can skipped.","code":"library(ggplot2) library(xgboost) library(data.table) library(shapr)  # Additional packages which are only used for plotting in this vignette. # These are not listed as dependencies in shapr library(GGally) library(ggpubr) library(gridExtra)    # Ensure that shapr's functions are prioritized; otherwise, we need to use the `shapr::` # prefix when calling explain(). The `conflicted` package is imported by `tidymodels`. conflicted::conflicts_prefer(shapr::explain, shapr::prepare_data) # Set up the data # Can also download the data set from the source https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset # temp <- tempfile() # download.file(\"https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\", temp) # bike <- read.csv(unz(temp, \"day.csv\")) # unlink(temp) bike <- read.csv(\"../inst/extdata/day.csv\") # Difference in days, which takes DST into account bike$trend <- as.numeric(difftime(bike$dteday, bike$dteday[1], units = \"days\")) bike$cosyear <- cospi(bike$trend / 365 * 2) bike$sinyear <- sinpi(bike$trend / 365 * 2) # Unnormalize variables (see data set information in link above) bike$temp <- bike$temp * (39 - (-8)) + (-8) bike$atemp <- bike$atemp * (50 - (-16)) + (-16) bike$windspeed <- 67 * bike$windspeed bike$hum <- 100 * bike$hum  # Plot the data ggplot(bike, aes(x = trend, y = cnt, color = temp)) +   geom_point(size = 0.75) +   scale_color_gradient(low = \"blue\", high = \"red\") +   labs(colour = \"temp\") +   xlab(\"Days since 1 January 2011\") +   ylab(\"Number of bikes rented\") +   theme_minimal() +   theme(legend.position = \"right\", legend.title = element_text(size = 10)) # Define the features and the response variable x_var <- c(\"trend\", \"cosyear\", \"sinyear\", \"temp\", \"atemp\", \"windspeed\", \"hum\") y_var <- \"cnt\"  # NOTE: To avoid RNG reproducibility issues across different systems, we # load the training-test split from a file. 80% training and 20% test train_index <- readRDS(\"../inst/extdata/train_index.rds\")  # Training data x_train <- as.matrix(bike[train_index, x_var]) y_train_nc <- as.matrix(bike[train_index, y_var]) # not centered y_train <- y_train_nc - mean(y_train_nc)  # Plot pairs plot GGally::ggpairs(x_train) # Test/explicand data x_explain <- as.matrix(bike[-train_index, x_var]) y_explain_nc <- as.matrix(bike[-train_index, y_var]) # not centered y_explain <- y_explain_nc - mean(y_train_nc)  # Get 6 explicands to plot the Shapley values for, with a wide spread in their predicted outcomes n_index_x_explain <- 6 index_x_explain <- order(y_explain)[seq(1, length(y_explain), length.out = n_index_x_explain)] y_explain[index_x_explain] #> [1] -3900.03 -1872.03  -377.03   411.97  1690.97  3889.97  # Fit an XGBoost model to the training data model <- xgboost::xgboost(   data = x_train,   label = y_train,   nround = 100,   verbose = FALSE )  # Save the phi0 phi0 <- mean(y_train)  # Look at the root mean squared error sqrt(mean((predict(model, x_explain) - y_explain)^2)) #> [1] 798.71 ggplot(   data.table(\"response\" = y_explain[, 1], \"predicted_response\" = predict(model, x_explain)),   aes(response, predicted_response) ) +   geom_point() causal_ordering <- list(1, c(2, 3), c(4:7)) causal_ordering <- list(\"trend\", c(\"cosyear\", \"sinyear\"), c(\"temp\", \"atemp\", \"windspeed\", \"hum\")) confounding <- c(FALSE, TRUE, FALSE) # Extract the MSEv criterion scores and elapsed times print_MSEv_scores_and_time <- function(explanation_list) {   res <- as.data.frame(t(sapply(     explanation_list,     function(explanation) {       round(c(         explanation$MSEv$MSEv$MSEv,         explanation$MSEv$MSEv$MSEv_sd,         explanation$timing$summary$total_time_secs       ), 2)     }   )))   colnames(res) <- c(\"MSEv\", \"MSEv_sd\", \"Time (secs)\")   return(res) }  # Print the full time information print_time <- function(explanation_list) {   t(sapply(explanation_list, function(explanation) explanation$timing$summary$total_time_secs)) }  # Make beeswarm plots plot_beeswarms <- function(explanation_list, title = \"\", ...) {   # Make the beeswarm plots   grobs <- lapply(seq(length(explanation_list)), function(explanation_idx) {     gg <- plot(explanation_list[[explanation_idx]], plot_type = \"beeswarm\", ...) +       ggplot2::ggtitle(tools::toTitleCase(gsub(\"_\", \" \", names(explanation_list)[[explanation_idx]])))    # Flip the order such that the features come in the right order     gg <- gg +       ggplot2::scale_x_discrete(limits = rev(levels(gg$data$variable)[levels(gg$data$variable) != \"none\"]))   })    # Get the limits   ylim <- sapply(grobs, function(grob) ggplot2::ggplot_build(grob)$layout$panel_scales_y[[1]]$range$range)   ylim <- c(min(ylim), max(ylim))    # Update the limits   grobs <- suppressMessages(lapply(grobs, function(grob) grob + ggplot2::coord_flip(ylim = ylim)))    # Make the combined plot   gridExtra::grid.arrange(     grobs = grobs, ncol = 1,     top = grid::textGrob(title, gp = grid::gpar(fontsize = 18, font = 8))   ) }"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"symmetric-conditional-shapley-values-default","dir":"Articles","previous_headings":"Code example","what":"Symmetric conditional Shapley values (default)","title":"Asymmetric and causal Shapley value explanations","text":"start demonstrating compute symmetric conditional Shapley values. default version shapr need specify arguments . However, specified sake clarity. use gaussian, ctree, regression_separate(xgboost default hyperparameters) approaches, approach can also used. can look MSEv\\operatorname{MSE}_v evaluation scores compare approaches. approaches comparable, xgboost clearly fastest approach. can plot Shapley values six explicands chosen .  can also make beeswarm plots Shapley values look structure Shapley values explicands. figures quite similar, minor differences. E.g., gaussian approach produces almost Shapley values around 500500 trend feature.","code":"# list to store the results explanation_sym_con <- list()  explanation_sym_con[[\"gaussian\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   approach = \"gaussian\",   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   asymmetric = FALSE, # Default value (TRUE will give the same since `causal_ordering = NULL`)   causal_ordering = NULL, # Default value   confounding = NULL # Default value ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:58:53 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 7 #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de48d3994d.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 46 of 128 coalitions, 20 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 68 of 128 coalitions, 22 new.  explanation_sym_con[[\"ctree\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   approach = \"ctree\",   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   asymmetric = FALSE, # Default value (TRUE will give the same since `causal_ordering = NULL`)   causal_ordering = NULL, # Default value   confounding = NULL # Default value ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:59:03 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de704ccb45.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 46 of 128 coalitions, 20 new.  #>  #> ‚îÄ‚îÄ Iteration 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 70 of 128 coalitions, 24 new.  #>  #> ‚îÄ‚îÄ Iteration 5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 94 of 128 coalitions, 24 new.  #>  #> ‚îÄ‚îÄ Iteration 6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 110 of 128 coalitions, 16 new.  explanation_sym_con[[\"xgboost\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::boost_tree(engine = \"xgboost\", mode = \"regression\"),   asymmetric = FALSE, # Default value (TRUE will give the same as `causal_ordering = NULL`)   causal_ordering = NULL, # Default value   confounding = NULL # Default value ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:59:54 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de7060ae26.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 46 of 128 coalitions, 20 new.  #>  #> ‚îÄ‚îÄ Iteration 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 70 of 128 coalitions, 24 new.  #>  #> ‚îÄ‚îÄ Iteration 5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 94 of 128 coalitions, 24 new.  #>  #> ‚îÄ‚îÄ Iteration 6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 110 of 128 coalitions, 16 new.  #>  #> ‚îÄ‚îÄ Iteration 7 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 118 of 128 coalitions, 8 new. print_MSEv_scores_and_time(explanation_sym_con) #>             MSEv MSEv_sd Time (secs) #> gaussian 1076528   75021        9.95 #> ctree    1044396   66196       51.09 #> xgboost  1086792   62794       17.41 plot_SV_several_approaches(explanation_sym_con, index_x_explain) +   theme(legend.position = \"bottom\") plot_beeswarms(explanation_sym_con, title = \"Symmetric conditional Shapley values\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"asymmetric-conditional-shapley-values","dir":"Articles","previous_headings":"Code example","what":"Asymmetric conditional Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"look asymmetric conditional Shapley values. obtain types Shapley values, specify asymmetric = TRUE causal_ordering. use causal_ordering = list(1, c(2, 3), c(4:7)). asymmetric conditional Shapley value framework faster consider 2020 coalitions (including empty grand coalitions) instead 128128 coalitions (see code ). can look beeswarm plots asymmetric conditional Shapley values. ctree xgboost approaches produce similar figures, gaussian approach shrinks groups Shapley values trend feature, produces negative values cosyear feature. going symmetric asymmetric Shapley values, see many features‚Äô Shapley values now shrunk closer zero, especially temp atemp.  can also compare obtained symmetric asymmetric conditional Shapley values 6 explicands. often see asymmetric version gives larger Shapley values distal/root causes, .e., trend cosyear, symmetric version. line Section 3.2 Frye, Rowat, Feige (2020).","code":"explanation_asym_con <- list()  explanation_asym_con[[\"gaussian\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"gaussian\",   asymmetric = TRUE,   causal_ordering = causal_ordering,   confounding = NULL # Default value ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 7 #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Number of asymmetric coalitions: 20 #>  #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de234a7543.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 13 of 20 coalitions, 13 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 20 of 20 coalitions, 7 new.  explanation_asym_con[[\"gaussian_non_iterative\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"gaussian\",   asymmetric = TRUE,   causal_ordering = causal_ordering,   confounding = NULL, # Default value   iterative = FALSE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:16 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 20 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de72d8d627.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 20 of 20 coalitions.  explanation_asym_con[[\"ctree\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"ctree\",   asymmetric = TRUE,   causal_ordering = causal_ordering,   confounding = NULL # Default value ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:18 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 20 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de6ec09445.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 13 of 20 coalitions, 13 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 20 of 20 coalitions, 7 new.  explanation_asym_con[[\"xgboost\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::boost_tree(engine = \"xgboost\", mode = \"regression\"),   asymmetric = TRUE,   causal_ordering = causal_ordering,   confounding = NULL # Default value ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:28 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 20 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de7e69f7e3.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 13 of 20 coalitions, 13 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 20 of 20 coalitions, 7 new. print_MSEv_scores_and_time(explanation_asym_con) #>                          MSEv MSEv_sd Time (secs) #> gaussian               306849   35460        3.25 #> gaussian_non_iterative 306458   35412        1.73 #> ctree                  270172   31527       10.31 #> xgboost                304617   35310        2.27  # Look at the number of coalitions considered. Decreased from 128 to 20. explanation_sym_con$gaussian$internal$parameters$max_n_coalitions #> [1] 128 explanation_asym_con$gaussian$internal$parameters$max_n_coalitions #> [1] 20  # Here we can see the 20 coalitions that respect the causal ordering explanation_asym_con$gaussian$internal$objects$dt_valid_causal_coalitions[[\"coalitions\"]] #> [[1]] #> integer(0) #>  #> [[2]] #> [1] 1 #>  #> [[3]] #> [1] 1 2 #>  #> [[4]] #> [1] 1 3 #>  #> [[5]] #> [1] 1 2 3 #>  #> [[6]] #> [1] 1 2 3 4 #>  #> [[7]] #> [1] 1 2 3 5 #>  #> [[8]] #> [1] 1 2 3 6 #>  #> [[9]] #> [1] 1 2 3 7 #>  #> [[10]] #> [1] 1 2 3 4 5 #>  #> [[11]] #> [1] 1 2 3 4 6 #>  #> [[12]] #> [1] 1 2 3 4 7 #>  #> [[13]] #> [1] 1 2 3 5 6 #>  #> [[14]] #> [1] 1 2 3 5 7 #>  #> [[15]] #> [1] 1 2 3 6 7 #>  #> [[16]] #> [1] 1 2 3 4 5 6 #>  #> [[17]] #> [1] 1 2 3 4 5 7 #>  #> [[18]] #> [1] 1 2 3 4 6 7 #>  #> [[19]] #> [1] 1 2 3 5 6 7 #>  #> [[20]] #> [1] 1 2 3 4 5 6 7 plot_beeswarms(explanation_asym_con, title = \"Asymmetric conditional Shapley values\") # Order the symmetric and asymmetric conditional explanations into a joint list explanation_sym_con_tmp <- copy(explanation_sym_con) names(explanation_sym_con_tmp) <- paste0(names(explanation_sym_con_tmp), \"_sym\") explanation_asym_con_tmp <- copy(explanation_asym_con) names(explanation_asym_con_tmp) <- paste0(names(explanation_asym_con_tmp), \"_asym\") explanation_asym_sym_con <- c(explanation_sym_con_tmp, explanation_asym_con_tmp)[c(1, 4, 2, 5, 3, 6)] plot_SV_several_approaches(explanation_asym_sym_con, index_x_explain, brewer_palette = \"Paired\") +   theme(legend.position = \"bottom\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"symmetric-marginal-shapley-values","dir":"Articles","previous_headings":"Code example","what":"Symmetric marginal Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"marginal Shapley values, can consider symmetric version must set causal_ordering = list(1:7) (NULL) confounding = TRUE. Setting asymmetric = TRUE effect, causal ordering consists single component containing features, .e., coalitions respect causal ordering. stated , shapr generates marginal Monte Carlo samples Gaussian marginals approach = \"gaussian\", Monte Carlo approaches marginals estimated training data, .e., assuming feature independence. Thus, matter set approach = \"independence\" Monte Carlo-based approaches. use approach = \"independence\" clarity. Furthermore, also obtain marginal Shapley values using conditional Shapley value framework independence approach. However, note minuscule difference produced Shapley values due different sampling setups/orders. can look beeswarm plots","code":"explanation_sym_marg <- list()  # Here we sample from the estimated Gaussian marginals explanation_sym_marg[[\"gaussian\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"gaussian\",   asymmetric = FALSE,   causal_ordering = list(1:7),   confounding = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:33 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 7 #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Causal ordering: {trend, cosyear, sinyear, temp, atemp, windspeed, #> hum} #>  #> ‚Ä¢ Components with confounding: {trend, cosyear, sinyear, temp, atemp, #> windspeed, hum} #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de62c3da64.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 46 of 128 coalitions, 20 new.  # Here we sample from the marginals of the training data explanation_sym_marg[[\"independence_marg\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"independence\",   asymmetric = FALSE,   causal_ordering = list(1:7),   confounding = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:42 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: independence #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Causal ordering: {trend, cosyear, sinyear, temp, atemp, windspeed, #> hum} #> ‚Ä¢ Components with confounding: {trend, cosyear, sinyear, temp, atemp, #> windspeed, hum} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767deaa672e8.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 46 of 128 coalitions, 20 new.  # Here we use the conditional Shapley value framework with the `independence` approach explanation_sym_marg[[\"independence_con\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"independence\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:00:50 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: independence #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de50b128f8.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 46 of 128 coalitions, 20 new. print_MSEv_scores_and_time(explanation_sym_marg) #>                      MSEv MSEv_sd Time (secs) #> gaussian          1376367  109262        8.85 #> independence_marg 1377106  108898        7.94 #> independence_con  1376651  108870        9.14  plot_beeswarms(explanation_sym_marg, title = \"Symmetric marginal Shapley values\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"causal-shapley-values","dir":"Articles","previous_headings":"Code example","what":"Causal Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"compute (symmetric/asymmetric) causal Shapley values, provide causal_ordering confounding objects. set causal_ordering = list(1, 2:3, 4:7) confounding = c(FALSE, TRUE, FALSE), explained . causal framework takes longer frameworks, generating Monte Carlo samples often consists chain sampling steps. example, ùíÆ=2\\mathcal{S} = {2}, must generate X1,X3,X4,X5,X6,X7‚à£X2X_1,X_3,X_4,X_5,X_6,X_7 \\mid X_2. However, directly due causal_ordering confounding specified . generate Monte Carlo samples, follow chain sampling steps. precisely, first need generate X1X_1 marginal, X3‚à£X1X_3 \\mid X_1, finally X4,X5,X6,X7‚à£X1,X2,X3X_4,X_5,X_6,X_7 \\mid X_1,X_2,X_3. latter two steps done using provided approach model conditional distributions. internal$objects$S_causal_steps_strings object contains sampling steps needed different feature combinations/coalitions ùíÆ\\mathcal{S}. causal Shapley values, Monte Carlo-based approaches applicable.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"symmetric","dir":"Articles","previous_headings":"Code example > Causal Shapley values","what":"Symmetric","title":"Asymmetric and causal Shapley value explanations","text":"","code":"explanation_sym_cau <- list()  explanation_sym_cau[[\"gaussian\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"gaussian\",   asymmetric = FALSE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE),   iterative = FALSE, # Set to FALSE to get a single iteration to illustrate sampling steps below   exact = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:01:00 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 7 #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #>  #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de22699027.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 128 of 128 coalitions.  # Look at the sampling steps for the third coalition (S = {2}) explanation_sym_cau$gaussian$internal$iter_list[[1]]$S_causal_steps_strings$id_coalition_3 #> [1] \"1|\"            \"3|1\"           \"4,5,6,7|1,2,3\"  # Use the copula approach explanation_sym_cau[[\"copula\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"copula\",   asymmetric = FALSE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:01:24 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 128`, #>   and is therefore set to `2^n_features = 128`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: copula #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de38411544.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 46 of 128 coalitions, 20 new. print_MSEv_scores_and_time(explanation_sym_cau) #>             MSEv MSEv_sd Time (secs) #> gaussian 1112304   85462        24.5 #> copula   1131125   87179        20.9 plot_beeswarms(explanation_sym_cau, title = \"Symmetric causal Shapley values\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"asymmetric","dir":"Articles","previous_headings":"Code example > Causal Shapley values","what":"Asymmetric","title":"Asymmetric and causal Shapley value explanations","text":"now turn asymmetric causal Shapley values. , use coalitions respect causal ordering. Thus, computations faster number coalitions reduced. can look elapsed time. See implementation details explanation. can plot beeswarm plots.   can also use Monte Carlo-based approaches (independence empirical), .","code":"explanation_asym_cau <- list()  explanation_asym_cau[[\"gaussian\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"gaussian\",   asymmetric = TRUE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:01:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 7 #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Number of asymmetric coalitions: 20 #>  #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #>  #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de36b4c890.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 13 of 20 coalitions, 13 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 20 of 20 coalitions, 7 new.  # Use the copula approach explanation_asym_cau[[\"copula\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"copula\",   asymmetric = TRUE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:01:49 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: copula #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 20 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de7e7297ad.rds' #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 13 of 20 coalitions, 13 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 20 of 20 coalitions, 7 new.  # Use the vaeac approach explanation_asym_cau[[\"vaeac\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   phi0 = phi0,   seed = 1,   n_MC_samples = 1000,   approach = \"vaeac\",   vaeac.epochs = 20,   asymmetric = TRUE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE)  ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:01:54 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (20), and is therefore set to 20. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: vaeac #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 20 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767debc01b09.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 20 of 20 coalitions. print_time(explanation_asym_cau) #>      gaussian copula vaeac #> [1,]   3.7314  4.746 351.7 # Plot the beeswarm plots plot_beeswarms(explanation_asym_cau, title = \"Asymmetric causal Shapley values\") # Plot the Shapley values plot_SV_several_approaches(explanation_asym_cau, index_x_explain) +   theme(legend.position = \"bottom\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"comparing-the-frameworks","dir":"Articles","previous_headings":"Code example","what":"Comparing the frameworks","title":"Asymmetric and causal Shapley value explanations","text":"plot obtained Shapley values six explicands using gaussian approach different Shapley value explanation frameworks, see different frameworks provide different explanations. largest difference symmetric asymmetric versions. summarize, asymmetric conditional/causal Shapley values focus root cause, marginal Shapley values direct effect, symmetric conditional/causal Shapley values consider natural explanation.","code":"explanation_gaussian <- list(   symmetric_marginal = explanation_sym_marg$gaussian,   symmetric_conditional = explanation_sym_con$gaussian,   symmetric_causal = explanation_sym_cau$gaussian,   asymmetric_conditional = explanation_asym_con$gaussian,   asymmetric_causal = explanation_asym_cau$gaussian )  plot_SV_several_approaches(explanation_gaussian, index_x_explain) +   theme(legend.position = \"bottom\") +   guides(fill = guide_legend(nrow = 2)) +   ggtitle(\"Shapley value prediction explanation (approach = 'gaussian')\") +   guides(color = guide_legend(title = \"Framework\"))"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"scatter-plots-marginal-vs--causal-shapley-values","dir":"Articles","previous_headings":"Code example","what":"Scatter plots: marginal vs.¬†causal Shapley values","title":"Asymmetric and causal Shapley value explanations","text":"section, produce scatter plots comparing symmetric marginal symmetric causal Shapley values temperature feature temp seasonal feature cosyear explicands. plots show marginal Shapley values almost purely explain predictions based temperature, causal Shapley values also give credit season. can change features frameworks code , chose values replicate Figure 3 Heskes et al. (2020).","code":"# The color of the points color <- \"temp\"  # The features we want to compare feature_1 <- \"cosyear\" feature_2 <- \"temp\"  # The Shapley value frameworks we want to compare sv_framework_1 <- explanation_sym_marg[[\"gaussian\"]] sv_framework_1_str <- \"Marginal SV\" sv_framework_2 <- explanation_sym_cau[[\"gaussian\"]] sv_framework_2_str <- \"Causal SV\"  # Set up the data.frame we are going to plot sv_correlation_df <- data.frame(   color = x_explain[, color],   sv_framework_1_feature_1 = sv_framework_1$shapley_values_est[[feature_1]],   sv_framework_2_feature_1 = sv_framework_2$shapley_values_est[[feature_1]],   sv_framework_1_feature_2 = sv_framework_1$shapley_values_est[[feature_2]],   sv_framework_2_feature_2 = sv_framework_2$shapley_values_est[[feature_2]] )  # Make the plots scatterplot_topleft <-   ggplot(     sv_correlation_df,     aes(x = sv_framework_1_feature_2, y = sv_framework_1_feature_1, color = color)   ) +   geom_point(size = 1) +   xlab(paste(sv_framework_1_str, feature_2)) +   ylab(paste(sv_framework_1_str, feature_1)) +   scale_x_continuous(limits = c(-1500, 1000), breaks = c(-1000, 0, 1000)) +   scale_y_continuous(limits = c(-500, 500), breaks = c(-500, 0, 500)) +   scale_color_gradient(low = \"blue\", high = \"red\") +   theme_minimal() +   theme(     text = element_text(size = 12),     axis.text.x = element_blank(),     axis.text.y = element_text(size = 12),     axis.ticks.x = element_blank(),     axis.title.x = element_blank()   )  scatterplot_topright <-   ggplot(     sv_correlation_df,     aes(x = sv_framework_2_feature_1, y = sv_framework_1_feature_1, color = color)   ) +   geom_point(size = 1) +   scale_color_gradient(low = \"blue\", high = \"red\") +   xlab(paste(sv_framework_2_str, feature_1)) +   ylab(paste(sv_framework_1_str, feature_1)) +   scale_x_continuous(limits = c(-1500, 1000), breaks = c(-1000, 0, 1000)) +   scale_y_continuous(limits = c(-500, 500), breaks = c(-500, 0, 500)) +   theme_minimal() +   theme(     text = element_text(size = 12),     axis.title.x = element_blank(),     axis.title.y = element_blank(),     axis.text.x = element_blank(),     axis.ticks.x = element_blank(),     axis.text.y = element_blank(),     axis.ticks.y = element_blank()   )  scatterplot_bottomleft <-   ggplot(     sv_correlation_df,     aes(x = sv_framework_1_feature_2, y = sv_framework_2_feature_2, color = color)   ) +   geom_point(size = 1) +   scale_color_gradient(low = \"blue\", high = \"red\") +   xlab(paste(sv_framework_1_str, feature_2)) +   ylab(paste(sv_framework_2_str, feature_2)) +   scale_x_continuous(limits = c(-1500, 1000), breaks = c(-1000, 0, 1000)) +   scale_y_continuous(limits = c(-1000, 1000), breaks = c(-500, 0, 500)) +   theme_minimal() +   theme(     text = element_text(size = 12),     axis.text.x = element_text(size = 12),     axis.text.y = element_text(size = 12)   )  scatterplot_bottomright <-   ggplot(     sv_correlation_df,     aes(x = sv_framework_2_feature_1, y = sv_framework_2_feature_2, color = color)   ) +   geom_point(size = 1) +   xlab(paste(sv_framework_2_str, feature_1)) +   ylab(paste(sv_framework_2_str, feature_2)) +   scale_x_continuous(limits = c(-1500, 1000), breaks = c(-1000, 0, 1000)) +   scale_y_continuous(limits = c(-1000, 1000), breaks = c(-500, 0, 500)) +   scale_color_gradient(low = \"blue\", high = \"red\") +   theme_minimal() +   theme(     text = element_text(size = 12),     axis.text.x = element_text(size = 12),     axis.title.y = element_blank(),     axis.text.y = element_blank(),     axis.ticks.y = element_blank()   )  # Plot of the trend of the data bike_plot_new <- ggplot(bike, aes(x = trend, y = cnt, color = get(color))) +   geom_point(size = 0.75) +   scale_color_gradient(low = \"blue\", high = \"red\") +   labs(color = color) +   xlab(\"Days since 1 January 2011\") +   ylab(\"Number of bikes rented\") +   theme_minimal() +   theme(legend.position = \"right\", legend.title = element_text(size = 10))  # Combine the plots ggpubr::ggarrange(   bike_plot_new,   ggpubr::ggarrange(     scatterplot_topleft,     scatterplot_topright,     scatterplot_bottomleft,     scatterplot_bottomright,     legend = \"none\"   ),   nrow = 2, heights = c(1, 2) )"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"investigating-two-similar-days","dir":"Articles","previous_headings":"Code example","what":"Investigating two similar days","title":"Asymmetric and causal Shapley value explanations","text":"investigate difference symmetric/asymmetric conditional, symmetric/asymmetric causal, marginal Shapley values two days: October 10 December 3, 2012. less temperature 13 13.27 degrees Celsius, predicted bike counts 6117 6241, respectively. figure extension Figure 4 Heskes et al. (2020), included asymmetric conditional, symmetric causal, marginal Shapley values. plot various Shapley values cosyear temp features . obtain results Heskes et al. (2020) obtained, namely, marginal Shapley value explanation framework provides similar explanations days. .e., considers direct effect temp. asymmetric conditional causal Shapley values almost indistinguishable put weight ‚Äòroot‚Äô cause cosyear. Heskes et al. (2020) states symmetric causal Shapley values provide sensible balance two extremes gives credit season temperature, still different explanations two days. However, also include symmetric conditional Shapley values, see extremely similar symmetric causal Shapley values. .e., conditional Shapley value explanation framework also provides sensible balance marginal asymmetric Shapley values. summarize: concluded Heskes et al. (2020) Figure 4, asymmetric conditional/causal Shapley values focus root cause, marginal Shapley values direct effect, symmetric conditional/causal Shapley values consider natural explanation.  can also make similar plot using plot_SV_several_approaches function shapr, get explicand separate facet instead facet framework.  Furthermore, instead Heskes et al. (2020) considering features cosyear temp, can plot features, , get complete overview.","code":"# Features of interest features <- c(\"cosyear\", \"temp\")  # Get explicands with similar temperature: 2012-10-09 (October) and 2012-12-03 (December) dates <- c(\"2012-10-09\", \"2012-12-03\") dates_idx <- sapply(dates, function(data) which(as.integer(row.names(x_explain)) == which(bike$dteday == data))) # predict(model, x_explain)[dates_idx] + mean(y_train_nc) # predicted values for the two points  # List of the Shapley value explanations explanations <- list(   \"Sym. Mar.\" = explanation_sym_marg[[\"gaussian\"]],   \"Sym. Con.\" = explanation_sym_con[[\"gaussian\"]],   \"Sym. Cau.\" = explanation_sym_cau[[\"gaussian\"]],   \"Asym. Con.\" = explanation_asym_con[[\"gaussian\"]],   \"Asym. Cau.\" = explanation_asym_cau[[\"gaussian\"]] )  # Extract the relevant Shapley values explanations_extracted <- data.table::rbindlist(lapply(seq_along(explanations), function(idx) {   explanations[[idx]]$shapley_values_est[     dates_idx, ..features   ][, `:=`(Date = dates, type = names(explanations)[idx])] }))  # Set type to be an ordered factor explanations_extracted[, type := factor(type, levels = names(explanations), ordered = TRUE)]  # Convert from wide to long data table dt_all <- data.table::melt(explanations_extracted,   id.vars = c(\"Date\", \"type\"),   variable.name = \"feature\" )  # Make the plot ggplot(dt_all, aes(   x = feature, y = value, group = interaction(Date, feature),   fill = Date, label = round(value, 2) )) +   geom_col(position = \"dodge\") +   theme_classic() +   ylab(\"Shapley value\") +   facet_wrap(vars(type)) +   theme(axis.title.x = element_blank()) +   scale_fill_manual(values = c(\"indianred4\", \"ivory4\")) +   theme(     legend.position.inside = c(0.75, 0.25), axis.title = element_text(size = 20),     legend.title = element_text(size = 16), legend.text = element_text(size = 14),     axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12),     strip.text.x = element_text(size = 14)   ) # Here 2012-10-09 is the left facet and 2012-12-03 the right facet plot_SV_several_approaches(explanations,   index_explicands = dates_idx,   only_these_features = features, # Can include more features.   facet_scales = \"free_x\",   horizontal_bars = FALSE,   axis_labels_n_dodge = 1 ) + theme(legend.position = \"bottom\") # Here 2012-10-09 is the left facet and 2012-12-03 the right facet plot_SV_several_approaches(explanations,   index_explicands = dates_idx,   facet_scales = \"free_x\",   horizontal_bars = FALSE,   axis_labels_rotate_angle = 45,   digits = 2 ) + theme(legend.position = \"bottom\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"sampling-of-coalitions","dir":"Articles","previous_headings":"Code example","what":"Sampling of coalitions","title":"Asymmetric and causal Shapley value explanations","text":"can use max_n_coalitions specify/reduce number coalitions use computing Shapley value explanation framework. applies marginal, conditional, causal Shapley values, symmetric asymmetric versions. However, recall asymmetric versions already fewer valid coalitions due causal ordering. example , demonstrate sampling coalitions asymmetric symmetric causal Shapley value explanation frameworks. half number coalitions versions see elapsed times approximately halved, . can plot beeswarm plots Shapley values six selected explicands. see minuscule differences Shapley values obtain use coalitions obtain use half valid coalitions.","code":"explanation_n_coal <- list()  explanation_n_coal[[\"sym_cau_gaussian_64\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   approach = \"gaussian\",   phi0 = phi0,   seed = 1,   asymmetric = FALSE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE),   max_n_coalitions = 64 # Instead of 128 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:07:51 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 7 #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #>  #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3b2d7dcf.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 14 of 128 coalitions, 14 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 26 of 128 coalitions, 12 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 46 of 128 coalitions, 20 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 50 of 128 coalitions, 4 new.  explanation_n_coal[[\"asym_cau_gaussian_10\"]] <- explain(   model = model,   x_train = x_train,   x_explain = x_explain,   approach = \"gaussian\",   phi0 = phi0,   seed = 1,   asymmetric = TRUE,   causal_ordering = list(1, 2:3, 4:7),   confounding = c(FALSE, TRUE, FALSE),   verbose = c(\"basic\", \"convergence\", \"shapley\"),   max_n_coalitions = 10, # Instead of 20   iterative = FALSE # Due to small number of coalitions ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:08:03 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 7 #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 20 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp, atemp, #> windspeed, hum} #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de32e4af9.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 10 of 10 coalitions.  #>  #> ‚îÄ‚îÄ Convergence info  #> ‚úî Iterative Shapley value estimation stopped at 10 coalitions after 1 iterations, due to: #> Maximum number of iterations (1) reached! #> Maximum number of coalitions (10) reached! #>  #> Final estimated Shapley values (sd) #>      explain_id   none             trend           cosyear          sinyear #>           <int> <char>            <char>            <char>           <char> #>   1:          1  0 (0) -2181.91 (389.03)  -825.54 (377.21) -240.38 (257.68) #>   2:          2  0 (0) -2174.36 (384.98)  -846.61 (381.99) -187.05 (273.99) #>   3:          3  0 (0) -2088.96 (373.84)  -793.63 (365.63) -187.85 (248.84) #>   4:          4  0 (0) -2103.36 (379.95)  -798.13 (377.31) -109.12 (270.58) #>   5:          5  0 (0) -2003.88 (362.92)  -723.94 (346.66) -234.82 (228.12) #>  ---                                                                        #> 140:        140  0 (0)  1575.95 (631.53) -1014.08 (569.93)  248.47 (371.16) #> 141:        141  0 (0)  1588.69 (650.49) -1057.22 (573.59)   33.39 (242.37) #> 142:        142  0 (0)  1466.75 (635.17) -1109.15 (558.07)  -97.32 (243.07) #> 143:        143  0 (0)  1003.94 (665.91) -1780.47 (623.77) -104.82 (347.18) #> 144:        144  0 (0)   711.14 (787.04) -2635.90 (784.97) -184.27 (536.88) #>                  temp            atemp         windspeed               hum #>                <char>           <char>            <char>            <char> #>   1:  -34.34 ( 63.89)    0.21 ( 55.92)   116.77 ( 70.18)    13.81 ( 88.83) #>   2:  -41.25 ( 54.60)   34.98 ( 23.07)    13.85 ( 36.81)   181.12 ( 77.88) #>   3:  -94.02 ( 50.84)  -17.90 ( 43.43)   244.64 ( 61.81)  -132.54 ( 59.19) #>   4:  191.34 (105.19)   44.35 ( 61.89)  -183.83 ( 66.85)  -228.80 (108.61) #>   5:   42.28 ( 43.88)    4.16 ( 31.93)   203.34 ( 47.27)   -32.18 ( 55.58) #>  ---                                                                       #> 140:  -41.16 (210.29)   16.01 (195.60)   361.82 (171.47)   589.55 (262.98) #> 141:   11.21 ( 34.71)    6.74 ( 23.45)   216.48 ( 30.02)   -80.28 ( 48.53) #> 142:  -35.61 ( 69.65)  129.07 ( 27.12)    79.35 ( 39.85)   265.54 ( 93.28) #> 143:   20.56 ( 64.24)   -4.87 ( 28.60)    47.65 ( 34.25)  -233.05 ( 82.77) #> 144:   47.65 (137.29)  -66.93 ( 74.15)  -469.80 ( 83.42)   558.27 (204.47)  # Look at the times explanation_n_coal[[\"sym_cau_gaussian_all_128\"]] <- explanation_sym_cau$gaussian explanation_n_coal[[\"asym_cau_gaussian_all_20\"]] <- explanation_asym_cau$gaussian explanation_n_coal <- explanation_n_coal[c(1, 3, 2, 4)] print_time(explanation_n_coal) #>      sym_cau_gaussian_64 sym_cau_gaussian_all_128 asym_cau_gaussian_10 #> [1,]              12.255                   24.503               1.8802 #>      asym_cau_gaussian_all_20 #> [1,]                   3.7314 plot_beeswarms(explanation_n_coal, title = \"Shapley values (gaussian) exact vs. approximation\") plot_SV_several_approaches(explanation_n_coal, index_x_explain) +   theme(legend.position = \"bottom\") +   guides(fill = guide_legend(nrow = 2))"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"groups-of-features","dir":"Articles","previous_headings":"Code example","what":"Groups of features","title":"Asymmetric and causal Shapley value explanations","text":"section, demonstrate can compute marginal, asymmetric conditional, symmetric/asymmetric Shapley values groups features, . group Shapley values, need specify causal ordering group level feature level. demonstrate gaussian approach, approaches applicable, . pairs plot (), see can natural group features temp atemp due (conceptual) similarity high correlation.  set groups update causal ordering group level. can compute (group) Shapley values using different Shapley value frameworks. can make beeswarm plots Shapley value plots six selected explicands. beeswarm plots, set include_group_feature_means = TRUE make plots. means plot function uses mean temp atemp features feature value. makes sense due high correlation two features. main difference feature-wise group-wise Shapley values now see much wider spread Shapley values temp_group temp atemp. example, symmetric causal framework, saw temp atemp obtained Shapley values (around) ‚àí500-500 500500, grouped version temp_group obtains Shapley values ‚àí1000-1000 10001000.","code":"GGally::ggpairs(x_train[, 4:5]) group_list <- list(   trend = \"trend\",   cosyear = \"cosyear\",   sinyear = \"sinyear\",   temp_group = c(\"temp\", \"atemp\"),   windspeed = \"windspeed\",   hum = \"hum\" )  causal_ordering_group <-   list(\"trend\", c(\"cosyear\", \"sinyear\"), c(\"temp_group\", \"windspeed\", \"hum\")) confounding <- c(FALSE, TRUE, FALSE) explanation_group_gaussian <- list()  explanation_group_gaussian[[\"symmetric_marginal\"]] <-   explain(     model = model,     x_train = x_train,     x_explain = x_explain,     approach = \"gaussian\",     phi0 = phi0,     seed = 1,     asymmetric = FALSE,     causal_ordering = list(seq(length(group_list))), # or `NULL`     confounding = TRUE,     n_MC_samples = 1000,     group = group_list,     iterative = FALSE   ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:08:07 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_groups = 64`, and #>   is therefore set to `2^n_groups = 64`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of group-wise Shapley values: 6 #>  #> ‚Ä¢ Feature groups: trend: {\"trend\"}; cosyear: {\"cosyear\"}; sinyear: #> {\"sinyear\"}; temp_group: {\"temp\", \"atemp\"}; windspeed: {\"windspeed\"}; #> hum: {\"hum\"} #>  #> ‚Ä¢ Number of observations to explain: 144 #>  #> ‚Ä¢ Causal ordering: {trend, cosyear, sinyear, temp_group, windspeed, #> hum} #>  #> ‚Ä¢ Components with confounding: {trend, cosyear, sinyear, temp_group, #> windspeed, hum} #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767debb09456.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 64 of 64 coalitions.  explanation_group_gaussian[[\"symmetric_conditional\"]] <-   explain(     model = model,     x_train = x_train,     x_explain = x_explain,     approach = \"gaussian\",     phi0 = phi0,     seed = 1,     asymmetric = FALSE,     causal_ordering = list(seq(length(group_list))), # or `NULL`     confounding = NULL,     n_MC_samples = 1000,     group = group_list,     iterative = FALSE   ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:08:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_groups = 64`, and #>   is therefore set to `2^n_groups = 64`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of group-wise Shapley values: 6 #> ‚Ä¢ Feature groups: trend: {\"trend\"}; cosyear: {\"cosyear\"}; sinyear: #> {\"sinyear\"}; temp_group: {\"temp\", \"atemp\"}; windspeed: {\"windspeed\"}; #> hum: {\"hum\"} #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de4646db69.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 64 of 64 coalitions.  explanation_group_gaussian[[\"asymmetric_conditional\"]] <-   explain(     model = model,     x_train = x_train,     x_explain = x_explain,     approach = \"gaussian\",     phi0 = phi0,     seed = 1,     asymmetric = TRUE,     causal_ordering = causal_ordering_group,     confounding = NULL,     n_MC_samples = 1000,     group = group_list,     iterative = FALSE   ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:08:15 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (12), and is therefore set to 12. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of group-wise Shapley values: 6 #> ‚Ä¢ Feature groups: trend: {\"trend\"}; cosyear: {\"cosyear\"}; sinyear: #> {\"sinyear\"}; temp_group: {\"temp\", \"atemp\"}; windspeed: {\"windspeed\"}; #> hum: {\"hum\"} #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 12 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp_group, #> windspeed, hum} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3b1b09a3.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 12 of 12 coalitions.  explanation_group_gaussian[[\"symmetric_causal\"]] <-   explain(     model = model,     x_train = x_train,     x_explain = x_explain,     approach = \"gaussian\",     phi0 = phi0,     seed = 1,     asymmetric = FALSE,     causal_ordering = causal_ordering_group,     confounding = confounding,     n_MC_samples = 1000,     group = group_list,     iterative = FALSE   ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:08:17 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_groups = 64`, and #>   is therefore set to `2^n_groups = 64`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of group-wise Shapley values: 6 #> ‚Ä¢ Feature groups: trend: {\"trend\"}; cosyear: {\"cosyear\"}; sinyear: #> {\"sinyear\"}; temp_group: {\"temp\", \"atemp\"}; windspeed: {\"windspeed\"}; #> hum: {\"hum\"} #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp_group, #> windspeed, hum} #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de130c1e31.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 64 of 64 coalitions.  explanation_group_gaussian[[\"asymmetric_causal\"]] <-   explain(     model = model,     x_train = x_train,     x_explain = x_explain,     approach = \"gaussian\",     phi0 = phi0,     seed = 1,     asymmetric = TRUE,     causal_ordering = causal_ordering_group,     confounding = confounding,     n_MC_samples = 1000,     group = group_list,     iterative = FALSE   ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 10:08:28 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than the number of coalitions #>   respecting the causal ordering (12), and is therefore set to 12. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of group-wise Shapley values: 6 #> ‚Ä¢ Feature groups: trend: {\"trend\"}; cosyear: {\"cosyear\"}; sinyear: #> {\"sinyear\"}; temp_group: {\"temp\", \"atemp\"}; windspeed: {\"windspeed\"}; #> hum: {\"hum\"} #> ‚Ä¢ Number of observations to explain: 144 #> ‚Ä¢ Number of asymmetric coalitions: 12 #> ‚Ä¢ Causal ordering: {trend}, {cosyear, sinyear}, {temp_group, #> windspeed, hum} #> ‚Ä¢ Components with confounding: {cosyear, sinyear} #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de40c14a18.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 12 of 12 coalitions.  # Look at the elapsed times (symmetric takes the longest time) print_time(explanation_group_gaussian) #>      symmetric_marginal symmetric_conditional asymmetric_conditional #> [1,]             6.1959                2.6076                 1.5224 #>      symmetric_causal asymmetric_causal #> [1,]           10.739            1.7213 plot_beeswarms(explanation_group_gaussian,   title = \"Group Shapley values (gaussian)\",   include_group_feature_means = TRUE ) plot_SV_several_approaches(explanation_group_gaussian, index_x_explain) +   ggtitle(\"Shapley value prediction explanation (gaussian)\") +   theme(legend.position = \"bottom\") + guides(fill = guide_legend(nrow = 2))"},{"path":"https://norskregnesentral.github.io/shapr/articles/asymmetric_causal.html","id":"implementation-details","dir":"Articles","previous_headings":"Code example","what":"Implementation details","title":"Asymmetric and causal Shapley value explanations","text":"shapr package built estimate conditional Shapley values, thus, parallelizes coalitions. makes perfect sense said framework batch coalitions independent batches, means easy parallelize. Furthermore, using many batches, drastically reduce memory usage shapr need store Monte Carlo samples coalitions. setup optimal causal Shapley value framework chains sampling steps two coalitions ùíÆ\\mathcal{S} ùíÆ*\\mathcal{S}^* can contain many steps. Ideally, unique sampling step modeled save computation time, sampling steps occur many chains. Thus, store Monte Carlo samples coalitions sampling step included, can therefore run memory consumption problems. Thus, current implementation, treat coalition ùíÆ\\mathcal{S} independently remodel needed sampling steps coalition. Furthermore, conditional Shapley value framework, ùíÆ‚Äæ=‚Ñ≥‚àñùíÆ\\bar{\\mathcal{S}} = \\mathcal{M} \\backslash \\mathcal{S}, thus shapr default generate Monte Carlo samples features ùíÆ\\mathcal{S}. causal Shapley value framework, case, .e., ùíÆ‚Äæ‚â†‚Ñ≥‚àñùíÆ\\bar{\\mathcal{S}} \\neq \\mathcal{M} \\backslash \\mathcal{S} general. reuse code, generate Monte Carlo samples features ùíÆ\\mathcal{S}, keep samples features ùíÆ‚Äæ\\bar{\\mathcal{S}}. speed shapr , one rewrite approaches support cases ùíÆ‚Äæ\\bar{\\mathcal{S}} complement ùíÆ\\mathcal{S}. code , see unique coalitions/set features condition generate Monte Carlo samples coalitions number times set conditional features needed symmetric causal Shapley value framework setup . see conditional distributions now remodeled eight times. gaussian approach, fast estimate conditional distributions, major impact time. However, , e.g., ctree approach much slower, take significant amount extra time. vaeac approach trains relevant coalitions. independence, empirical, ctree, categorical approaches produce weighted Monte Carlo samples. means necessarily generate n_MC_samples. ensure n_MC_samples, sample n_MC_samples samples using weighted sampling replacement weights weights returned approaches. marginal Shapley value explanation framework can extended support modeling marginal distributions using copula vaeac approaches methods support unconditional sampling.","code":"S_causal_steps <- explanation_sym_cau$gaussian$internal$iter_list[[1]]$S_causal_steps S_causal_unlist <- do.call(c, unlist(S_causal_steps, recursive = FALSE)) S_causal_steps_freq <- S_causal_unlist[grepl(\"\\\\.S(?!bar)\", names(S_causal_unlist), perl = TRUE)] S_causal_steps_freq <- S_causal_steps_freq[!sapply(S_causal_steps_freq, is.null)] # Remove NULLs S_causal_steps_freq <- S_causal_steps_freq[sapply(S_causal_steps_freq, length) > 0] # Remove extra integer(0) table(sapply(S_causal_steps_freq, paste0, collapse = \",\")) #>  #>           1       1,2,3     1,2,3,4   1,2,3,4,5 1,2,3,4,5,6 1,2,3,4,5,7  #>          95           7           8           8           8           8  #>   1,2,3,4,6 1,2,3,4,6,7   1,2,3,4,7     1,2,3,5   1,2,3,5,6 1,2,3,5,6,7  #>           8           8           8           8           8           8  #>   1,2,3,5,7     1,2,3,6   1,2,3,6,7     1,2,3,7  #>           8           8           8           8"},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"intro","dir":"Articles","previous_headings":"","what":"Introduction","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"shapr package implements extended version Kernel SHAP method approximating Shapley values (Lundberg Lee (2017)), dependence features taken account (Aas, Jullum, L√∏land (2021)). Estimation Shapley values interest attempting explain complex machine learning models. existing work interpreting individual predictions, Shapley values regarded model-agnostic explanation method solid theoretical foundation (Lundberg Lee (2017)). Kernel SHAP computationally efficient approximation Shapley values higher dimensions, assumes independent features. Aas, Jullum, L√∏land (2021) extends Kernel SHAP method handle dependent features, resulting accurate approximations true Shapley values. See paper (Aas, Jullum, L√∏land (2021)) details.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"functionality","dir":"Articles","previous_headings":"Overview of Package","what":"Functionality","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"overview main functions. can read documentation see examples ?function_name. Main functions shapr package. shapr package implements Kernel SHAP estimation dependence-aware Shapley values eight different Monte Carlo-based approaches estimating conditional distributions data, namely \"empirical\", \"gaussian\", \"copula\", \"ctree\", \"vaeac\", \"categorical\", \"timeseries\", \"independence\". shapr also implemented two regression-based approaches \"regression_separate\" \"regression_surrogate\". See Estimation approaches plotting functionality examples. also possible combine different approaches, see combined approach. package allows parallelized computation future package, see Parallelization details. level detail output can controlled verbose argument. addition, progress updates process estimating v(S)‚Äôs (training \"vaeac\" model) available progressr package, supporting progress updates also parallelized computation. See Verbosity progress updates details. Moreover, default behavior estimate Shapley values iteratively, increasing number feature coalitions added, stop estimation estimated Shapley values achieved certain level stability. information provided Iterative estimation , combined batch computation v(S) values, enables fast accurate estimation Shapley values memory-friendly manner. package provides functionality printing summarizing Shapley value computation, well extracting objects created computation, see Summary, Printing, Result Extraction. package also provides functionality computing Shapley values groups features, custom function explanation, see Advanced usage. Finally, explanation multiple output time series forecasting models discussed Explaining forecasting models.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"default-behavior-of-explain","dir":"Articles","previous_headings":"Overview of Package","what":"Default behavior of explain","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"provide brief descriptions important parts default behavior explain function. default explain always computes feature-wise Shapley values. Groups features can explained providing feature groups group argument. five fewer features (feature groups), iterative estimation default disabled. reason usually faster estimate Shapley values possible coalitions (v(S)), estimate uncertainty Shapley values, potentially stop estimation earlier. iterative estimation default starting six features, mainly ten features, beneficial, can save lot computation time. reason number possible coalitions grows exponentially. defaults can overridden setting iterative argument TRUE FALSE. using iterative argument, estimation observation stopped Shapley value standard deviations t times range Shapley values. t value controls convergence tolerance, defaults 0.02, can set iterative_args$convergence_tol argument, see iterative estimation details. Since iterativeness default changes based number features (feature groups), default also upper bound number coalitions considered. can controlled max_n_coalitions argument.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"the-kernel-shap-method","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"The Kernel SHAP Method","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"Assume predictive model f(ùê±)f(\\boldsymbol{x}) response value yy features ùê±‚àà‚ÑùM\\boldsymbol{x}\\\\mathbb{R}^M, trained training set, want explain predictions new sets data. may done using ideas cooperative game theory, letting single prediction take place game played features place players. Letting NN denote set MM players, S‚äÜNS \\subseteq N subset |S||S| players, ‚Äúcontribution‚Äù function v(S)v(S) describes total expected sum payoffs members SS can obtain cooperation. Shapley value (Shapley (1953)) one way distribute total gains players, assuming collaborate. amount player ii gets œïi(v)=œïi=‚àëS‚äÜN\\{}|S|!(M‚àí|S|‚àí1)!M!(v(S‚à™{})‚àív(S)),\\phi_i(v) = \\phi_i = \\sum_{S \\subseteq N \\setminus\\{\\}} \\frac{|S| ! (M-| S| - 1)!}{M!}(v(S\\cup \\{\\})-v(S)), , weighted mean subsets SS players containing player ii. Lundberg Lee (2017) define contribution function certain subset SS features ùê±S\\boldsymbol{x}_S v(S)=E[f(ùê±)|ùê±S]v(S) = \\mbox{E}[f(\\boldsymbol{x})|\\boldsymbol{x}_S], expected output predictive model conditional feature values subset. Lundberg Lee (2017) names type Shapley values SHAP (SHapley Additive exPlanation) values. Since conditional expectations can written conditional distributions p(ùê±S‚Äæ|ùê±S=ùê±S*)p(\\boldsymbol{x}_{\\bar{S}}|\\boldsymbol{x}_S=\\boldsymbol{x}_S^*) needed compute contributions. Kernel SHAP method Lundberg Lee (2017) assumes feature independence, p(ùê±S‚Äæ|ùê±S=ùê±S*)=p(ùê±S‚Äæ)p(\\boldsymbol{x}_{\\bar{S}}|\\boldsymbol{x}_S=\\boldsymbol{x}_S^*)=p(\\boldsymbol{x}_{\\bar{S}}). samples ùê±S‚Äæk,k=1,‚Ä¶,K\\boldsymbol{x}_{\\bar{S}}^{k}, k=1,\\ldots,K, p(ùê±S‚Äæ|ùê±S=ùê±S*)p(\\boldsymbol{x}_{\\bar{S}}|\\boldsymbol{x}_S=\\boldsymbol{x}_S^*) available, conditional expectation can approximated Kernel SHAP, ùê±S‚Äæk,k=1,‚Ä¶,K\\boldsymbol{x}_{\\bar{S}}^{k}, k=1,\\ldots,K sampled S‚Äæ\\bar{S}-part training data, independently ùê±S\\boldsymbol{x}_{S}. motivated using training set empirical distribution ùê±S‚Äæ\\boldsymbol{x}_{\\bar{S}}, assuming ùê±S‚Äæ\\boldsymbol{x}_{\\bar{S}} independent ùê±S=ùê±S*\\boldsymbol{x}_S=\\boldsymbol{x}_S^*. Due independence assumption, features given model highly dependent, Kernel SHAP method may give completely wrong answer. can avoided estimating conditional distribution p(ùê±S‚Äæ|ùê±S=ùê±S*)p(\\boldsymbol{x}_{\\bar{S}}|\\boldsymbol{x}_S=\\boldsymbol{x}_S^*) directly generating samples distribution. small change, contributions Shapley values may approximated ordinary Kernel SHAP framework. Aas, Jullum, L√∏land (2021) propose three different approaches estimating conditional probabilities implemented: empirical, gaussian copula. package also implements ctree method Redelmeier, Jullum, Aas (2020), vaeac method Olsen et al. (2022) categorical categorical data. original independence approach Lundberg Lee (2017) also available. methods may also combined, e.g.¬†one method used conditioning small number features, another method used otherwise. shapr package also supports directly estimating contribution function using regression. briefly introduce regression-based methods , refer separate regression vignette (Shapley value explanations using regression paradigm) Olsen et al. (2024) -depth explanation regression paradigm.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"gaussian","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Multivariate Gaussian Distribution Approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"first approach arises assumption feature vector ùê±\\boldsymbol{x} stems multivariate Gaussian distribution mean vector ùõç\\boldsymbol{\\mu} covariance matrix ùö∫\\boldsymbol{\\Sigma}. assumption, conditional distribution p(ùê±ùíÆ‚Äæ|ùê±ùíÆ=ùê±ùíÆ*)p(\\boldsymbol{x}_{\\bar{\\mathcal{S}}} |\\boldsymbol{x}_{\\mathcal{S}}=\\boldsymbol{x}_{\\mathcal{S}}^*) also multivariate GaussianN|ùíÆ‚Äæ|(ùõçùíÆ‚Äæ|ùíÆ,ùö∫ùíÆ‚Äæ|ùíÆ)\\text{N}_{|\\bar{\\mathcal{S}}|}(\\boldsymbol{\\mu}_{\\bar{\\mathcal{S}}|\\mathcal{S}},\\boldsymbol{\\Sigma}_{\\bar{\\mathcal{S}}|\\mathcal{S}}), analytical expressions conditional mean vector ùõçùíÆ‚Äæ|ùíÆ\\boldsymbol{\\mu}_{\\bar{\\mathcal{S}}|\\mathcal{S}} covariance matrix ùö∫ùíÆ‚Äæ|ùíÆ\\boldsymbol{\\Sigma}_{\\bar{\\mathcal{S}}|\\mathcal{S}}, see Aas, Jullum, L√∏land (2021) details. Hence, instead sampling marginal empirical distribution ùê±ùíÆ‚Äæ\\boldsymbol{x}_{\\bar{\\mathcal{S}}} approximated training data, can sample Gaussian conditional distribution, fitted using training data. Using resulting samples ùê±ùíÆ‚Äæk,k=1,‚Ä¶,K\\boldsymbol{x}_{\\bar{\\mathcal{S}}}^k, k=1,\\ldots,K, conditional expectations approximated Kernel SHAP.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"copula","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Gaussian Copula Approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"features far multivariate Gaussian, alternative approach instead represent marginals empirical distributions, model dependence structure Gaussian copula. Assuming Gaussian copula, may convert marginals training data Gaussian features using empirical distributions, fit multivariate Gaussian distribution . produce samples conditional distribution p(ùê±ùíÆ‚Äæ|ùê±ùíÆ=ùê±ùíÆ*)p(\\boldsymbol{x}_{\\bar{\\mathcal{S}}} |\\boldsymbol{x}_{\\mathcal{S}}=\\boldsymbol{x}_{\\mathcal{S}}^*), convert marginals ùê±ùíÆ\\boldsymbol{x}_{\\mathcal{S}} Gaussians, sample conditional Gaussian distribution , convert marginals samples back original distribution. samples used approximate sample resulting multivariate Gaussian conditional distribution. copulas may used, Gaussian copula benefit may use analytical expressions conditionals ùõçùíÆ‚Äæ|ùíÆ\\boldsymbol{\\mu}_{\\bar{\\mathcal{S}}|\\mathcal{S}} ùö∫ùíÆ‚Äæ|ùíÆ\\boldsymbol{\\Sigma}_{\\bar{\\mathcal{S}}|\\mathcal{S}}. Finally, may convert marginals back original distribution, use resulting samples approximate conditional expectations Kernel SHAP.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"empirical","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Empirical Conditional Distribution Approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"dependence structure marginal distributions ùê±\\boldsymbol{x} far Gaussian, neither two aforementioned methods work well. methods exist non-parametric estimation conditional densities, classic kernel estimator (Rosenblatt (1956)) non-parametric density estimation suffers greatly curse dimensionality provide way generate samples estimated distribution. situations, Aas, Jullum, L√∏land (2021) propose empirical conditional approach sample approximately p(ùê±ùíÆ‚Äæ|ùê±ùíÆ*)p(\\boldsymbol{x}_{\\bar{\\mathcal{S}}}|\\boldsymbol{x}_{\\mathcal{S}}^*). idea compute weights wùíÆ(ùê±*,ùê±i),=1,...,ntrainw_{\\mathcal{S}}(\\boldsymbol{x}^*,\\boldsymbol{x}^),\\ =1,...,n_{\\text{train}} training instances based Mahalanobis distances (SS subset ) instance ùê±*\\boldsymbol{x}^* explained. Instead sampling weighted (conditional) empirical distribution, Aas, Jullum, L√∏land (2021) suggests efficient variant, using KK instances largest weights: vcondKerSHAP(ùíÆ)=‚àëk=1KwùíÆ(ùê±*,ùê±[k])f(ùê±ùíÆ‚Äæ[k],ùê±ùíÆ*)‚àëk=1KwùíÆ(ùê±*,ùê±[k]),v_{\\text{condKerSHAP}}(\\mathcal{S}) = \\frac{\\sum_{k=1}^K w_{\\mathcal{S}}(\\boldsymbol{x}^*, \\boldsymbol{x}^{[k]}) f(\\boldsymbol{x}_{\\bar{\\mathcal{S}}}^{[k]}, \\boldsymbol{x}_{\\mathcal{S}}^*)}{\\sum_{k=1}^K w_{\\mathcal{S}}(\\boldsymbol{x}^*,\\boldsymbol{x}^{[k]})}, number samples KK used approximate prediction can instance chosen KK largest weights accounts fraction Œ∑\\eta, example 0.90.9, total weight. KK exceeds certain limit, instance 5,0005,000, might set limit. bandwidth parameter œÉ\\sigma used scale weights, must also specified. choice may viewed bias-variance trade-. small œÉ\\sigma puts weight closest training observations thereby gives low bias, high variance. œÉ‚Üí‚àû\\sigma \\rightarrow \\infty, method converges original Kernel SHAP assuming feature independence. Typically, features highly dependent, small œÉ\\sigma typically needed bias dominate. Aas, Jullum, L√∏land (2021) show proper criterion selecting œÉ\\sigma small-sample-size corrected version AIC known AICc. calculation computationally intensive, approximate version selection criterion also suggested. Details found Aas, Jullum, L√∏land (2021).","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"ctree","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Conditional Inference Tree Approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"previous three methods can handle numerical data. means data contains categorical/discrete/ordinal features, features first one-hot encoded. number levels/features large, feasible. approach handles mixed (.e., numerical, categorical, discrete, ordinal) features univariate multivariate responses conditional inference trees (Hothorn, Hornik, Zeileis (2006)). Conditional inference trees special tree-fitting procedure relies hypothesis tests choose splitting feature splitting point. tree fitting procedure sequential: first splitting feature chosen (feature least independent response), splitting point chosen feature. decreases chance biased towards features many splits (Hothorn, Hornik, Zeileis (2006)). use conditional inference trees (ctree) model conditional distribution, p(ùê±ùíÆ‚Äæ|ùê±ùíÆ*)p(\\boldsymbol{x}_{\\bar{\\mathcal{S}}}|\\boldsymbol{x}_{\\mathcal{S}}^*), found Shapley methodology. First, fit different conditional inference tree conditional distribution. tree fit given dependent features, end node ùê±ùíÆ*\\boldsymbol{x}_{\\mathcal{S}}^* found. , sample end node use resulting samples, ùê±ùíÆ‚Äæk,k=1,‚Ä¶,K\\boldsymbol{x}_{\\bar{\\mathcal{S}}}^k, k=1,\\ldots,K, approximating conditional expectations Kernel SHAP. See Redelmeier, Jullum, Aas (2020) details. conditional inference trees fit using party partykit packages (Hothorn Zeileis (2015)).","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"vaeac","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Variational AutoEncoder with Arbitrary Conditioning (vaeac) Approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"Another approach supports mixed features Variational AutoEncoder Arbitrary Conditioning (Olsen et al. (2022)), abbreviated vaeac. vaeac extension regular variational autoencoder (Kingma Welling (2014)), instead giving probabilistic representation distribution p(ùê±)p(\\boldsymbol{x}) gives probabilistic representation conditional distribution p(ùê±ùíÆ‚Äæ‚à£ùê±ùíÆ)p(\\boldsymbol{x}_{\\bar{\\mathcal{S}}} \\mid \\boldsymbol{x}_{\\mathcal{S}}), possible feature subsets ùíÆ‚äÜ‚Ñ≥\\mathcal{S}\\subseteq\\mathcal{M} simultaneously, ‚Ñ≥\\mathcal{M} set features. , single vaeac model needed model conditional distributions. vaeac consists three neural networks: full encoder, masked encoder, decoder. encoders map full masked/conditional input representations, .e., ùê±\\boldsymbol{x} ùê±ùíÆ\\boldsymbol{x}_{\\mathcal{S}}, respectively, latent probabilistic representations. Sampled instances latent probabilistic representations sent decoder, maps back feature space provides samplable probabilistic representation unconditioned features ùê±ùíÆ‚Äæ\\boldsymbol{x}_{\\bar{\\mathcal{S}}}. full encoder used training phase vaeac model guide training process masked encoder, former relies full input sample ùê±\\boldsymbol{x}, accessible deployment phase (generate Monte Carlo samples), access ùê±ùíÆ\\boldsymbol{x}_{\\mathcal{S}}. networks trained minimizing variational lower bound. See Section 3 Olsen et al. (2022) -depth introduction vaeac methodology. use vaeac model epoch obtains lowest validation IWAE score generate Monte Carlo samples used Shapley value computations. fit vaeac model using R package torch (Falbel Luraschi (2023)). main parameters number layers networks (vaeac.depth), width layers (vaeac.width), number dimensions latent space (vaeac.latent_dim), activation function layers networks (vaeac.activation_function), learning rate ADAM optimizer (vaeac.lr), number vaeac models initiate remedy poorly initiated model parameter values (vaeac.n_vaeacs_initialize), number learning epochs (vaeac.epochs). See ?shapr::setup_approach.vaeac detailed description parameters. additional extra parameters can set including named list call explain() function. example, can change batch size 32 including vaeac.extra_parameters = list(vaeac.batch_size = 32) argument explain() function. See ?shapr::vaeac_get_extra_para_default description possible extra parameters vaeac approach. Note main parameters entered arguments directly explain() function, extra parameters specified named list called vaeac.extra_parameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"categorical-approach","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Categorical Approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"features categorical, can estimate conditional expectations using basic statistical formulas. example, three features, x1,x2,x3x_1, x_2, x_3 three levels (indicated 1, 2, 3), provided table counts indicating many times combination feature values occurs, can estimate marginal conditional probabilities follows. Marginal probabilities estimated dividing number times given feature (features) takes certain value data set total number observations data set. Conditional probabilities (example, P(X1=1|X2=1)P(X_1 = 1 | X_2 = 1)) estimated first subsetting data set reflect conditioning (.e., extracting rows X2=1X_2 = 1), dividing number times feature left hand side || takes given value subset total number observations subset. marginal conditional probabilities estimated combinations feature values, conditional expectation can calculated. example, expected value X1X_1 given X2=1X_2 = 1 X3=2X_3 = 2 E(X1|X2,X3)=‚àëxxP(X1=x|X2=1,X3=2)=‚àëxxP(X1=x,X2=1,X3=2)P(X2=1,X3=2).E(X_1|X_2, X_3) = \\sum_{x}x P(X_1 = x | X_2=1, X_3=2) = \\sum_{x} x \\frac{P(X_1 = x, X_2 = 1, X_3 = 2)}{P(X_2=1, X_3=2)}.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"Regression_approaches","dir":"Articles","previous_headings":"Kernel SHAP and dependence-aware estimators","what":"Separate and Surrogate Regression Approaches","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"Another paradigm estimating contribution function regression paradigm. contrast methods , belong Monte Carlo paradigm, regression-based methods use regression models estimate contribution function v(S)=E[f(ùê±)|ùê±S=ùê±S*]v(S) = E[f(\\boldsymbol{x})|\\boldsymbol{x}_S = \\boldsymbol{x}_S^*] directly. separate regression method class fits separate regression model coalition SS, surrogate regression method class fits single regression model simultaneously predict contribution function coalitions. refer Olsen et al. (2024) one use different paradigms, method classes, methods. separate vignette (Shapley value explanations using regression paradigm), elaborate demonstrate regression paradigm. describe specify regression model, enable automatic cross-validation model‚Äôs hyperparameters, apply pre-processing steps data fitting regression models. Olsen et al. (2024) divides regression paradigm separate surrogate regression method classes. separate vignette, briefly introduce two method classes. -depth explanation, refer reader Sections 3.5 3.6 Olsen et al. (2024).","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"ex","dir":"Articles","previous_headings":"","what":"Estimation approaches and plotting functionality","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"following example shows simple xgboost model trained using airquality dataset, shapr can used explain individual predictions. Since approach used estimate contribution functions depend type data one working , user must specify approach used approach argument. Allowed values \"gaussian\", \"copula\", \"empirical\", \"ctree\", \"vaeac\", \"categorical\", \"timeseries\", \"independence\", \"regression_separate\", \"regression_surrogate\". First load shapr package  multiple plot options specified plot_type argument plot. waterfall option shows changes prediction score due feature‚Äôs contribution (Shapley values): multiple plot options specified plot_type argument plot. waterfall option shows changes prediction score due feature‚Äôs contribution (Shapley values):  two plot options, \"beeswarm\" \"scatter\", can useful many observations want explain. purpose illustration, explain whole airquality dataset (including training data) plot types. plot_type = \"beeswarm\" summarizes distribution Shapley values along x-axis across features. point gives Shapley value given instance, points colored feature value instance:  plot_type = \"scatter\" plots feature values x-axis Shapley values y-axis, well (optionally) background scatter_hist showing distribution feature data:  can use mixed (.e., continuous, categorical, ordinal) data ctree vaeac. Use ctree mixed data following manner:  can specify parameters used build conditional inference trees following manner. default values based Hothorn, Hornik, Zeileis (2006). features categorical, one may use categorical approach follows: Shapley values can used explain predictive model. predictive models taking time series input, approach='timeseries' can used. models, joint behavior consecutive time points often important outcome single time points. Therefore, makes sense derive Shapley value segments time series instead single time point. shapr can achieved group attribute. optional parameters approach='timeseries' timeseries.fixed_sigma timeseries.bounds (vector indicating upper lower bounds time series necessary).","code":"library(shapr) library(xgboost) library(data.table) #> data.table 1.17.8 using 11 threads (see ?getDTthreads).  Latest news: r-datatable.com  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\") y_var <- \"Ozone\"  ind_x_explain <- 1:6 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Set seed for reproducibility set.seed(123)  # Fitting a basic xgboost model to the training data model <- xgboost::xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features p0 <- mean(y_train)  # Computing the actual Shapley values with Kernel SHAP accounting for feature dependence using # the empirical (conditional) distribution approach with bandwidth parameter sigma = 0.1 (default) explanation <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:02 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1676ef65031.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Printing the Shapley values for the test data. # For more information about the interpretation of the values in the table, see ?shapr::explain. print(explanation) #>    explain_id  none Solar.R  Wind  Temp  Month #>         <int> <num>   <num> <num> <num>  <num> #> 1:          1  43.1  13.212  4.79 -25.6  -5.60 #> 2:          2  43.1  -9.973  5.83 -11.0  -7.83 #> 3:          3  43.1  -2.292 -7.05 -10.2  -4.45 #> 4:          4  43.1   3.325 -3.24 -10.2  -6.66 #> 5:          5  43.1   4.304 -2.63 -14.2 -12.27 #> 6:          6  43.1   0.479 -5.25 -12.6  -6.65  # Plot the resulting explanations for observations 1 and 6 plot(explanation, bar_plot_phi0 = FALSE, index_x_explain = c(1, 6)) plot(explanation, plot_type = \"waterfall\", index_x_explain = c(1, 6)) x_explain_many <- data[, ..x_var] explanation_plot <- explain(   model = model,   x_explain = x_explain_many,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:05 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 111 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16774b12138.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. plot(explanation_plot, plot_type = \"beeswarm\") plot(explanation_plot, plot_type = \"scatter\", scatter_hist = TRUE) # convert the month variable to a factor data[, Month_factor := as.factor(Month)]  data_train_cat <- data[-ind_x_explain, ] data_explain_cat <- data[ind_x_explain, ]  x_var_cat <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month_factor\")  x_train_cat <- data_train_cat[, ..x_var_cat] x_explain_cat <- data_explain_cat[, ..x_var_cat]  # Fitting an lm model here as xgboost does not handle categorical features directly # (workaround in example below) lm_formula <- as.formula(paste0(y_var, \" ~ \", paste0(x_var_cat, collapse = \" + \")))  model_lm_cat <- lm(lm_formula, data_train_cat)  p0 <- mean(y_train) explanation_lm_cat <- explain(   model = model_lm_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   approach = \"ctree\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:11 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: ctree #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1676c05f54.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Plot the resulting explanations for observations 1 and 6, excluding # the no-covariate effect plot(explanation_lm_cat, bar_plot_phi0 = FALSE, index_x_explain = c(1, 6)) # Use the conditional inference tree approach # We can specify parameters used to build trees by specifying mincriterion, # minsplit, minbucket explanation_ctree <- explain(   model = model_lm_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   approach = \"ctree\",   phi0 = p0,   seed = 1,   ctree.mincriterion = 0.80,   ctree.minsplit = 20,   ctree.minbucket = 20 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:12 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: ctree #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167e4c8ba2.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Default parameters (based on (Hothorn, 2006)) are: # mincriterion = 0.95 # minsplit = 20 # minbucket = 7 # For the sake of illustration, convert ALL features to factors data[, Solar.R_factor := as.factor(cut(Solar.R, 10))] data[, Wind_factor := as.factor(cut(Wind, 3))] data[, Temp_factor := as.factor(cut(Temp, 2))] data[, Month_factor := as.factor(Month)]  data_train_all_cat <- data[-ind_x_explain, ] data_explain_all_cat <- data[ind_x_explain, ]   x_var_all_cat <- c(\"Solar.R_factor\", \"Wind_factor\", \"Temp_factor\", \"Month_factor\")  x_train_all_cat <- data_train_all_cat[, ..x_var_all_cat] x_explain_all_cat <- data_explain_all_cat[, ..x_var_all_cat]  # Fit an lm model here lm_formula_all_cat <- as.formula(paste0(y_var, \" ~ \", paste0(x_var_all_cat, collapse = \" + \")))  model_lm_all_cat <- lm(lm_formula_all_cat, data_train_all_cat)  explanation_cat_method <- explain(   model = model_lm_all_cat,   x_explain = x_explain_all_cat,   x_train = x_train_all_cat,   approach = \"categorical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: categorical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1671314a236.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Simulate time series data with AR(1)-structure set.seed(1) data_ts <- data.frame(matrix(NA, ncol = 41, nrow = 4)) for (n in 1:100) {   set.seed(n)   e <- rnorm(42, mean = 0, sd = 1)    m_1 <- 0   for (i in 2:length(e)) {     m_1[i] <- 1 + 0.8 * m_1[i - 1] + e[i]   }   data_ts[n, ] <- m_1[-1] } data_ts <- data.table::as.data.table(data_ts)  x_var_ts <- paste0(\"X\", 1:40) y_var_ts <- \"X41\"  ind_x_explain <- 1:6 data_ts_train <- data_ts[-ind_x_explain]  # Creating a predictive model (for illustration just predicting the next point in the time series with a linear model) lm_ts_formula <- as.formula(X41 ~ .) model_lm_ts <- lm(lm_ts_formula, data_ts_train)  x_explain_ts <- data_ts[ind_x_explain, ..x_var_ts] x_train_ts <- data_ts[-ind_x_explain, ..x_var_ts]  # Splitting the time series into 4 segments group_ts <- list(   S1 = paste0(\"X\", 1:10),   S2 = paste0(\"X\", 11:20),   S3 = paste0(\"X\", 21:30),   S4 = paste0(\"X\", 31:40) )   p0_ts <- mean(unlist(data_ts_train[, ..y_var_ts]))  explanation_timeseries <- explain(   model = model_lm_ts,   x_explain = x_explain_ts,   x_train = x_train_ts,   approach = \"timeseries\",   phi0 = p0_ts,   seed = 1,   group = group_ts ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_groups = 16`, and #>   is therefore set to `2^n_groups = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: timeseries #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of group-wise Shapley values: 4 #>  #> ‚Ä¢ Feature groups: S1: {\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", #> \"X9\", \"X10\"}; S2: {\"X11\", \"X12\", \"X13\", \"X14\", \"X15\", \"X16\", \"X17\", #> \"X18\", \"X19\", \"X20\"}; S3: {\"X21\", \"X22\", \"X23\", \"X24\", \"X25\", \"X26\", #> \"X27\", \"X28\", \"X29\", \"X30\"}; S4: {\"X31\", \"X32\", \"X33\", \"X34\", \"X35\", #> \"X36\", \"X37\", \"X38\", \"X39\", \"X40\"} #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16717361378.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"MSEv","dir":"Articles","previous_headings":"Estimation approaches and plotting functionality","what":"MSEv evaluation criterion","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"can use MSEv\\operatorname{MSE}_{v} criterion proposed Frye et al. (2021), later used , e.g., Olsen et al. (2022) Olsen et al. (2024), evaluate rank approaches/methods. MSEv\\operatorname{MSE}_{v} given vÃÇùöö{\\hat{v}}_{\\texttt{q}} estimated contribution function using method ùöö\\texttt{q} NùíÆ=|ùí´*(‚Ñ≥)|=2M‚àí2N_\\mathcal{S} = |\\mathcal{P}^*(\\mathcal{M})| = 2^M-2, .e., removed empty (ùíÆ=‚àÖ\\mathcal{S} = \\emptyset) grand combinations (ùíÆ=‚Ñ≥\\mathcal{S} = \\mathcal{M}) method independent. Meaning two combinations influence ranking methods methods used compute contribution function . motivation behind MSEv\\operatorname{MSE}_{v} criterion ùîºùíÆùîºùê±(vùöùùöõùöûùöé(ùíÆ,ùê±)‚àívÃÇùöö(ùíÆ,ùê±))2\\mathbb{E}_\\mathcal{S}\\mathbb{E}_{\\boldsymbol{x}} (v_{\\texttt{true}}(\\mathcal{S},\\boldsymbol{x}) - \\hat{v}_{\\texttt{q}}(\\mathcal{S}, \\boldsymbol{x}))^2 can decomposed see Appendix Covert, Lundberg, Lee (2020). first term right-hand side equation can estimated MSEv\\operatorname{MSE}_{v}, second term fixed (unknown) constant influenced approach . Thus, low value MSEv\\operatorname{MSE}_{v} indicates estimated contribution function vÃÇùöö\\hat{v}_{\\texttt{q}} closer true counterpart vùöùùöõùöûùöév_{\\texttt{true}} high value. shapr, allow weighting combinations MSEv\\operatorname{MSE}_{v} evaluation criterion either uniformly using corresponding Shapley kernel weights (sampling frequencies sampling combinations used). determined logical parameter MSEv_uniform_comb_weights explain() function, default uniform weighting, , MSEv_uniform_comb_weights = TRUE.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"advantage","dir":"Articles","previous_headings":"Estimation approaches and plotting functionality > MSEv evaluation criterion","what":"Advantage:","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"advantage MSEv\\operatorname{MSE}_{v} criterion vùöùùöõùöûùöév_\\texttt{true} involved. Thus, can apply evaluation criterion real-world data sets true Shapley values unknown.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"disadvantages","dir":"Articles","previous_headings":"Estimation approaches and plotting functionality > MSEv evaluation criterion","what":"Disadvantages:","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"First, can use MSEv\\operatorname{MSE}_{v} criterion rank methods assess closeness optimum since minimum value MSEv\\operatorname{MSE}_{v} criterion unknown. Second, criterion evaluates contribution functions Shapley values. Olsen et al. (2024) observed relatively linear relationship MSEv\\operatorname{MSE}_{v} criterion mean absolute error (MAE)(\\operatorname{MAE}) true estimated Shapley values extensive simulation studies true Shapley values known. , method achieves low MSEv\\operatorname{MSE}_{v} score also tends obtain low MAE\\operatorname{MAE} score, vice versa.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"confidence-intervals","dir":"Articles","previous_headings":"Estimation approaches and plotting functionality > MSEv evaluation criterion","what":"Confidence intervals","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"MSEv\\operatorname{MSE}_{v} criterion can written MSEv=1Nexplain‚àë=1NexplainMSEv,explain \\operatorname{MSE}_{v} = \\frac{1}{N_\\text{explain}}\\sum_{=1}^{N_\\text{explain}} \\operatorname{MSE}_{v,\\text{explain }}. can therefore use central limit theorem compute approximate confidence interval MSEv\\operatorname{MSE}_{v} criterion. MSEv¬±tŒ±/2SD(MSEv)Nexplain\\operatorname{MSE}_{v} \\pm t_{\\alpha/2}\\frac{\\operatorname{SD}(\\operatorname{MSE}_{v})}{\\sqrt{N_\\text{explain}}} (1‚àíŒ±/2)%(1-\\alpha/2)\\% approximate confidence interval evaluation criterion, tŒ±/2t_{\\alpha/2} Œ±/2\\alpha/2 percentile TNexplain‚àí1T_{N_\\text{explain}-1} distribution. Note NexplainN_\\text{explain} large (rule thumb least 3030) central limit theorem valid. quantities MSEv\\operatorname{MSE}_{v} SD(MSEv)Nexplain\\frac{\\operatorname{SD}(\\operatorname{MSE}_{v})}{\\sqrt{N_\\text{explain}}} returned explain() function MSEv list data tables. can also compute similar approximate confidence interval MSEv\\operatorname{MSE}_{v} criterion combination/coalition averaging observations. However, make sense direction, .e., averaging combinations observation, combination different prediction tasks.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"msev-examples","dir":"Articles","previous_headings":"Estimation approaches and plotting functionality > MSEv evaluation criterion","what":"MSEv examples","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"Start explaining predictions using different methods combining lists. can compare different approaches creating plots MSEv\\operatorname{MSE}_{v} evaluation criterion. main plot interest MSEv_bar, displays MSEv\\operatorname{MSE}_{v} evaluation criterion method averaged combinations/coalitions test observations/explicands. However, can also look plots averaged observations combinations (bar line plots).   can specify index_x_explain id_combination parameters plot_MSEv_eval_crit() plot certain test observations combinations, respectively.  can also alter plots design-wise code .","code":"# We use more explicands here for more stable confidence intervals ind_x_explain_many <- 1:25 x_train <- data[-ind_x_explain_many, ..x_var] y_train <- data[-ind_x_explain_many, get(y_var)] x_explain <- data[ind_x_explain_many, ..x_var]  # Fitting a basic xgboost model to the training data model <- xgboost::xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features p0 <- mean(y_train)  # Independence approach explanation_independence <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"independence\",   phi0 = p0,   seed = 1,   n_MC_samples = 1e2,   MSEv_uniform_comb_weights = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:18 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: independence #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 25 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1673253594c.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Empirical approach explanation_empirical <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1,   n_MC_samples = 1e2,   MSEv_uniform_comb_weights = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:19 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16776248c80.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Gaussian 1e1 approach explanation_gaussian_1e1 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1,   n_MC_samples = 1e1,   MSEv_uniform_comb_weights = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:23 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 10 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16745fcf708.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Gaussian 1e2 approach explanation_gaussian_1e2 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1,   n_MC_samples = 1e2,   MSEv_uniform_comb_weights = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:23 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167295d594f.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Combined approach explanation_combined <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = c(\"gaussian\", \"empirical\", \"independence\"),   phi0 = p0,   seed = 1,   n_MC_samples = 1e2,   MSEv_uniform_comb_weights = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:24 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian, empirical, and independence #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16767f00602.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Create a list of explanations with names explanation_list_named <- list(   \"Ind.\" = explanation_independence,   \"Emp.\" = explanation_empirical,   \"Gaus. 1e1\" = explanation_gaussian_1e1,   \"Gaus. 1e2\" = explanation_gaussian_1e2,   \"Combined\" = explanation_combined ) # Create the MSEv plots with approximate 95% confidence intervals MSEv_plots <- plot_MSEv_eval_crit(explanation_list_named,   plot_type = c(\"overall\", \"comb\", \"explicand\"),   CI_level = 0.95 )  # 5 plots are made names(MSEv_plots) #> [1] \"MSEv_explicand_bar\"        \"MSEv_explicand_line_point\" #> [3] \"MSEv_coalition_bar\"        \"MSEv_coalition_line_point\" #> [5] \"MSEv_bar\" # The main plot of the overall MSEv averaged over both the combinations and observations MSEv_plots$MSEv_bar # The MSEv averaged over only the explicands for each combinations MSEv_plots$MSEv_combination_bar #> NULL  # The MSEv averaged over only the combinations for each observation/explicand MSEv_plots$MSEv_explicand_bar # To see which coalition S each of the `id_combination` corresponds to, # i.e., which features that are conditions on. explanation_list_named[[1]]$MSEv$MSEv_combination[, c(\"id_combination\", \"features\")] #> NULL # We can specify which test observations or combinations to plot plot_MSEv_eval_crit(explanation_list_named,   plot_type = \"explicand\",   index_x_explain = c(1, 3:4, 6),   CI_level = 0.95 )$MSEv_explicand_bar plot_MSEv_eval_crit(explanation_list_named,   plot_type = \"comb\",   id_coalition = c(3, 4, 9, 13:15),   CI_level = 0.95 )$MSEv_combination_bar #> NULL bar_text_n_decimals <- 1 plot_MSEv_eval_crit(explanation_list_named) +   ggplot2::scale_x_discrete(limits = rev(levels(MSEv_plots$MSEv_bar$data$Method))) +   ggplot2::coord_flip() +   ggplot2::scale_fill_brewer(palette = \"Paired\") +   ggplot2::theme_minimal() + # This must be set before other theme calls   ggplot2::theme(     plot.title = ggplot2::element_text(size = 10),     legend.position = \"bottom\"   ) +   ggplot2::geom_text(     ggplot2::aes(label = sprintf(       paste(\"%.\", sprintf(\"%d\", bar_text_n_decimals), \"f\", sep = \"\"),       round(MSEv, bar_text_n_decimals)     )),     vjust = -0.35, # This number might need altering for different plots sizes     hjust = 1.1, # This number might need altering for different plots sizes     color = \"black\",     position = ggplot2::position_dodge(0.9),     size = 4   )"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"iterative","dir":"Articles","previous_headings":"","what":"Iterative estimation","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"Iterative estimation default computing Shapley values six features (feature groups), can always manually overridden setting iterative = FALSE explain() function. idea behind iterative estimation estimate sufficiently accurate Shapley value estimates faster. First, initial number coalitions sampled, , bootsrapping used estimate variance Shapley values. convergence criterion used determine variances Shapley values sufficiently small. variances high, estimate number required samples reach convergence, thereby add coalitions. process repeated variances threshold. Specifics related iterative process convergence criterion set iterative_args argument. convergence criterion use adopted Covert Lee (2021), slightly modified work multiple observations mediani(maxjsdÃÇ(œïÃÇij)maxjœïÃÇij‚àíminjœïÃÇij)<t \\operatorname{median}_i \\left(   \\frac{     \\max_j \\hat{\\text{sd}}(\\hat{\\phi}_{ij})   }{     \\max_j \\hat{\\phi}_{ij} - \\min_j \\hat{\\phi}_{ij}   } \\right) < t œïÃÇij\\hat{\\phi}_{ij} Shapley value feature jj observation ii, sd(œïij)\\text{sd}(\\phi_{ij}) (bootstrap) estimated standard deviation. default value tt 0.02. provide examples use iterative estimation procedure.","code":"library(xgboost) library(data.table)  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\", \"Day\") y_var <- \"Ozone\"  ind_x_explain <- 1:6 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Set seed for reproducibility set.seed(123)  # Fitting a basic xgboost model to the training data model <- xgboost::xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features p0 <- mean(y_train)  # Explanation with iterative computation ex <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1,   iterative = TRUE,   iterative_args = list(convergence_tol = 0.1) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:32 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 32`, and #>   is therefore set to `2^n_features = 32`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 5 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16749ca702f.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 6 of 32 coalitions, 6 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 8 of 32 coalitions, 2 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 12 of 32 coalitions, 4 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 14 of 32 coalitions, 2 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 32 coalitions, 2 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 18 of 32 coalitions, 2 new."},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary, Printing, and Result Extraction","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"shown , print(explain_object) displays estimated Shapley values object created using explain(). default behavior print() method shapr objects. However, print.shapr also includes argument controls printed. allows users also display: - standard deviations arising coalition sampling (= \"shapley_sd\"), - variants MSEv criterion introduced , using = \"MSEv\", \"MSEv_explicand\", \"MSEv_coalition\". summary(explain_object) function provides neatly formatted summary object (invisibly) returns complete list summary components. Internally, summary.shapr calls get_results(), produces full set components, including: parameters used, intermediate Shapley value estimates (standard deviations), estimates v(S)v(S), . See ?get_results full overview returned output. , illustrate capabilities using iterative explanation object ex computed .","code":"# Uses the object ex to illustrate printing and summary functionality print(ex) # Prints the estimated Shapley values by default #>    explain_id  none Solar.R  Wind  Temp Month    Day #>         <int> <num>   <num> <num> <num> <num>  <num> #> 1:          1  43.1    1.26  6.49 -21.9 -6.46 -1.270 #> 2:          2  43.1   -3.72  2.28 -14.3 -4.42 -0.948 #> 3:          3  43.1   -1.16 -8.89 -12.9 -3.87 -0.190 #> 4:          4  43.1    4.16 -6.22 -16.9 -3.48 -5.188 #> 5:          5  43.1    3.09  1.76 -24.7 -6.00 -4.695 #> 6:          6  43.1   -2.60 -5.15 -12.5 -3.67 -1.949 print(ex, what = \"shapley_sd\") # Prints the estimated standard deviations of the Shapley values #>    explain_id  none Solar.R  Wind   Temp Month   Day #>         <int> <num>   <num> <num>  <num> <num> <num> #> 1:          1     0   0.539  2.07 0.0537  2.03 0.271 #> 2:          2     0   0.770  1.36 0.2302  1.28 0.431 #> 3:          3     0   0.854  1.37 0.3309  1.23 0.493 #> 4:          4     0   1.310  2.29 0.7248  1.93 0.394 #> 5:          5     0   1.075  1.74 0.6343  1.69 0.750 #> 6:          6     0   1.296  1.59 0.6154  1.43 0.569 print(ex, what = \"MSEv\") # Prints the MSEv evaluation criterion #>     MSEv MSEv_sd #>    <num>   <num> #> 1:   252    76.3  summary_ex <- summary(ex) #>  #> ‚îÄ‚îÄ Summary of Shapley value explanation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ä¢ Computed with`shapr::explain()` in 4.2 seconds, started 2025-08-21 #> 09:01:32 #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 5 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Number of coalitions used: 18 (of total 32) #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16749ca702f.rds' #>  #> ‚îÄ‚îÄ Convergence info #> ‚úî Iterative Shapley value estimation stopped at 18 coalitions after 6 iterations, due to: #> Standard deviation convergence threshold (0.1) reached: 0.095! #>  #> ‚îÄ‚îÄ Estimated Shapley values (sd in parentheses) #>    explain_id      none      Solar.R         Wind          Temp        Month #>         <int>    <char>       <char>       <char>        <char>       <char> #> 1:          1 43.09 (0)  1.26 (0.54)  6.49 (2.07) -21.89 (0.05) -6.46 (2.03) #> 2:          2 43.09 (0) -3.72 (0.77)  2.28 (1.36) -14.30 (0.23) -4.42 (1.28) #> 3:          3 43.09 (0) -1.16 (0.85) -8.89 (1.37) -12.86 (0.33) -3.87 (1.23) #> 4:          4 43.09 (0)  4.16 (1.31) -6.22 (2.29) -16.94 (0.72) -3.48 (1.93) #> 5:          5 43.09 (0)  3.09 (1.08)  1.76 (1.74) -24.73 (0.63) -6.00 (1.69) #> 6:          6 43.09 (0) -2.60 (1.30) -5.15 (1.59) -12.49 (0.62) -3.67 (1.43) #>             Day #>          <char> #> 1: -1.27 (0.27) #> 2: -0.95 (0.43) #> 3: -0.19 (0.49) #> 4: -5.19 (0.39) #> 5: -4.70 (0.75) #> 6: -1.95 (0.57) #>  #>  #> ‚îÄ‚îÄ Estimated MSEv  #>  #> Estimated MSE of v(S) = 252 (with sd = 76)  summary_ex$shapley_est # The estimated Shapley values #>    explain_id   none Solar.R    Wind    Temp   Month      Day #>         <int>  <num>   <num>   <num>   <num>   <num>    <num> #> 1:          1 43.086  1.2581  6.4857 -21.888 -6.4643 -1.27021 #> 2:          2 43.086 -3.7166  2.2818 -14.300 -4.4155 -0.94828 #> 3:          3 43.086 -1.1594 -8.8924 -12.857 -3.8660 -0.19021 #> 4:          4 43.086  4.1632 -6.2204 -16.939 -3.4778 -5.18784 #> 5:          5 43.086  3.0899  1.7643 -24.729 -6.0042 -4.69524 #> 6:          6 43.086 -2.6017 -5.1481 -12.492 -3.6724 -1.94911 summary_ex$shapley_sd # The estimated standard deviations of the Shapley values #>    explain_id  none Solar.R   Wind    Temp  Month     Day #>         <int> <num>   <num>  <num>   <num>  <num>   <num> #> 1:          1     0 0.53861 2.0722 0.05372 2.0327 0.27087 #> 2:          2     0 0.76982 1.3551 0.23023 1.2844 0.43089 #> 3:          3     0 0.85360 1.3669 0.33087 1.2281 0.49341 #> 4:          4     0 1.31039 2.2946 0.72485 1.9312 0.39398 #> 5:          5     0 1.07501 1.7426 0.63426 1.6942 0.74981 #> 6:          6     0 1.29621 1.5901 0.61541 1.4318 0.56859 summary_ex$timing_summary$total_time_secs # Total computation time in seconds #> [1] 4.2177 summary_ex$parameters$n_MC_samples # Number of Monte Carlo samples used #> [1] 1000  summary_ex$parameters$gaussian.mu # Estimated mean vector (Gaussian approach) #> [1] 184.2381   9.9181  78.4381   7.3429  16.6190 summary_ex$parameters$gaussian.cov_mat # Estimated covariance matrix (Gaussian approach) #>           Solar.R     Wind     Temp   Month      Day #> Solar.R 8378.0678 -41.1072 284.0966 -9.1882 -42.7738 #> Wind     -41.1072  13.0369 -17.3205 -1.0274   1.7137 #> Temp     284.0966 -17.3205  86.6908  4.4734 -16.0623 #> Month     -9.1882  -1.0274   4.4734  1.9967  -1.7143 #> Day      -42.7738   1.7137 -16.0623 -1.7143  71.3535  res_ex <- get_results(ex) # Gives output equivalent to summary(ex), but without the printed summary  # You may also extract individual summary components directly using get_results() get_results(ex, what = \"shapley_sd\") #>    explain_id  none Solar.R   Wind    Temp  Month     Day #>         <int> <num>   <num>  <num>   <num>  <num>   <num> #> 1:          1     0 0.53861 2.0722 0.05372 2.0327 0.27087 #> 2:          2     0 0.76982 1.3551 0.23023 1.2844 0.43089 #> 3:          3     0 0.85360 1.3669 0.33087 1.2281 0.49341 #> 4:          4     0 1.31039 2.2946 0.72485 1.9312 0.39398 #> 5:          5     0 1.07501 1.7426 0.63426 1.6942 0.74981 #> 6:          6     0 1.29621 1.5901 0.61541 1.4318 0.56859 get_results(ex, what = \"dt_vS\") #> Index: <id_coalition> #>     id_coalition p_hat1_1 p_hat1_2 p_hat1_3 p_hat1_4 p_hat1_5 p_hat1_6 #>            <num>    <num>    <num>    <num>    <num>    <num>    <num> #>  1:            1   43.086   43.086   43.086   43.086   43.086   43.086 #>  2:            2   20.039   21.631   21.344   18.789   19.603   17.306 #>  3:            3   46.041   45.072   45.052   44.502   44.910   44.222 #>  4:            4   43.805   33.235   39.879   51.410   53.133   32.563 #>  5:            5   40.055   37.617   23.363   25.468   36.338   21.362 #>  6:            6   33.164   32.626   32.341   32.109   32.271   31.993 #>  7:            7   17.311   19.722   20.930   15.424   16.352   13.905 #>  8:            8   46.974   33.761   41.975   49.616   54.302   32.537 #>  9:            9   54.267   36.021   25.105   34.668   53.820   22.055 #> 10:           10   18.412   21.230   21.117   13.870   13.453   17.950 #> 11:           11   26.620   23.578   15.561   26.318   25.754   20.190 #> 12:           12   42.102   30.662   22.379   32.084   43.571   21.228 #> 13:           13   24.729   23.271   16.715   20.409   23.440   17.828 #> 14:           14   16.767   19.115   20.317   15.660   16.196   14.509 #> 15:           15   41.791   29.288   19.374   25.790   40.506   18.723 #> 16:           16   26.921   24.228   17.002   27.350   26.326   21.189 #> 17:           17   19.873   18.993   15.369   15.603   18.250   13.808 #> 18:           18   21.207   21.987   16.120   15.424   12.512   17.223"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"para","dir":"Articles","previous_headings":"","what":"Parallelization","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"shapr package supports parallelization Shapley value estimation process future package. parallelization conducted batches v(S)-values. therefore start describing batch computing.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"batch-computation","dir":"Articles","previous_headings":"Parallelization","what":"Batch computation","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"computational complexity Shapley value based explanations grows fast number features, number conditional expectations one needs estimate Shapley formula grows exponentially. outlined , estimating conditional expectations also computationally expensive, typically requiring estimation conditional probability distribution, followed Monte Carlo integration. computations heavy CPU, also require lot memory (RAM), typically limited resource. resource-hungry computations (computation v(S)) sequential batches different feature subsets SS, memory usage can significantly reduced. user can control number batches setting two arguments extra_computation_args$max_batch_size (defaults 10) extra_computation_args$min_n_batches (defaults 10).","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"parallelized-computation","dir":"Articles","previous_headings":"Parallelization","what":"Parallelized computation","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"addition reducing memory consumption, batch computing allows computations within batch performed parallel. parallelization shapr::explain() handled future_apply package builds future environment. packages work OSes, allow user decide parallelization backend (multiple R processes forking), work directly HPC clusters, also supports progress updates parallelized task via associated progressr package (see Verbosity progress updates). Note , since takes time duplicate data different processes/machines running parallel, always preferable run shapr::explain() parallel, least many parallel sessions/workers. Parallelization also increases memory consumption proportionally, may want limit number workers reason . basic example parallelization two workers.","code":"library(future) future::plan(multisession, workers = 2)  explanation_par <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:37 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 32`, and #>   is therefore set to `2^n_features = 32`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 5 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1674d923856.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 32 of 32 coalitions.  future::plan(sequential) # To return to non-parallel computation"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"verbose","dir":"Articles","previous_headings":"","what":"Verbosity and progress updates","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"verbose argument controls verbosity output running explain(), allows one strings \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation performed, \"progress displays information calculation process function currently , \"convergence\" displays information close convergence Shapley value estimates (iterative estimation), \"shapley\" displays (intermediate) Shapley value estimates standard deviations + final estimates, \"vS_details\" displays information v(S) estimates approaches. user wants printout, argument can set NULL. addition, progress updates computation v(S) values (optionally) provided R-package progressr. gives user full control visual appearance progress updates. main reason providing separate progress update feature integrates seamlessly parallelization framework future used shapr (see Parallelization), apparently framework allowing progress updates also parallelized tasks. progress updates can used combination , independently , verbose argument. progress updates via progressr can enabled current R-session running command progressr::handlers(local=TRUE), calling explain(). use progress updates single call explain(), one can wrap call using progressr::with_progress follows: progressr::with_progress({ shapr::explain() }) default appearance progress updates basic ASCII-based horizontal progress bar. variants can chosen passing different strings progressr::handlers(), require additional packages. using RStudio, progress can displayed directly GUI progressr::handlers('rstudio') (requires rstudioapi package). running Windows, may use pop-GUI progress bar progressr::handlers('handler_winprogressbar'). wrapper progressbar flexible cli package, also available progressr::handlers('cli'). full list progression handlers customization options available progressr, see progressr vignette. full code example using progressr shapr shown :","code":"library(progressr) progressr::handlers(global = TRUE) handlers(\"cli\") # If no progression handler is specified, the txtprogressbar is used # Other progression handlers: # progressr::handlers('progress') # requires the 'progress' package # progressr::handlers('rstudio') # requires the 'rstudioapi' package # progressr::handlers('handler_winprogressbar') # Window only ex_progress <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 )  # ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                       32% | Estimating v(S) ETA:  2s"},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"combined","dir":"Articles","previous_headings":"Advanced usage","what":"Combined approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"addition letting user select one five aforementioned approaches estimating conditional distribution data (.e. approach equals either \"gaussian\", \"copula\", \"empirical\", \"ctree\", \"vaeac\", \"categorical\") \"timeseries\", package allows user combine given approaches. 'regression_surrogate' 'regression_separate approaches supported combined approach. simplify usage, flexibility restricted approach used conditioning number features. also line Aas, Jullum, L√∏land (2021, sec. 3.4). can done setting approach equal character vector, length vector one less number features model. Consider situation trained model consists 10 features, like use \"empirical\" approach condition 1-3 features, \"copula\" approach condition 4-5 features, \"gaussian\" approach conditioning 6 features. can applied simply passing approach = c(rep(\"empirical\", 3), rep(\"copula\", 2), rep(\"gaussian\", 4)), .e.¬†approach[] determines method use conditioning features. Conditioning features needs approach given complete prediction , thus part vector. code exemplifies approach case four features, using \"empirical\", \"copula\" \"gaussian\" conditioning respectively 1, 2 3 features.  second example using \"ctree\" condition 1 2 features, \"empirical\" conditioning 3 features:","code":"library(xgboost) library(data.table)  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\") y_var <- \"Ozone\"  ind_x_explain <- 1:6 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Set seed for reproducibility set.seed(123)  # Fitting a basic xgboost model to the training data model <- xgboost::xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features p0 <- mean(y_train)   # Use the combined approach explanation_combined <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = c(\"empirical\", \"copula\", \"gaussian\"),   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:44 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical, copula, and gaussian #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1673f27bdec.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Plot the resulting explanations for observations 1 and 6, excluding # the no-covariate effect plot(explanation_combined, bar_plot_phi0 = FALSE, index_x_explain = c(1, 6)) # Use the combined approach explanation_combined <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = c(\"ctree\", \"ctree\", \"empirical\"),   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:44 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: ctree, ctree, and empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167443a4f41.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"explain-groups-of-features","dir":"Articles","previous_headings":"Advanced usage","what":"Explain groups of features","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"cases, especially number features large, may appropriate explain predictions terms groups features instead single features, see (Jullum, Redelmeier, Aas (2021)) intuition real-world examples. Explaining predictions terms groups features easy using shapr:","code":"# Define the feature groups group_list <- list(   A = c(\"Temp\", \"Month\"),   B = c(\"Wind\", \"Solar.R\") )  # Use the empirical approach explanation_group <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1,   group = group_list ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_groups = 4`, and is #>   therefore set to `2^n_groups = 4`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of group-wise Shapley values: 2 #>  #> ‚Ä¢ Feature groups: A: {\"Temp\", \"Month\"}; B: {\"Wind\", \"Solar.R\"} #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1673a5edbc1.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 4 of 4 coalitions. # Prints the group-wise explanations explanation_group #>    explain_id  none     A       B #>         <int> <num> <num>   <num> #> 1:          1  43.1 -29.2  16.073 #> 2:          2  43.1 -15.2  -7.837 #> 3:          3  43.1 -13.1 -10.878 #> 4:          4  43.1 -17.5   0.665 #> 5:          5  43.1 -28.3   3.529 #> 6:          6  43.1 -20.6  -3.379 # Plots the group-wise explanations plot(explanation_group, bar_plot_phi0 = TRUE, index_x_explain = c(1, 6))"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"explain-custom-models","dir":"Articles","previous_headings":"Advanced usage","what":"Explain custom models","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"shapr currently natively supports explanation predictions models fitted following functions: stats::lm stats::glm ranger::ranger mgcv::gam xgboost::xgboost/xgboost::xgb.train workflows::workflow continuous response regression model binary classification model model classes, can explained package directly exemplified , give example workflows::workflow tidymodels/workflows section. Moreover, essentially feature dependent prediction model can explained package specifying two (one) simple additional functions model. first function predict_model, taking model data (matrix data.frame/data.table) input outputting corresponding prediction numeric vector. second (optional, highly recommended) function get_model_specs, taking model input outputting list following elements: labels (vector feature names compute Shapley values ), classes (named vector labels names class type elements), factor_levels (named list labels names vectors factor levels elements (NULL feature factor)). get_model_specs function used check data passed explain correct format terms necessary feature columns available correct class/attributes. highly recommended checks order ensure correct usage explain. , reason, checking desirable, one provide get_model_specs function. , however, throw warning feature consistency checking model disabled. functions created, can explain predictions model passing functions input arguments predict_model get_model_specs explain(). functions can made general enough handle supported model types class, can made minimal, possibly allowing explanation specific version model class hand. give examples full support versions functions minimal version skips get_model_specs function. gbm model class gbm package, fitted airquality data set used .","code":"library(gbm) #> Loaded gbm 2.2.2 #> This version of gbm is no longer under development. Consider transitioning to gbm3, https://github.com/gbm-developers/gbm3  formula_gbm <- as.formula(paste0(y_var, \"~\", paste0(x_var, collapse = \"+\"))) # Fitting a gbm model set.seed(825) model_gbm <- gbm::gbm(   formula_gbm,   data = cbind(x_train, Ozone = y_train),   distribution = \"gaussian\" )  #### Full feature versions of the three required model functions #### MY_predict_model <- function(x, newdata) {   if (!requireNamespace(\"gbm\", quietly = TRUE)) {     stop(\"The gbm package is required for predicting train models\")   }   model_type <- ifelse(     x$distribution$name %in% c(\"bernoulli\", \"adaboost\"),     \"classification\",     \"regression\"   )   if (model_type == \"classification\") {     predict(x, as.data.frame(newdata), type = \"response\", n.trees = x$n.trees)   } else {     predict(x, as.data.frame(newdata), n.trees = x$n.trees)   } } MY_get_model_specs <- function(x) {   feature_specs <- list()   feature_specs$labels <- labels(x$Terms)   m <- length(feature_specs$labels)   feature_specs$classes <- attr(x$Terms, \"dataClasses\")[-1]   feature_specs$factor_levels <- setNames(vector(\"list\", m), feature_specs$labels)   feature_specs$factor_levels[feature_specs$classes == \"factor\"] <- NA # model object doesn't contain factor levels info   return(feature_specs) }  # Compute the Shapley values set.seed(123) p0 <- mean(y_train) explanation_custom <- explain(   model = model_gbm,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1,   predict_model = MY_predict_model,   get_model_specs = MY_get_model_specs ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:47 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <gbm> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167224ee1c3.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Plot results plot(explanation_custom, index_x_explain = c(1, 6)) #### Minimal version of the custom model setup #### # Note: Working only for this exact version of the model class # Avoiding to define get_model_specs skips all feature # consistency checking between your data and model MY_MINIMAL_predict_model <- function(x, newdata) {   predict(x, as.data.frame(newdata), n.trees = x$n.trees) }  # Compute the Shapley values set.seed(123) explanation_custom_minimal <- explain(   model = model_gbm,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1,   predict_model = MY_MINIMAL_predict_model ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:49 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ You passed a model to `shapr::explain()` which is not natively #>   supported, and did not supply a `get_model_specs` function to #>   `shapr::explain()`. #>   Consistency checks between model and data are therefore disabled. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <gbm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167bbeea3d.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Plot results plot(explanation_custom_minimal, index_x_explain = c(1, 6))"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"workflow_example","dir":"Articles","previous_headings":"Advanced usage","what":"Tidymodels and workflows","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"section, demonstrate use shapr explain tidymodels models fitted using workflows. example , directly used xgboost package fit xgboost model. However, can also fit xgboost model using tidymodels package. fits identical, tidymodels calls xgboost internally, demonstrate example . Note can replace xgboost (.e., parsnip::boost_tree) fitted tidymodels model workflows procedure outlined .","code":"# Fitting a basic xgboost model to the training data using tidymodels set.seed(123) # Set the same seed as above all_var <- c(y_var, x_var) train <- data[-ind_x_explain, ..all_var]  # Fitting the `tidymodels` model using `workflows` model_tidymodels <- parsnip::fit(   workflows::add_recipe(     workflows::add_model(       workflows::workflow(),       parsnip::boost_tree(trees = 20, engine = \"xgboost\", mode = \"regression\")     ),     recipes::recipe(Ozone ~ ., data = train)   ),   data = train )  # # We can also specify the same model using pipes `%>%` by (if pipes are installed/loaded) # model_tidymodels <- #   workflows::workflow() %>% #   workflows::add_model(parsnip::boost_tree(trees = 20, engine = \"xgboost\", mode = \"regression\")) %>% #   workflows::add_recipe(recipes::recipe(Ozone ~ ., data = train)) %>% #   parsnip::fit(data = train)  # See that the output of the two models are identical all.equal(predict(model_tidymodels, x_train)$.pred, predict(model, as.matrix(x_train))) #> [1] TRUE  # Create the Shapley values for the tidymodels version explanation_tidymodels <- explain(   model = model_tidymodels,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:52 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <workflow> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167621a6894.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # See that the Shapley value explanations are identical too all.equal(explanation$shapley_values_est, explanation_tidymodels$shapley_values_est) #> [1] TRUE"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"the-parameters-of-the-vaeac-approach","dir":"Articles","previous_headings":"Advanced usage","what":"The parameters of the vaeac approach","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"vaeac approach flexible method supports mixed data. main parameters number layers networks (vaeac.depth), width layers (vaeac.width), number dimensions latent space (vaeac.latent_dim), activation function layers networks (vaeac.activation_function), learning rate ADAM optimizer (vaeac.lr), number vaeac models initiate remedy poorly initiated model parameter values (vaeac.n_vaeacs_initialize), number learning epochs (vaeac.epochs). Call ?shapr::setup_approach.vaeac detailed description parameters. additional extra parameters can set including named list call explain() function. example, can change batch size 32 including vaeac.extra_parameters = list(vaeac.batch_size = 32) parameter call explain() function. See ?shapr::vaeac_get_extra_para_default description possible extra parameters vaeac approach. main parameters directly entered explain() function, extra parameters included named list called vaeac.extra_parameters. can look training validation errors trained vaeac model see vaeac.epochs = 3 likely epochs, still seems like vaeac model learning.","code":"explanation_vaeac <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = p0,   seed = 1,   n_MC_samples = 100,   vaeac.width = 16,   vaeac.depth = 2,   vaeac.epochs = 3,   vaeac.n_vaeacs_initialize = 2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:01:55 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167602c1288.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Look at the training and validation errors. plot_vaeac_eval_crit(list(\"Vaeac 3 epochs\" = explanation_vaeac), plot_type = \"method\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"early-stopping","dir":"Articles","previous_headings":"Advanced usage > The parameters of the vaeac approach","what":"Early stopping","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"uncertain choice vaeac.epochs, can rather use vaeac early stopping. set vaeac.epochs large number, act maximum number allowed epochs, vaeac.extra_parameters list set vaeac.epochs_early_stopping number epochs allow vaeac model improve validation score. , vaeac.epochs_early_stopping = 2, vaeac stop training procedure improvement validation score 2 consecutive epochs, vaeac.epochs reached. Note using early stopping progress updates simultaneously, estimated timer remaining obviously incorrect early stopping applied. Furthermore, value 2 low real world applications, set low make vignette faster build. Can compare previous version see results stable now.  Can also compare MSEvMSE_{v} evaluation scores.","code":"explanation_vaeac_early_stop <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = p0,   seed = 1,   n_MC_samples = 100,   vaeac.width = 16,   vaeac.depth = 2,   vaeac.epochs = 1000, # Set it to a large number   vaeac.n_vaeacs_initialize = 2,   vaeac.extra_parameters = list(vaeac.epochs_early_stopping = 2) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:02:07 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167da85446.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Look at the training and validation errors. plot_vaeac_eval_crit(   list(\"Vaeac 3 epochs\" = explanation_vaeac, \"Vaeac early stopping\" = explanation_vaeac_early_stop),   plot_type = \"method\" ) plot_MSEv_eval_crit(list(\"Vaeac 3 epochs\" = explanation_vaeac, \"Vaeac early stopping\" = explanation_vaeac_early_stop))"},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"cont_computation","dir":"Articles","previous_headings":"Advanced usage","what":"Continued computation","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"section, demonstrate continue improve estimation accuracy additional coalition samples, previous Shapley value computation based shapr::explain() iterative estimation procedure. can done either passing existing object class shapr, passing string path intermediately saved results. latter found SHAPR_OBJ$saving_path, defaults temporary folder, updated iteration. can particularly handy long-running computations.","code":"# First we run the computation with the iterative estimation procedure for a limited number of coalition samples library(xgboost) library(data.table)  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\", \"Day\") y_var <- \"Ozone\"  ind_x_explain <- 1:6 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Set seed for reproducibility set.seed(123)  # Fitting a basic xgboost model to the training data model <- xgboost::xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features p0 <- mean(y_train)  # Initial explanation computation ex_init <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1,   max_n_coalitions = 20,   iterative = TRUE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:02:29 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: gaussian #>  #> ‚Ä¢ Procedure: Iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 5 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167399790e7.rds' #>  #>  #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 6 of 32 coalitions, 6 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 8 of 32 coalitions, 2 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 12 of 32 coalitions, 4 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 18 of 32 coalitions, 6 new.  #>  #>  #>  #> ‚îÄ‚îÄ Iteration 5 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚Ñπ Using 20 of 32 coalitions, 2 new.  # Using the ex_init object to continue the computation with 4 more coalition samples ex_further <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1,   max_n_coalitions = 24,   iterative_args = list(convergence_tol = 0.005), # Decrease the convergence threshold   prev_shapr_object = ex_init ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:02:34 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 5 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16732fc84c4.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 24 of 32 coalitions.  ex_further_path <- get_results(ex_further, what = \"saving_path\") # Gets path to the saved intermediate estimation object  # Using the ex_init object to continue the computation for the remaining coalition samples # but this time using the path to the saved intermediate estimation object ex_even_further <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1,   max_n_coalitions = NULL,   prev_shapr_object = ex_further_path ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:02:35 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 32`, and #>   is therefore set to `2^n_features = 32`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 5 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1674caa895f.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 26 of 32 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/general_usage.html","id":"forecasting","dir":"Articles","previous_headings":"","what":"Explaining a forecasting model using explain_forecast","title":"`shapr`: Explaining individual machine learning predictions with Shapley values","text":"shapr provides specific function, explain_forecast, explain forecasts time series models, one steps future. main difference compared explain data supplied (set ) time series, addition index arguments (train_idx explain_idx) specifying time points represents train explain parts data. See ?explain_forecast information. demonstrate use function, 500 observations generated follow AR(1) structure, .e. yt=0.5yt‚àí1+Œµty_t = 0.5 y_{t-1} + \\varepsilon_t. data arima model order (2, 0, 0) fitted, therefore like explain forecasts terms two previous lags time series. specified argument explain_y_lags = 2. Note models may also put restrictions amount data required make forecast. AR(2) model used , instance, requires two previous time point make forecast. example, two separate forecasts, three steps ahead, explained. set starting points two forecasts, explain_idx set 499:500. means one forecast t=(500,501,502)t = (500, 501, 502) another t=(501,502,503)t = (501, 502, 503), explained. words, explain_idx tells shapr points time data available , making forecast explain. way, train_idx denotes points time used estimate conditional expectations used explain different forecasts. Note since want explain forecasts terms two previous lags (explain_y_lags = 2), smallest value train_idx must also 2, time t=1t = 1 single observation available. Since data stationary, mean data used value phi0 (.e.¬†œï0\\phi_0). can however chosen differently depending data application. multivariate model VAR (Vector AutoRegressive model), may interesting explain impact variable, rather lag variable. can done setting group_lags = TRUE. Note multivariate model VAR (Vector AutoRegressive model), models also including several exogenous variables, may informative explain impact variable, rather lag variable. can done setting group_lags = TRUE. make sense model, however, result decomposing forecast single group. now give hands-example use explain_forecast function. Say AR(2) model describes change time variable Temp dataset airquality. seems reasonable assume temperature today affect temperature tomorrow. lesser extent, may also suggest temperature today also impact day tomorrow. start building AR(2) model, naming model_ar_temp. model used make forecast temperature day comes last day data, forecast starts index 153. First, pass model data model y. Since AR(2) model, want explain forecasts terms two previous lags, specify explain_y_lags = 2. , let shapr know time indices use training data argument train_idx. use 2:152, meaning skip first index, want explain two previous lags. Letting training indices go 152 means every point time except first last used training data. last index, 153 passed argument explain_idx, means want explain forecast made time point 153 data. argument horizon set 2 order explain forecast length 2. argument phi0 set mean time series, repeated two times. value phi0 baseline forecast horizon. example, assume given effect two lags, temperature just average observed period. Finally, opt group lags setting group_lags FALSE. means lag 1 2 explained separately. Grouping lags may interesting model multiple variables, possible explain variable separately. results presented per value explain_idx forecast horizon. can see mean temperature around 77.9 degrees. horizon 1, first lag model caused 6.6 degrees lower, second lag just minor effect. horizon 2, first lag slightly smaller negative impact, second lag slightly larger impact. also possible explain forecasting model uses exogenous regressors. previous example expanded use ARIMA(2,0,0) model Wind exogenous regressor. Since exogenous regressor must available predicted time points, model just fit 151 first observations, leaving two observations Wind used exogenous values prediction phase. shapr package can explain two autoregressive lags, also single lag exogenous regressor. order , Wind variable passed argument xreg, explain_xreg_lags set 1. Notice first 151 observations used y 153 used xreg. makes possible shapr explain effect first lag exogenous variable, also contemporary effect forecasting period.","code":"# Simulate time series data with AR(1)-structure. set.seed(1) data_ts <- data.frame(Y = arima.sim(list(order = c(1, 0, 0), ar = .5), n = 500)) data_ts <- data.table::as.data.table(data_ts)  # Fit an ARIMA(2, 0, 0) model. arima_model <- arima(data_ts, order = c(2, 0, 0))  # Set prediction zero as the mean of the data for each forecast point. p0_ar <- rep(mean(data_ts$Y), 3)  # Explain forecasts from points t = 499 and t = 500. explain_idx <- 499:500  explanation_forecast <- explain_forecast(   model = arima_model,   y = data_ts,   train_idx = 2:498,   explain_idx = 499:500,   explain_y_lags = 2,   horizon = 3,   approach = \"empirical\",   phi0 = p0_ar,   group_lags = FALSE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain_forecast()` at 2025-08-21 09:02:36 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature names extracted from the model contain `NA`. #>   Consistency checks between model and data are therefore disabled. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 4`, and #>   is therefore set to `2^n_features = 4`. #> Registered S3 method overwritten by 'quantmod': #>   method            from #>   as.zoo.data.frame zoo  #>  #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <Arima> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 2 #>  #> ‚Ä¢ Number of observations to explain: 2 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16710e4d8a0.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 4 of 4 coalitions. explanation_forecast #>    explain_idx horizon   none    Y.1     Y.2 #>          <int>   <int>  <num>  <num>   <num> #> 1:         499       1 0.0402  0.505 -0.0766 #> 2:         500       1 0.0402 -0.362  0.0250 #> 3:         499       2 0.0402  0.505 -0.0766 #> 4:         500       2 0.0402 -0.362  0.0250 #> 5:         499       3 0.0402  0.505 -0.0766 #> 6:         500       3 0.0402 -0.362  0.0250 data_ts2 <- data.table::as.data.table(airquality)  model_ar_temp <- ar(data_ts2$Temp, order = 2)  predict(model_ar_temp, n.ahead = 2)$pred #> Time Series: #> Start = 154  #> End = 155  #> Frequency = 1  #> [1] 71.081 71.524 explanation_forecast <- explain_forecast(   model = model_ar_temp,   y = data_ts2[, \"Temp\"],   train_idx = 2:152,   explain_idx = 153,   explain_y_lags = 2,   horizon = 2,   approach = \"empirical\",   phi0 = rep(mean(data$Temp), 2),   group_lags = FALSE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain_forecast()` at 2025-08-21 09:02:39 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature names extracted from the model contain `NA`. #>   Consistency checks between model and data are therefore disabled. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 4`, and #>   is therefore set to `2^n_features = 4`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <ar> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 2 #>  #> ‚Ä¢ Number of observations to explain: 1 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16728975abb.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 4 of 4 coalitions.  print(explanation_forecast) #>    explain_idx horizon  none Temp.1 Temp.2 #>          <int>   <int> <num>  <num>  <num> #> 1:         153       1  77.8  -6.58 -0.134 #> 2:         153       2  77.8  -5.98 -0.288 data_ts3 <- data.table::as.data.table(airquality)  data_fit <- data_ts3[seq_len(151), ]  model_arimax_temp <- arima(data_fit$Temp, order = c(2, 0, 0), xreg = data_fit$Wind)  newxreg <- data_ts3[-seq_len(151), \"Wind\", drop = FALSE]  predict(model_arimax_temp, n.ahead = 2, newxreg = newxreg)$pred #> Time Series: #> Start = 152  #> End = 153  #> Frequency = 1  #> [1] 77.500 76.381 explanation_forecast <- explain_forecast(   model = model_ar_temp,   y = data_fit[, \"Temp\"],   xreg = data_ts3[, \"Wind\"],   train_idx = 2:150,   explain_idx = 151,   explain_y_lags = 2,   explain_xreg_lags = 1,   horizon = 2,   approach = \"empirical\",   phi0 = rep(mean(data_fit$Temp), 2),   group_lags = FALSE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain_forecast()` at 2025-08-21 09:02:40 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature names extracted from the model contain `NA`. #>   Consistency checks between model and data are therefore disabled. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 32`, and #>   is therefore set to `2^n_features = 32`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <ar> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 5 #>  #> ‚Ä¢ Number of observations to explain: 1 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167657f07b8.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 32 of 32 coalitions.  print(explanation_forecast) #>    explain_idx horizon  none Temp.1 Temp.2 Wind.1 Wind.F1 Wind.F2 #>          <int>   <int> <num>  <num>  <num>  <num>   <num>   <num> #> 1:         151       1    78 -0.678 -0.673  -1.27  0.4934      NA #> 2:         151       2    78  0.400 -0.501  -1.47  0.0659  -0.474  summary(explanation_forecast) #>  #> ‚îÄ‚îÄ Summary of Shapley value explanation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ä¢ Computed with`shapr::explain_forecast()` in 3.1 seconds, started #> 2025-08-21 09:02:40 #> ‚Ä¢ Model class: <ar> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 5 #> ‚Ä¢ Number of observations to explain: 1 #> ‚Ä¢ Number of coalitions used: 32 (of total 32) #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167657f07b8.rds' #>  #> ‚îÄ‚îÄ Estimated Shapley values  #>    explain_idx horizon   none Temp.1 Temp.2 Wind.1 Wind.F1 Wind.F2 #>          <int>   <int> <char> <char> <char> <char>  <char>  <char> #> 1:         151       1  77.96  -0.68  -0.67  -1.27    0.49      NA #> 2:         151       2  77.96   0.40  -0.50  -1.47    0.07   -0.47"},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"separate","dir":"Articles","previous_headings":"","what":"The separate regression method class","title":"Shapley value explanations using the regression paradigm","text":"regression_separate methods, train new regression model gS(ùê±S)g_S(\\boldsymbol{x}_S) estimate conditional expectation coalition features. idea estimate v(S)=E[f(ùê±)|ùê±S=ùê±S*]=E[f(ùê±S‚Äæ,ùê±S)|ùê±S=ùê±S*]v(S) = E[f(\\boldsymbol{x})|\\boldsymbol{x}_S = \\boldsymbol{x}_S^*] = E[f(\\boldsymbol{x}_{\\bar{S}},\\boldsymbol{x}_S)|\\boldsymbol{x}_S=\\boldsymbol{x}_S^*] separately coalition SS using regression. Let ùíü={ùê±[],y[]}=1Ntrain\\mathcal{D} = \\{ \\boldsymbol{x}^{[]}, y^{[]} \\}_{=1}^{N_{\\text{train}}} denote training data, ùê±[]\\boldsymbol{x}^{[]} iith MM-dimensional input y[]y^{[]} associated response. coalition S‚äÜ{1,2,‚Ä¶,M}S \\subseteq \\{1,2,\\dots,M\\}, corresponding training data set ùíüS={ùê±S[],f(ùê±S‚Äæ[],ùê±S[]‚èüùê±[])}=1Ntrain={ùê±S[],f(ùê±[])‚èüz[]}=1Ntrain={ùê±S[],z[]}=1Ntrain.\\begin{align*}             \\mathcal{D}_S             =             \\{\\boldsymbol{x}_S^{[]}, f(\\underbrace{\\boldsymbol{x}_\\bar{S}^{[]}, \\boldsymbol{x}_S^{[]}}_{\\boldsymbol{x}^{[]}})\\}_{=1}^{N_{\\text{train}}}             =             \\{\\boldsymbol{x}_S^{[]}, \\underbrace{f(\\boldsymbol{x}^{[]})}_{z^{[]}}\\}_{=1}^{N_{\\text{train}}}             =             \\{\\boldsymbol{x}_S^{[]}, z^{[]}\\}_{=1}^{N_{\\text{train}}}. \\end{align*} data set ùíüS\\mathcal{D}_S, train regression model gS(ùê±S)g_S(\\boldsymbol{x}_S) respect mean squared error loss function. , fit regression model prediction f(ùê±)f(\\boldsymbol{x}) acting response feature subset coalition SS, ùê±S\\boldsymbol{x}_S, acting available features. optimal model, respect loss function, gS*(ùê±S)=E[z|ùê±S]=E[f(ùê±S‚Äæ,ùê±S)|ùê±S]g^*_S(\\boldsymbol{x}_S) = E[z|\\boldsymbol{x}_S] = E[f(\\boldsymbol{x}_\\bar{S}, \\boldsymbol{x}_S)|\\boldsymbol{x}_S], corresponds contribution function v(S)v(S). regression model gSg_S aims optimal, hence, resembles/estimates contribution function, .e., gS(ùê±S)=vÃÇ(S)‚âàv(S)=E[f(ùê±S‚Äæ,ùê±S)|ùê±S=ùê±S*]g_S(\\boldsymbol{x}_S) = \\hat{v}(S) \\approx v(S) = E[f(\\boldsymbol{x}_\\bar{S}, \\boldsymbol{x}_S) | \\boldsymbol{x}_S = \\boldsymbol{x}_S^*].","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"separate_code","dir":"Articles","previous_headings":"The separate regression method class","what":"Code","title":"Shapley value explanations using the regression paradigm","text":"supplementary vignette, use data explain model type general usage. train simple xgboost model airquality dataset demonstrate use shapr separate regression method class explain individual predictions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"setup","dir":"Articles","previous_headings":"The separate regression method class > Code","what":"Setup","title":"Shapley value explanations using the regression paradigm","text":"First, set airquality dataset train xgboost model, whose predictions want explain using Shapley value explanation framework. import packages tidymodels framework code chunk , specified directly, . vignette, use following packages tidymodels framework: parsnip, recipes, workflows, dials, hardhat, tibble, rlang, ggplot2. include package::function() notation throughout vignette indicate package functions originate tidymodels framework. make rest vignette easier follow, create helper functions plot summarize results explanation methods. code block optional understand can skipped. establish baseline compare regression methods, compare Monte Carlo-based empirical approach default hyperparameters. last section, include Monte Carlo-based methods implemented shapr make extensive comparison.","code":"# Either use `library(tidymodels)` or separately specify the libraries indicated above library(tidymodels) library(shapr)  # Ensure that shapr's functions are prioritized, otherwise we need to use the `shapr::` # prefix when calling explain(). The `conflicted` package is imported by `tidymodels`. conflicted::conflicts_prefer(shapr::explain, shapr::prepare_data) # Other libraries library(xgboost) library(data.table)  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\") y_var <- \"Ozone\"  ind_x_explain <- 1:20 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Fitting a basic xgboost model to the training data set.seed(123) # Set seed for reproducibility model <- xgboost::xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features p0 <- mean(y_train)  # List to store all the explanation objects explanation_list <- list() # Plot the MSEv criterion scores as horizontal bars and add dashed line of one method's score plot_MSEv_scores <- function(explanation_list, method_line = NULL) {   fig <- plot_MSEv_eval_crit(explanation_list) +     ggplot2::theme(legend.position = \"none\") +     ggplot2::coord_flip() +     ggplot2::theme(plot.title = ggplot2::element_text(size = rel(0.95)))   fig <- fig + ggplot2::scale_x_discrete(limits = rev(levels(fig$data$Method)))   if (!is.null(method_line) && method_line %in% fig$data$Method) {     fig <- fig + ggplot2::geom_hline(       yintercept = fig$data$MSEv[fig$data$Method == method_line],       linetype = \"dashed\",       color = \"black\"     )   }   return(fig) }  # Extract the MSEv criterion scores and elapsed times print_MSEv_scores_and_time <- function(explanation_list) {   res <- as.data.frame(t(sapply(     explanation_list,     function(explanation) {       round(c(explanation$MSEv$MSEv$MSEv, explanation$timing$summary$total_time_secs), 2)     }   )))   colnames(res) <- c(\"MSEv\", \"Time\")   return(res) }  # Extract the k best methods in decreasing order get_k_best_methods <- function(explanation_list, k_best) {   res <- print_MSEv_scores_and_time(explanation_list)   return(rownames(res)[order(res$MSEv)[seq(k_best)]]) } # Compute the Shapley value explanations using the empirical method explanation_list$MC_empirical <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:48:55 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767debbb81e7.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"linear-regression-model","dir":"Articles","previous_headings":"The separate regression method class > Code","what":"Linear regression model","title":"Shapley value explanations using the regression paradigm","text":"compute Shapley value explanations using linear regression model separate regression method class. linear model often flexible enough properly model contribution function. Thus, can produce inaccurate Shapley value explanations. figure shows empirical approach outperforms linear regression model approach quite significantly concerning MSEv\\operatorname{MSE}_v evaluation criterion.","code":"explanation_list$sep_lm <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg() ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:48:59 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de622e143d.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. plot_MSEv_scores(explanation_list)"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"separate_preproc","dir":"Articles","previous_headings":"The separate regression method class > Code","what":"Pre-processing","title":"Shapley value explanations using the regression paradigm","text":"section describes pre-process data fitting separate regression models. demonstrate linear regression model, can apply pre-processing regression methods. recipes package tidymodels framework contains many functions pre-process data fitting model, example, normalization, interaction, encodings, transformations (e.g., log, splines, pls, pca). Click access complete list available functions. list also contains functions helping us select features apply functions , e.g., recipes::all_predictors(), recipes::all_numeric_predictors(), recipes::all_factor_predictors() apply functions features, numerical features, factor features, respectively. can also specify names features functions applied. However, included features change coalition, need check feature want apply function present dataset. give example . First, demonstrate compute principal components use () first two components separate linear regression model. write ‚Äú‚Äù can compute single principal component singleton coalitions, .e., feature . regression model called principal component regression. Second, apply pre-processing step computes basis expansions features using natural splines two degrees freedom. similar fitting generalized additive model. Finally, provide example include interactions features Solar.R Wind, log-transform Solar.R, convert Wind 0 1 take square root, include polynomials third degree Temp, apply Box-Cox transformation Month. transformations applied features present different separate models. Furthermore, stress purpose example highlight framework‚Äôs flexibility, transformations reasonable. can examine MSEv\\operatorname{MSE}_v evaluation scores, see method using natural splines significantly outperforms methods.","code":"explanation_list$sep_pcr <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg(),   regression.recipe_func = function(regression_recipe) {     return(recipes::step_pca(regression_recipe, recipes::all_numeric_predictors(), num_comp = 2))   } ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:00 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de2fab29bc.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. explanation_list$sep_splines <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg(),   regression.recipe_func = function(regression_recipe) {     return(recipes::step_ns(regression_recipe, recipes::all_numeric_predictors(), deg_free = 2))   } ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:01 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3d45de41.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Example function of how to apply step functions from the recipes package to specific features regression.recipe_func <- function(recipe) {   # Get the names of the present features   feature_names <- recipe$var_info$variable[recipe$var_info$role == \"predictor\"]    # If Solar.R and Wind is present, then we add the interaction between them   if (all(c(\"Solar.R\", \"Wind\") %in% feature_names)) {     recipe <- recipes::step_interact(recipe, terms = ~ Solar.R:Wind)   }    # If Solar.R is present, then log transform it   if (\"Solar.R\" %in% feature_names) recipe <- recipes::step_log(recipe, Solar.R)    # If Wind is present, then scale it to be between 0 and 1 and then sqrt transform it   if (\"Wind\" %in% feature_names) recipe <- recipes::step_sqrt(recipes::step_range(recipe, Wind))    # If Temp is present, then expand it using orthogonal polynomials of degree 3   if (\"Temp\" %in% feature_names) recipe <- recipes::step_poly(recipe, Temp, degree = 3)    # If Month is present, then Box-Cox transform it   if (\"Month\" %in% feature_names) recipe <- recipes::step_BoxCox(recipe, Month)    # Finally we normalize all features (not needed as LM does this internally)   recipe <- recipes::step_normalize(recipe, recipes::all_numeric_predictors())    return(recipe) }  # Compute the Shapley values using the pre-processing steps defined above explanation_list$sep_recipe_example <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg(),   regression.recipe_func = regression.recipe_func ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:01 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de255ef0b8.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Compare the MSEv criterion of the different explanation methods plot_MSEv_scores(explanation_list, method_line = \"MC_empirical\") # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                      MSEv  Time #> MC_empirical       179.43  4.29 #> sep_lm             745.21  0.89 #> sep_pcr            784.91  0.81 #> sep_splines        165.13 -0.34 #> sep_recipe_example 687.45  1.00"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"other-regression-models","dir":"Articles","previous_headings":"The separate regression method class > Code","what":"Other regression models","title":"Shapley value explanations using the regression paradigm","text":"following example, use decision tree model instead simple linear regression model. tidymodels framework supports several implementations decision tree model. use set_engine(\"rpart\") specify want use implementation rpart package, use set_mode(\"regression\") specify regression. tidymodels framework uses default hyperparameter values set rpart specify . searching ‚Äúdecision tree‚Äù list tidymodels, see default hyperparameter values decision_tree_rpart model tree_depth = 30, min_n = 2, cost_complexity = 0.01. can also set regression.model = parsnip::decision_tree(tree_depth = 1, min_n = 2, cost_complexity = 0.01) %>% parsnip::set_engine(\"rpart\") %>% parsnip::set_mode(\"regression\") want use pipe function (%>%). can now compare two new methods. decision tree default parameters outperforms linear model approach concerning MSEv\\operatorname{MSE}_v criterion level empirical approach. obtained worse method using stumps, .e., trees depth one.","code":"# Decision tree with specified parameters (stumps) explanation_list$sep_tree_stump <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::decision_tree(     tree_depth = 1,     min_n = 2,     cost_complexity = 0.01,     engine = \"rpart\",     mode = \"regression\"   ) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:02 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de23a78dc4.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Decision tree with default parameters explanation_list$sep_tree_default <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::decision_tree(engine = \"rpart\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:02 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de51e6cebc.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions. # Compare the MSEv criterion of the different explanation methods plot_MSEv_scores(explanation_list, method_line = \"MC_empirical\") # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                      MSEv  Time #> MC_empirical       179.43  4.29 #> sep_lm             745.21  0.89 #> sep_pcr            784.91  0.81 #> sep_splines        165.13 -0.34 #> sep_recipe_example 687.45  1.00 #> sep_tree_stump     218.05  0.73 #> sep_tree_default   177.68  0.87"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"separate_cv","dir":"Articles","previous_headings":"The separate regression method class > Code","what":"Cross-validation","title":"Shapley value explanations using the regression paradigm","text":"Another option use cross-validation tune hyperparameters. , need specify three things: regression.model, need specify parameters tune model. setting parameter equal hardhat::tune(). example, want tune tree_depth parameter parsnip::decision_tree model using default parameters parameters, set parsnip::decision_tree(tree_depth = hardhat::tune()). regression.tune_values, must provide either data.frame (can also data.table tibble) containing possible hyperparameter values function takes training data combination/coalition outputs data.frame containing possible hyperparameter values. latter allows us use different hyperparameter values different coalition sizes, essential hyperparameter‚Äôs domain changes coalition size. example, see example want tune mtry parameter ranger (random forest). column names regression.tune_values (output function) must match tunable hyperparameters specified regression.model. example , regression.tune_values must one-column data.frame column name tree_depth. can either manually specify hyperparameter values use dials package, e.g., dials::grid_regular(dials::tree_depth(), levels = 5). can function outputs data.frame form. Specifying regression.vfold_cv_para parameter optional. used, regression.vfold_cv_para must list specifying parameters send cross-validation function rsample::vfold_cv(). Use ?rsample::vfold_cv see default parameters. names objects regression.vfold_cv_para list must match parameter names rsample::vfold_cv(). example, want 5-fold cross-validation, set regression.vfold_cv_para = list(v = 5). First, let us look ways specify regression.tune_values. Note dials several grid functions, e.g., dials::grid_random() dials::grid_latin_hypercube(). now demonstrate use cross-validation fine-tune separate decision tree regression method. following examples, consider two versions. first example, use cross-validation tune tree_depth parameter using dials::grid_regular() function. second example, tune tree_depth cost_complexity parameters, manually specify possible hyperparameter values time. also include one example random forest model tunable hyperparameter mtry depends coalition size. Thus, regression.tune_values must function returns data.frame hyperparameter values mtry change based coalition size. let regression.tune_values function, tidymodels crash mtry higher 1. Furthermore, setting letting \"vS_details\" %% verbose, receive messages results cross-validation procedure run within shapr. Note tested hyperparameter value combinations change based coalition size. can look MSEv\\operatorname{MSE}_v evaluation criterion, see cross-validation improves decision tree random forest methods. two cross-validated decision tree methods comparable, second version outperforms first version small margin. comparison somewhat unfair empirical approach, also hyperparameters potentially tune. However, shapr currently provide function automatically. figure , include vertical line MSEv\\operatorname{MSE}_v score empirical method easier comparison.  Furthermore, must consider cross-validation drastically increases elapsed time (seconds) determine increased precision worth extra computational time. also see complex random forest method performs significantly worse simple decision tree method. result indicates even though hyperparameter tuning, still overfit data.","code":"# Possible ways to define the `regression.tune_values` object. # function(x) dials::grid_regular(dials::tree_depth(), levels = 4) dials::grid_regular(dials::tree_depth(), levels = 4) data.table(tree_depth = c(1, 5, 10, 15)) # Can also use data.frame or tibble  # For several features # function(x) dials::grid_regular(dials::tree_depth(), dials::cost_complexity(), levels = 3) dials::grid_regular(dials::tree_depth(), dials::cost_complexity(), levels = 3) expand.grid(tree_depth = c(1, 3, 5), cost_complexity = c(0.001, 0.05, 0.01)) # Decision tree with cross-validated depth (default values for other parameters) explanation_list$sep_tree_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::decision_tree(     tree_depth = hardhat::tune(), engine = \"rpart\", mode = \"regression\"   ),   regression.tune_values = dials::grid_regular(dials::tree_depth(), levels = 4),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:04 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de62ff6c3e.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Use trees with cross-validation on the depth and cost complexity. Manually set the values. explanation_list$sep_tree_cv_2 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::decision_tree(     tree_depth = hardhat::tune(),     cost_complexity = hardhat::tune(),     engine = \"rpart\",     mode = \"regression\"   ),   regression.tune_values =     expand.grid(tree_depth = c(1, 3, 5), cost_complexity = c(0.001, 0.01, 0.1)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de64e2c26c.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions. # Using random forest with default parameters explanation_list$sep_rf <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::rand_forest(engine = \"ranger\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:31 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de709e4454.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using random forest with parameters tuned by cross-validation explanation_list$sep_rf_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   verbose = c(\"basic\",\"vS_details\"), # To get printouts   approach = \"regression_separate\",   regression.model = parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = \"ranger\", mode = \"regression\"   ),   regression.tune_values =     function(x) {       dials::grid_regular(dials::mtry(c(1, ncol(x))), dials::trees(c(50, 750)), levels = 3)     },   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:32 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de76b20436.rds' #>  #> ‚îÄ‚îÄ Additional details about the regression model  #> Random Forest Model Specification (regression) #>  #> Main Arguments: mtry = hardhat::tune() trees = hardhat::tune() #>  #> Computational engine: ranger #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Extra info about the tuning of the regression model ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Top 6 best configs for  v(1 4) (using 5-fold CV)  #> #1: mtry = 1 trees = 50 rmse = 28.43 rmse_std_err = 3.02 #> #2: mtry = 1 trees = 750 rmse = 28.76 rmse_std_err = 2.57 #> #3: mtry = 1 trees = 400 rmse = 28.80 rmse_std_err = 2.64 #> #4: mtry = 2 trees = 50 rmse = 29.27 rmse_std_err = 2.29 #> #5: mtry = 2 trees = 400 rmse = 29.42 rmse_std_err = 2.40 #> #6: mtry = 2 trees = 750 rmse = 29.46 rmse_std_err = 2.20 #>  #> ‚îÄ‚îÄ Top 6 best configs for  v(2 4) (using 5-fold CV)  #> #1: mtry = 1 trees = 50 rmse = 21.12 rmse_std_err = 0.73 #> #2: mtry = 1 trees = 750 rmse = 21.21 rmse_std_err = 0.66 #> #3: mtry = 2 trees = 400 rmse = 21.27 rmse_std_err = 1.02 #> #4: mtry = 2 trees = 750 rmse = 21.31 rmse_std_err = 1.01 #> #5: mtry = 1 trees = 400 rmse = 21.34 rmse_std_err = 0.69 #> #6: mtry = 2 trees = 50 rmse = 21.65 rmse_std_err = 0.94 #>  #> ‚îÄ‚îÄ Top 6 best configs for  v(1 3) (using 5-fold CV)  #> #1: mtry = 1 trees = 50 rmse = 21.34 rmse_std_err = 3.18 #> #2: mtry = 1 trees = 400 rmse = 21.56 rmse_std_err = 3.13 #> #3: mtry = 1 trees = 750 rmse = 21.68 rmse_std_err = 3.13 #> #4: mtry = 2 trees = 50 rmse = 21.79 rmse_std_err = 3.10 #> #5: mtry = 2 trees = 750 rmse = 21.85 rmse_std_err = 2.98 #> #6: mtry = 2 trees = 400 rmse = 21.89 rmse_std_err = 2.97 #>  #> ‚îÄ‚îÄ Top 6 best configs for  v(3 4) (using 5-fold CV)  #> #1: mtry = 1 trees = 750 rmse = 22.22 rmse_std_err = 4.18 #> #2: mtry = 1 trees = 400 rmse = 22.32 rmse_std_err = 4.25 #> #3: mtry = 1 trees = 50 rmse = 22.71 rmse_std_err = 4.32 #> #4: mtry = 2 trees = 750 rmse = 23.33 rmse_std_err = 4.18 #> #5: mtry = 2 trees = 400 rmse = 23.55 rmse_std_err = 4.09 #> #6: mtry = 2 trees = 50 rmse = 24.06 rmse_std_err = 4.06 #>  #> ‚îÄ‚îÄ Top 6 best configs for  v(2 3) (using 5-fold CV)  #> #1: mtry = 2 trees = 50 rmse = 17.46 rmse_std_err = 2.26 #> #2: mtry = 2 trees = 750 rmse = 17.53 rmse_std_err = 2.43 #> #3: mtry = 2 trees = 400 rmse = 17.64 rmse_std_err = 2.38 #> #4: mtry = 1 trees = 750 rmse = 17.80 rmse_std_err = 2.09 #> #5: mtry = 1 trees = 50 rmse = 17.81 rmse_std_err = 1.79 #> #6: mtry = 1 trees = 400 rmse = 17.89 rmse_std_err = 2.13 #>  #> ‚îÄ‚îÄ Top 3 best configs for  v(3) (using 5-fold CV)  #> #1: mtry = 1 trees = 50 rmse = 22.55 rmse_std_err = 4.68 #> #2: mtry = 1 trees = 400 rmse = 22.59 rmse_std_err = 4.63 #> #3: mtry = 1 trees = 750 rmse = 22.64 rmse_std_err = 4.65 #>  #> ‚îÄ‚îÄ Top 6 best configs for  v(1 2) (using 5-fold CV)  #> #1: mtry = 1 trees = 400 rmse = 22.27 rmse_std_err = 2.46 #> #2: mtry = 1 trees = 50 rmse = 22.45 rmse_std_err = 2.49 #> #3: mtry = 1 trees = 750 rmse = 22.51 rmse_std_err = 2.64 #> #4: mtry = 2 trees = 750 rmse = 22.95 rmse_std_err = 2.48 #> #5: mtry = 2 trees = 400 rmse = 23.05 rmse_std_err = 2.49 #> #6: mtry = 2 trees = 50 rmse = 23.06 rmse_std_err = 2.51 #>  #> ‚îÄ‚îÄ Top 3 best configs for  v(4) (using 5-fold CV)  #> #1: mtry = 1 trees = 750 rmse = 32.14 rmse_std_err = 4.32 #> #2: mtry = 1 trees = 400 rmse = 32.21 rmse_std_err = 4.31 #> #3: mtry = 1 trees = 50 rmse = 32.21 rmse_std_err = 4.25 #>  #> ‚îÄ‚îÄ Top 3 best configs for  v(1) (using 5-fold CV)  #> #1: mtry = 1 trees = 50 rmse = 30.34 rmse_std_err = 3.40 #> #2: mtry = 1 trees = 750 rmse = 30.53 rmse_std_err = 3.31 #> #3: mtry = 1 trees = 400 rmse = 30.63 rmse_std_err = 3.32 #>  #> ‚îÄ‚îÄ Top 3 best configs for  v(2) (using 5-fold CV)  #> #1: mtry = 1 trees = 750 rmse = 26.62 rmse_std_err = 2.33 #> #2: mtry = 1 trees = 400 rmse = 26.72 rmse_std_err = 2.29 #> #3: mtry = 1 trees = 50 rmse = 26.97 rmse_std_err = 2.24 #>  #> ‚îÄ‚îÄ Top 9 best configs for  v(1 2 4) (using 5-fold CV)  #> #1: mtry = 1 trees = 750 rmse = 20.17 rmse_std_err = 2.77 #> #2: mtry = 2 trees = 750 rmse = 20.19 rmse_std_err = 2.46 #> #3: mtry = 1 trees = 400 rmse = 20.35 rmse_std_err = 2.95 #> #4: mtry = 2 trees = 50 rmse = 20.41 rmse_std_err = 2.44 #> #5: mtry = 2 trees = 400 rmse = 20.41 rmse_std_err = 2.42 #> #6: mtry = 1 trees = 50 rmse = 20.71 rmse_std_err = 2.74 #> #7: mtry = 3 trees = 50 rmse = 20.82 rmse_std_err = 2.24 #> #8: mtry = 3 trees = 400 rmse = 20.91 rmse_std_err = 2.41 #> #9: mtry = 3 trees = 750 rmse = 21.06 rmse_std_err = 2.46 #>  #> ‚îÄ‚îÄ Top 9 best configs for  v(1 2 3) (using 5-fold CV)  #> #1: mtry = 2 trees = 400 rmse = 16.16 rmse_std_err = 2.75 #> #2: mtry = 3 trees = 400 rmse = 16.30 rmse_std_err = 2.80 #> #3: mtry = 2 trees = 750 rmse = 16.41 rmse_std_err = 2.79 #> #4: mtry = 3 trees = 750 rmse = 16.43 rmse_std_err = 2.82 #> #5: mtry = 3 trees = 50 rmse = 16.52 rmse_std_err = 2.52 #> #6: mtry = 1 trees = 750 rmse = 16.69 rmse_std_err = 3.15 #> #7: mtry = 2 trees = 50 rmse = 16.89 rmse_std_err = 2.76 #> #8: mtry = 1 trees = 400 rmse = 16.98 rmse_std_err = 2.93 #> #9: mtry = 1 trees = 50 rmse = 17.69 rmse_std_err = 3.16 #>  #> ‚îÄ‚îÄ Top 9 best configs for  v(1 3 4) (using 5-fold CV)  #> #1: mtry = 1 trees = 400 rmse = 21.88 rmse_std_err = 4.33 #> #2: mtry = 1 trees = 750 rmse = 21.96 rmse_std_err = 4.38 #> #3: mtry = 1 trees = 50 rmse = 22.03 rmse_std_err = 4.07 #> #4: mtry = 2 trees = 400 rmse = 22.65 rmse_std_err = 4.11 #> #5: mtry = 2 trees = 750 rmse = 22.72 rmse_std_err = 4.09 #> #6: mtry = 2 trees = 50 rmse = 22.89 rmse_std_err = 3.97 #> #7: mtry = 3 trees = 400 rmse = 23.38 rmse_std_err = 3.80 #> #8: mtry = 3 trees = 750 rmse = 23.50 rmse_std_err = 3.77 #> #9: mtry = 3 trees = 50 rmse = 23.88 rmse_std_err = 3.64 #>  #> ‚îÄ‚îÄ Top 9 best configs for  v(2 3 4) (using 5-fold CV)  #> #1: mtry = 3 trees = 50 rmse = 17.72 rmse_std_err = 3.21 #> #2: mtry = 2 trees = 50 rmse = 17.84 rmse_std_err = 3.56 #> #3: mtry = 2 trees = 400 rmse = 17.88 rmse_std_err = 3.54 #> #4: mtry = 2 trees = 750 rmse = 17.92 rmse_std_err = 3.58 #> #5: mtry = 3 trees = 400 rmse = 17.92 rmse_std_err = 3.38 #> #6: mtry = 3 trees = 750 rmse = 17.93 rmse_std_err = 3.46 #> #7: mtry = 1 trees = 750 rmse = 17.97 rmse_std_err = 3.49 #> #8: mtry = 1 trees = 400 rmse = 18.01 rmse_std_err = 3.59 #> #9: mtry = 1 trees = 50 rmse = 18.10 rmse_std_err = 3.56 plot_MSEv_scores(explanation_list, method_line = \"MC_empirical\") # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                      MSEv  Time #> MC_empirical       179.43  4.29 #> sep_lm             745.21  0.89 #> sep_pcr            784.91  0.81 #> sep_splines        165.13 -0.34 #> sep_recipe_example 687.45  1.00 #> sep_tree_stump     218.05  0.73 #> sep_tree_default   177.68  0.87 #> sep_tree_cv        222.71  9.19 #> sep_tree_cv_2      219.45 17.92 #> sep_rf             218.13  1.20 #> sep_rf_cv          226.42 21.88"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"separate_parallelization","dir":"Articles","previous_headings":"The separate regression method class > Code","what":"Parallelization","title":"Shapley value explanations using the regression paradigm","text":"future package can train separate regression models parallel. specifically, parallelize training step (fit models) prediction step (compute v(S)v(S)). general usage, also explain enable progress bars. code chunk , consider four regression-based methods. first method uses xgboost models default hyperparameter values, remaining three use cross-validation tune number trees. second third methods specify potential hyperparameter values, run former sequentially latter run parallel speed computations. fourth model run parallel also tunes depth trees number trees. small side note: let \"vS_details\" %% verbose, can see tree value shapr chooses coalition. see values 25, 50, 100, 500 never chosen. Thus, can remove values without influencing result instead finer grid search among lower values. fourth method. Looking elapsed time, see parallel version two workers faster sequential version. Note elapsed time parallel version reduced factor two creation parallel processes creates additional overhead, significant small example. However, parallelization yield considerable relative time improvements complex situations. E.g., settings () training observations features (.e., coalitions compute) situations time-consuming cross-validation (.e., folds, hyperparameters tune, hyperparameter values consider). Furthermore, see conducting cross-validation lowered MSEv\\operatorname{MSE}_v criterion drastically. Finally, note obtain value whether run cross-validation parallel sequentially.","code":"# Regular xgboost with default parameters explanation_list$sep_xgboost <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::boost_tree(engine = \"xgboost\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:54 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3234fe1d.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Cross validate the number of trees explanation_list$sep_xgboost_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model =     parsnip::boost_tree(trees = hardhat::tune(), engine = \"xgboost\", mode = \"regression\"),   regression.tune_values = expand.grid(trees = c(10, 15, 25, 50, 100, 500)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:49:56 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de350314e5.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Cross validate the number of trees in parallel on two threads future::plan(future::multisession, workers = 2) explanation_list$sep_xgboost_cv_par <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model =     parsnip::boost_tree(trees = hardhat::tune(), engine = \"xgboost\", mode = \"regression\"),   regression.tune_values = expand.grid(trees = c(10, 15, 25, 50, 100, 500)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:25 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de1a79abf1.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Use a finer grid of low values for `trees` and also tune `tree_depth` future::plan(future::multisession, workers = 4) # Change to 4 threads due to more complex CV explanation_list$sep_xgboost_cv_2_par <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::boost_tree(     trees = hardhat::tune(),     tree_depth = hardhat::tune(),     engine = \"xgboost\",     mode = \"regression\"   ),   regression.tune_values = expand.grid(trees = c(8, 10, 12, 15), tree_depth = c(4, 6, 8)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:32 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de4951f82.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions. future::plan(future::sequential) # To return to non-parallel computation # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                        MSEv  Time #> MC_empirical         179.43  4.29 #> sep_lm               745.21  0.89 #> sep_pcr              784.91  0.81 #> sep_splines          165.13 -0.34 #> sep_recipe_example   687.45  1.00 #> sep_tree_stump       218.05  0.73 #> sep_tree_default     177.68  0.87 #> sep_tree_cv          222.71  9.19 #> sep_tree_cv_2        219.45 17.92 #> sep_rf               218.13  1.20 #> sep_rf_cv            226.42 21.88 #> sep_xgboost          197.72  2.14 #> sep_xgboost_cv       168.45 27.61 #> sep_xgboost_cv_par   168.45  6.61 #> sep_xgboost_cv_2_par 155.02  5.82"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"surrogate","dir":"Articles","previous_headings":"","what":"The surrogate regression method class","title":"Shapley value explanations using the regression paradigm","text":"Since regression_separate methods train new regression model gS(ùê±S)g_S(\\boldsymbol{x}_S) coalition S‚äÜ{1,2,‚Ä¶,M}S \\subseteq \\{1,2,\\dots,M\\}, total 2M‚àí22^M-2 models trained, can time-consuming slowly fitted models. minus two corresponds empty grand coalitions. regression_surrogate method class builds ideas regression_separate class, instead fitting new regression model coalition, train single regression model g(ùê±ÃÉS)g(\\tilde{\\boldsymbol{x}}_S) coalitions S‚äÜ{1,2,‚Ä¶,M}S \\subseteq \\{1,2,\\dots,M\\} (except empty grand coalitions), ùê±ÃÉS\\tilde{\\boldsymbol{x}}_S augmented version ùê±S\\boldsymbol{x}_S. See Section 3.6.1 Olsen et al. (2024) details examples. can also apply examples separate regression method class surrogate regression method class.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"surrogate_code","dir":"Articles","previous_headings":"The surrogate regression method class","what":"Code","title":"Shapley value explanations using the regression paradigm","text":"demonstrate surrogate method class using several regression models . specifically, use linear regression, random forest (without () cross-validation), xgboost (without () cross-validation).","code":"# Compute the Shapley value explanations using a surrogate linear regression model explanation_list$sur_lm <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::linear_reg() ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:38 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_surrogate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de4e260984.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using xgboost with default parameters as the surrogate model explanation_list$sur_xgboost <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::boost_tree(engine = \"xgboost\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:39 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de4a6ad2e.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using xgboost with parameters tuned by cross-validation as the surrogate model explanation_list$sur_xgboost_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::boost_tree(     trees = hardhat::tune(),     tree_depth = hardhat::tune(),     engine = \"xgboost\",     mode = \"regression\"   ),   regression.tune_values = expand.grid(trees = c(5, 15, 25), tree_depth = c(2, 6, 10)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:40 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de7fb11618.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using random forest with default parameters as the surrogate model explanation_list$sur_rf <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::rand_forest(engine = \"ranger\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:44 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de2b4a50cc.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using random forest with parameters tuned by cross-validation as the surrogate model explanation_list$sur_rf_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = \"ranger\", mode = \"regression\"   ),   regression.tune_values = dials::grid_regular(     dials::mtry(c(1, ncol(x_explain))),     dials::trees(c(50, 750)),     levels = 6   ),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:50:45 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de51d0ac70.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"surrogate_parallelization","dir":"Articles","previous_headings":"The surrogate regression method class > Code","what":"Parallelization","title":"Shapley value explanations using the regression paradigm","text":"code chunk demonstrates run surrogate regression method class parallel using future package. setup procedure identical one specified separate regression method class. training step surrogate regression model can run parallel tune hyperparameters. parallelize cross-validation procedure training step; hence, apply parallelization training step surrogate model specified hyperparameters. Furthermore, parallelize prediction step (compute v(S)v(S)) way separate regression method class. Note parallelization introduce overhead, can cause slower running code sequentially smaller problems. looking MSEv\\operatorname{MSE}_v evaluation criterion elapsed time, see surrogate methods (except linear regression model) outperform empirical level best separate regression methods. Furthermore, parallelization (4 cores) decreased elapsed time obtaining MSEv\\operatorname{MSE}_v score. identical scores mean separate models identical independent whether run sequentially parallel.","code":"# Cross validate the number of trees in parallel on four threads future::plan(future::multisession, workers = 4) explanation_list$sur_rf_cv_par <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = \"ranger\", mode = \"regression\"   ),   regression.tune_values = dials::grid_regular(     dials::mtry(c(1, ncol(x_explain))),     dials::trees(c(50, 750)),     levels = 6   ),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:05 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_surrogate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de18fe2476.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. future::plan(future::sequential) # To return to non-parallel computation  # Check that we get identical Shapley value explanations all.equal(   explanation_list$sur_rf_cv$shapley_values_est,   explanation_list$sur_rf_cv_par$shapley_values_est ) #> [1] TRUE # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                        MSEv  Time #> MC_empirical         179.43  4.29 #> sep_lm               745.21  0.89 #> sep_pcr              784.91  0.81 #> sep_splines          165.13 -0.34 #> sep_recipe_example   687.45  1.00 #> sep_tree_stump       218.05  0.73 #> sep_tree_default     177.68  0.87 #> sep_tree_cv          222.71  9.19 #> sep_tree_cv_2        219.45 17.92 #> sep_rf               218.13  1.20 #> sep_rf_cv            226.42 21.88 #> sep_xgboost          197.72  2.14 #> sep_xgboost_cv       168.45 27.61 #> sep_xgboost_cv_par   168.45  6.61 #> sep_xgboost_cv_2_par 155.02  5.82 #> sur_lm               649.61  0.60 #> sur_xgboost          169.92  1.17 #> sur_xgboost_cv       169.87  4.48 #> sur_rf               192.12  0.79 #> sur_rf_cv            183.39 19.85 #> sur_rf_cv_par        183.39 16.15  # Compare the MSEv criterion of the different explanation methods. # Include vertical line corresponding to the MSEv of the empirical method. plot_MSEv_scores(explanation_list, method_line = \"MC_empirical\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"new","dir":"Articles","previous_headings":"","what":"Add new regression methods","title":"Shapley value explanations using the regression paradigm","text":"Even though tidymodels framework contains many models, might want add additional methods. following section, demonstrate add projection pursuit regression (PPR) model new method can used shapr compute Shapley value explanations, separate surrogate method. use ppr() implementation stats package fit PPR model. model several hyperparameters can tuned, main hyperparameter number terms nterms. following based tidymodels guide adding new regression models. refer guide details explanations code . can now use PPR model compute Shapley value explanations. can use separate surrogate regression method, can either set number terms num_terms specific value use cross-validation tune hyperparameter. four combinations . can compare MSEv\\operatorname{MSE}_v Shapley value explanations. see conducting cross-validation improves evaluation criterion, also increase running time.","code":"# Step 1: register the model, modes, and arguments parsnip::set_new_model(model = \"ppr_reg\") parsnip::set_model_mode(model = \"ppr_reg\", mode = \"regression\") parsnip::set_model_engine(model = \"ppr_reg\", mode = \"regression\", eng = \"ppr\") parsnip::set_dependency(\"ppr_reg\", eng = \"ppr\", pkg = \"stats\")  # If your function has several parameters, then we add one of these functions for each parameter parsnip::set_model_arg(   model = \"ppr_reg\",   eng = \"ppr\",   original = \"nterms\", # The original parameter name used in stats::ppr   parsnip = \"num_terms\", # Change parameter name to match tidymodels' name convention   func = list(pkg = \"dials\", fun = \"num_terms\"), # list(pkg = \"stats\", fun = \"ppr\"),   has_submodel = FALSE )  # Step 2: create the model function ppr_reg <- function(mode = \"regression\", engine = \"ppr\", num_terms = NULL) {   # Check for correct mode   if (mode != \"regression\") rlang::abort(\"`mode` should be 'regression'\")    # Check for correct engine   if (engine != \"ppr\") rlang::abort(\"`engine` should be 'ppr'\")    # Capture the arguments in quosures   args <- list(num_terms = rlang::enquo(num_terms))    # Save some empty slots for future parts of the specification   parsnip::new_model_spec(     \"ppr_reg\",     args = args,     eng_args = NULL,     mode = mode,     method = NULL,     engine = engine   ) }  # Step 3: add a fit module parsnip::set_fit(   model = \"ppr_reg\",   eng = \"ppr\",   mode = \"regression\",   value = list(     interface = \"formula\",     protect = c(\"formula\", \"data\", \"weights\"),     func = c(pkg = \"stats\", fun = \"ppr\"),     defaults = list()   ) )  parsnip::set_encoding(   model = \"ppr_reg\",   eng = \"ppr\",   mode = \"regression\",   options = list(     predictor_indicators = \"traditional\",     compute_intercept = TRUE,     remove_intercept = TRUE,     allow_sparse_x = FALSE   ) )  # Step 4: add modules for prediction parsnip::set_pred(   model = \"ppr_reg\",   eng = \"ppr\",   mode = \"regression\",   type = \"numeric\",   value = list(     pre = NULL,     post = NULL,     func = c(fun = \"predict\"),     args = list(       object = quote(object$fit),       newdata = quote(new_data),       type = \"numeric\"     )   ) )  # Step 5: add tuning function (used by tune::tune_grid()) tunable.ppr_reg <- function(x, ...) {   tibble::tibble(     name = c(\"num_terms\"),     call_info = list(list(pkg = NULL, fun = \"num_terms\")),     source = \"model_spec\",     component = \"ppr_reg\",     component_id = \"main\"   ) }  # Step 6: add updating function (used by tune::finalize_workflow()) update.ppr_reg <- function(object, parameters = NULL, num_terms = NULL, ...) {   rlang::check_installed(\"parsnip\")   eng_args <- parsnip::update_engine_parameters(object$eng_args, fresh = TRUE, ...)   args <- list(num_terms = rlang::enquo(num_terms))   args <- parsnip::update_main_parameters(args, parameters)   parsnip::new_model_spec(     \"ppr_reg\",     args = args,     eng_args = eng_args,     mode = object$mode,     method = NULL,     engine = object$engine   ) } # PPR separate with specified number of terms explanation_list$sep_ppr <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = ppr_reg(num_terms = 2) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:22 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de69bd9abe.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # PPR separate with cross-validated number of terms explanation_list$sep_ppr_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = ppr_reg(num_terms = hardhat::tune()),   regression.tune_values = dials::grid_regular(dials::num_terms(c(1, 4)), levels = 3),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:23 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3db84edb.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # PPR surrogate with specified number of terms explanation_list$sur_ppr <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = ppr_reg(num_terms = 3) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:31 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3d37d352.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # PPR surrogate with cross-validated number of terms explanation_list$sur_ppr_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = ppr_reg(num_terms = hardhat::tune()),   regression.tune_values = dials::grid_regular(dials::num_terms(c(1, 8)), levels = 4),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:32 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de43746af.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions. # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                        MSEv  Time #> MC_empirical         179.43  4.29 #> sep_lm               745.21  0.89 #> sep_pcr              784.91  0.81 #> sep_splines          165.13 -0.34 #> sep_recipe_example   687.45  1.00 #> sep_tree_stump       218.05  0.73 #> sep_tree_default     177.68  0.87 #> sep_tree_cv          222.71  9.19 #> sep_tree_cv_2        219.45 17.92 #> sep_rf               218.13  1.20 #> sep_rf_cv            226.42 21.88 #> sep_xgboost          197.72  2.14 #> sep_xgboost_cv       168.45 27.61 #> sep_xgboost_cv_par   168.45  6.61 #> sep_xgboost_cv_2_par 155.02  5.82 #> sur_lm               649.61  0.60 #> sur_xgboost          169.92  1.17 #> sur_xgboost_cv       169.87  4.48 #> sur_rf               192.12  0.79 #> sur_rf_cv            183.39 19.85 #> sur_rf_cv_par        183.39 16.15 #> sep_ppr              327.23  0.81 #> sep_ppr_cv           246.28  7.80 #> sur_ppr              395.42  0.62 #> sur_ppr_cv           415.62  1.56  # Compare the MSEv criterion of the different explanation methods plot_MSEv_scores(explanation_list, method_line = \"MC_empirical\")"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"summary_figures","dir":"Articles","previous_headings":"","what":"Summary figures","title":"Shapley value explanations using the regression paradigm","text":"section, compute Shapley value explanations Monte Carlo-based methods shapr package compare results regression-based methods . purpose vignette demonstrate rich possibilities regression paradigm tidymodels framework adds shapr package. code chunk , compute Shapley value explanations using different Monte Carlo-based methods. compare regression Monte Carlo-based methods plotting MSEv\\operatorname{MSE}_v evaluation criterion. continue include vertical line corresponding MSEv\\operatorname{MSE}_v MC_empirical method make comparison easier.  vaeac approach best-performing method according MSEv\\operatorname{MSE}_v evaluation criterion, sep_xgboost_cv_2_par best-performing regression-based method. However, note vaeac method much slower difference MSEv\\operatorname{MSE}_v values minuscule inside confidence intervals. can also order methods easily look order methods according MSEv\\operatorname{MSE}_v criterion.  can also examine different Shapley value explanations first six explicands (two time), still sort methods best worst. methods agree general directions, especially important features (features largest absolute Shapley values), differences less important features. tendencies/discrepancies often visible methods poor/larger MSEv\\operatorname{MSE}_v values.    , focus five best methods (MC_empirical) make easier analyze individual Shapley value explanations, see quite strong agreement different methods.","code":"explanation_list_MC <- list()  # Compute the Shapley value explanations using the independence method explanation_list_MC$MC_independence <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"independence\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:33 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: independence #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de56a6bfeb.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Copy the Shapley value explanations for the empirical method explanation_list_MC$MC_empirical <- explanation_list$MC_empirical  # Compute the Shapley value explanations using the gaussian method explanation_list_MC$MC_gaussian <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:35 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de2140b214.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Compute the Shapley value explanations using the copula method explanation_list_MC$MC_copula <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"copula\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:36 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: copula #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de62620890.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Compute the Shapley value explanations using the ctree method explanation_list_MC$MC_ctree <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"ctree\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:36 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de2d22ae29.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Compute the Shapley value explanations using the vaeac method explanation_list_MC$MC_vaeac <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = p0,   seed = 1,   vaeac.epochs = 10 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:51:38 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: vaeac #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767dec84c22e.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Combine the two explanations lists explanation_list$MC_empirical <- NULL explanation_list <- c(explanation_list_MC, explanation_list) # Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list) #>                        MSEv  Time #> MC_independence      206.92  1.37 #> MC_empirical         179.43  4.29 #> MC_gaussian          235.15  1.00 #> MC_copula            237.35  0.09 #> MC_ctree             190.82  1.89 #> MC_vaeac             145.06 87.86 #> sep_lm               745.21  0.89 #> sep_pcr              784.91  0.81 #> sep_splines          165.13 -0.34 #> sep_recipe_example   687.45  1.00 #> sep_tree_stump       218.05  0.73 #> sep_tree_default     177.68  0.87 #> sep_tree_cv          222.71  9.19 #> sep_tree_cv_2        219.45 17.92 #> sep_rf               218.13  1.20 #> sep_rf_cv            226.42 21.88 #> sep_xgboost          197.72  2.14 #> sep_xgboost_cv       168.45 27.61 #> sep_xgboost_cv_par   168.45  6.61 #> sep_xgboost_cv_2_par 155.02  5.82 #> sur_lm               649.61  0.60 #> sur_xgboost          169.92  1.17 #> sur_xgboost_cv       169.87  4.48 #> sur_rf               192.12  0.79 #> sur_rf_cv            183.39 19.85 #> sur_rf_cv_par        183.39 16.15 #> sep_ppr              327.23  0.81 #> sep_ppr_cv           246.28  7.80 #> sur_ppr              395.42  0.62 #> sur_ppr_cv           415.62  1.56  # Compare the MSEv criterion of the different explanation methods # Include vertical line corresponding to the MSEv of the MC_empirical method plot_MSEv_scores(explanation_list, method_line = \"MC_empirical\") order <- get_k_best_methods(explanation_list, k = length(explanation_list)) plot_MSEv_scores(explanation_list[order], method_line = \"MC_empirical\") plot_SV_several_approaches(explanation_list[order], index_explicands = c(1, 2), facet_ncol = 1) plot_SV_several_approaches(explanation_list[order], index_explicands = c(3, 4), facet_ncol = 1) plot_SV_several_approaches(explanation_list[order], index_explicands = c(5, 6), facet_ncol = 1) # Extract the 5 best methods (and empirical) best_methods <- get_k_best_methods(explanation_list, k = 5) if (!\"MC_empirical\" %in% best_methods) best_methods <- c(best_methods, \"MC_empirical\") plot_SV_several_approaches(explanation_list[best_methods], index_explicands = 1:4)"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"mixed","dir":"Articles","previous_headings":"","what":"Mixed data","title":"Shapley value explanations using the regression paradigm","text":"section, replicate extend mixed data example general usage demonstrating separate surrogate regression methods. Monte Carlo-based methods, independence (recommended), ctree, vaeac methods support mixed data. can divide regression models two groups based whether model can handle categorical features default need apply pre-processing categorical features. pre-processing, mean need convert categorical features numerical values using, example, dummy features. demonstrate using regression.recipe_func function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"mixed-data-setup","dir":"Articles","previous_headings":"Mixed data","what":"Mixed data: setup","title":"Shapley value explanations using the regression paradigm","text":"First, copy setup general usage.","code":"# Convert the month variable to a factor data_cat <- copy(data)[, Month_factor := as.factor(Month)]  data_train_cat <- data_cat[-ind_x_explain, ] data_explain_cat <- data_cat[ind_x_explain, ]  x_var_cat <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month_factor\")  x_train_cat <- data_train_cat[, ..x_var_cat] x_explain_cat <- data_explain_cat[, ..x_var_cat]  p0_cat <- mean(y_train)  # Fitting an lm model here as xgboost does not handle categorical features directly formula <- as.formula(paste0(y_var, \" ~ \", paste0(x_var_cat, collapse = \" + \"))) model_cat <- lm(formula, data_train_cat)  # We could also consider other models such as random forest which supports mixed data # model_cat <- ranger(formula, data_train_cat)  # List to store the explanations for this mixed data setup explanation_list_mixed <- list()"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"mixed-data-monte-carlo-based-methods","dir":"Articles","previous_headings":"Mixed data","what":"Mixed data: Monte Carlo-based methods","title":"Shapley value explanations using the regression paradigm","text":"Second, compute explanations using Monte Carlo-based methods.","code":"explanation_list_mixed$MC_independence <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"independence\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:53:09 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: independence #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de40627dc3.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  explanation_list_mixed$MC_ctree <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"ctree\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:53:10 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de322395e5.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  explanation_list_mixed$MC_vaeac <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"vaeac\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:53:10 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: vaeac #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de7b49d388.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"mixed-data-separate-regression-methods","dir":"Articles","previous_headings":"Mixed data","what":"Mixed data: separate regression methods","title":"Shapley value explanations using the regression paradigm","text":"Third, compute Shapley value explanations using separate regression methods. use many regression models continuous data examples.","code":"# Standard linear regression explanation_list_mixed$sep_lm <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg() ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:55:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de4906ca7c.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Linear regression where we have added splines to the numerical features explanation_list_mixed$sep_splines <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg(),   regression.recipe_func = function(regression_recipe) {     return(step_ns(regression_recipe, all_numeric_predictors(), deg_free = 2))   } ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:55:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de5eda9e5b.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Decision tree with default parameters explanation_list_mixed$sep_tree <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::decision_tree(engine = \"rpart\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:55:47 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de415ca317.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Use trees with cross-validation on the depth and cost complexity. Manually set the values. explanation_list_mixed$sep_tree_cv <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::decision_tree(     tree_depth = hardhat::tune(),     cost_complexity = hardhat::tune(),     engine = \"rpart\",     mode = \"regression\"   ),   regression.tune_values =     expand.grid(tree_depth = c(1, 3, 5), cost_complexity = c(0.001, 0.01, 0.1)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:55:48 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de63e9dcf.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Random forest with default hyperparameters. Do NOT need to use dummy features. explanation_list_mixed$sep_rf <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::rand_forest(engine = \"ranger\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:56:05 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de6311e50a.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Random forest with cross-validated hyperparameters. explanation_list_mixed$sep_rf_cv <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = \"ranger\", mode = \"regression\"   ),   regression.tune_values =     function(x) {       dials::grid_regular(dials::mtry(c(1, ncol(x))), dials::trees(c(50, 750)), levels = 4)     },   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:56:06 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de17ebbb75.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # XGBoost with default hyperparameters, but we have to dummy encode the factors explanation_list_mixed$sep_xgboost <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::boost_tree(engine = \"xgboost\", mode = \"regression\"),   regression.recipe_func = function(regression_recipe) {     return(step_dummy(regression_recipe, all_factor_predictors()))   } ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:56:35 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de58503e37.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # XGBoost with cross-validated hyperparameters and we dummy encode the factors explanation_list_mixed$sep_xgboost_cv <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::boost_tree(     trees = hardhat::tune(),     tree_depth = hardhat::tune(),     engine = \"xgboost\",     mode = \"regression\"   ),   regression.recipe_func = function(regression_recipe) {     return(step_dummy(regression_recipe, all_factor_predictors()))   },   regression.tune_values = expand.grid(trees = c(5, 15, 25), tree_depth = c(2, 6, 10)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:56:37 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de68d8d084.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"mixed-data-surrogate-regression-methods","dir":"Articles","previous_headings":"Mixed data","what":"Mixed data: surrogate regression methods","title":"Shapley value explanations using the regression paradigm","text":"Fourth, compute Shapley value explanations using surrogate regression methods. use regression models separate regression method class.","code":"# Standard linear regression explanation_list_mixed$sur_lm <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::linear_reg() ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:12 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <lm> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_surrogate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767dea198298.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Linear regression where we have added splines to the numerical features # NOTE that we remove the augmented mask variables to avoid a rank-deficient fit explanation_list_mixed$sur_splines <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::linear_reg(),   regression.recipe_func = function(recipe) {     return(step_ns(recipe, all_numeric_predictors(), -starts_with(\"mask_\"), deg_free = 2))   } ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de44f28d9a.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Decision tree with default parameters explanation_list_mixed$sur_tree <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::decision_tree(engine = \"rpart\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de5c19ac4c.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Use trees with cross-validation on the depth and cost complexity. Manually set the values. explanation_list_mixed$sur_tree_cv <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::decision_tree(     tree_depth = hardhat::tune(),     cost_complexity = hardhat::tune(),     engine = \"rpart\",     mode = \"regression\"   ),   regression.tune_values =     expand.grid(tree_depth = c(1, 3, 5), cost_complexity = c(0.001, 0.01, 0.1)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:13 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de169e44c6.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Random forest with default hyperparameters. Do NOT need to use dummy features. explanation_list_mixed$sur_rf <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::rand_forest(engine = \"ranger\", mode = \"regression\") ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:15 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de757a9faf.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Random forest with cross-validated hyperparameters. explanation_list_mixed$sur_rf_cv <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = \"ranger\", mode = \"regression\"   ),   regression.tune_values = expand.grid(mtry = c(1, 2, 4), trees = c(50, 250, 500, 750)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:16 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767dede307a3.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # XGBoost with default hyperparameters, but we have to dummy encode the factors explanation_list_mixed$sur_xgboost <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::boost_tree(engine = \"xgboost\", mode = \"regression\"),   regression.recipe_func = function(regression_recipe) {     return(step_dummy(regression_recipe, all_factor_predictors()))   } ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:25 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de22d41d0d.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # XGBoost with cross-validated hyperparameters and we dummy encode the factors explanation_list_mixed$sur_xgboost_cv <- explain(   model = model_cat,   x_explain = x_explain_cat,   x_train = x_train_cat,   phi0 = p0_cat,   seed = 1,   approach = \"regression_surrogate\",   regression.model = parsnip::boost_tree(     trees = hardhat::tune(),     tree_depth = hardhat::tune(),     engine = \"xgboost\",     mode = \"regression\"   ),   regression.recipe_func = function(regression_recipe) {     return(step_dummy(regression_recipe, all_factor_predictors()))   },   regression.tune_values = expand.grid(trees = c(5, 15, 25), tree_depth = c(2, 6, 10)),   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:26 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de514d028f.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions."},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"summary_mixed","dir":"Articles","previous_headings":"Mixed data","what":"Mixed data: summary","title":"Shapley value explanations using the regression paradigm","text":"Fifth, finally, compare results. surrogate random forest model performs well outperforms cross-validated version, note wide confidence interval. see several regression-based methods outperform Monte Carlo-based methods. specifically, three separate regression methods three surrogate regression methods.  best-performing methods surrogate random forest XGBoost cross-validation methods. Monte Carlo-based methods perform worse, ctree best, seventh-place overall ranking. can also order methods easily look order methods according MSEv\\operatorname{MSE}_v criterion.  also look Shapley value explanations see many methods produce similar explanations.  can also focus Shapley value explanations best five methods according MSEv\\operatorname{MSE}_v criterion. also include ctree method, best-performing Monte Carlo-based method.","code":"# Print the MSEv scores and the elapsed time (in seconds) for the different methods print_MSEv_scores_and_time(explanation_list_mixed) #>                   MSEv   Time #> MC_independence 641.82   1.11 #> MC_ctree        555.58   0.01 #> MC_vaeac        629.56 155.61 #> sep_lm          550.06   0.51 #> sep_splines     541.36   0.68 #> sep_tree        753.84   0.58 #> sep_tree_cv     756.27  17.16 #> sep_rf          523.61   0.94 #> sep_rf_cv       636.46  29.68 #> sep_xgboost     792.17   1.70 #> sep_xgboost_cv  595.64  34.68 #> sur_lm          610.61   0.40 #> sur_splines     596.86   0.47 #> sur_tree        677.04   0.46 #> sur_tree_cv     789.37   1.96 #> sur_rf          406.17   0.70 #> sur_rf_cv       521.25   9.21 #> sur_xgboost     742.54   0.62 #> sur_xgboost_cv  541.19   3.45  # Compare the MSEv criterion of the different explanation methods # Include vertical line corresponding to the MSEv of the empirical method. plot_MSEv_scores(explanation_list_mixed, method_line = \"MC_ctree\") order <- get_k_best_methods(explanation_list_mixed, k = length(explanation_list_mixed)) plot_MSEv_scores(explanation_list_mixed[order], method_line = \"MC_ctree\") plot_SV_several_approaches(explanation_list_mixed[order], index_explicands = c(1, 2), facet_ncol = 1) best_methods <- get_k_best_methods(explanation_list_mixed, k = 5) if (!\"MC_ctree\" %in% best_methods) best_methods <- c(best_methods, \"MC_ctree\") plot_SV_several_approaches(explanation_list_mixed[best_methods], index_explicands = 1:4)"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"regression-arguments-as-strings","dir":"Articles","previous_headings":"","what":"Regression arguments as strings","title":"Shapley value explanations using the regression paradigm","text":"section, demonstrate regression.model, regression.tune_values, regression.recipe_func parameters can provided strings. property convenient explain() function called Python associated shaprpy Python library. , user specify strings containing R code instead deal creating R objects Python. code chunk , see obtain identical MSEv\\operatorname{MSE}_v scores string non-string versions.","code":"explanation_list_str <- list() explanation_list_str$sep_lm <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = \"parsnip::linear_reg()\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:31 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Regression #>  #> ‚Ä¢ Approach: regression_separate #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 20 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3389dc1c.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  explanation_list_str$sep_pcr <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = \"parsnip::linear_reg()\",   regression.recipe_func = \"function(regression_recipe) {     return(recipes::step_pca(regression_recipe, recipes::all_numeric_predictors(), num_comp = 2))   }\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:32 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de5f96c7ad.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  explanation_list_str$sep_splines <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = parsnip::linear_reg(),   regression.recipe_func = \"function(regression_recipe) {     return(recipes::step_ns(regression_recipe, recipes::all_numeric_predictors(), deg_free = 2))   }\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:33 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de19dcc6e6.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  explanation_list_str$sep_tree_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = \"parsnip::decision_tree(     tree_depth = hardhat::tune(), engine = 'rpart', mode = 'regression'   )\",   regression.tune_values = \"dials::grid_regular(dials::tree_depth(), levels = 4)\",   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:34 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de7c90a699.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using random forest with parameters tuned by cross-validation explanation_list_str$sep_rf_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_separate\",   regression.model = \"parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = 'ranger', mode = 'regression'   )\",   regression.tune_values =     \"function(x) {       dials::grid_regular(dials::mtry(c(1, ncol(x))), dials::trees(c(50, 750)), levels = 3)     }\",   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:57:42 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de3e716608.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Using random forest with parameters tuned by cross-validation as the surrogate model explanation_list_str$sur_rf_cv <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   phi0 = p0,   seed = 1,   approach = \"regression_surrogate\",   regression.model = \"parsnip::rand_forest(     mtry = hardhat::tune(), trees = hardhat::tune(), engine = 'ranger', mode = 'regression'   )\",   regression.tune_values = \"dials::grid_regular(     dials::mtry(c(1, ncol(x_explain))),     dials::trees(c(50, 750)),     levels = 6   )\",   regression.vfold_cv_para = list(v = 5) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:58:04 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 20 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpBnaTyV/shapr_obj_767de5b3969fd.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # See that the evaluation scores match the non-string versions. print_MSEv_scores_and_time(explanation_list_str) #>               MSEv  Time #> sep_lm      745.21  0.65 #> sep_pcr     784.91  0.85 #> sep_splines 165.13  0.82 #> sep_tree_cv 222.71  8.73 #> sep_rf_cv   226.42 21.81 #> sur_rf_cv   183.39 19.40 print_MSEv_scores_and_time(explanation_list[names(explanation_list_str)]) #>               MSEv  Time #> sep_lm      745.21  0.89 #> sep_pcr     784.91  0.81 #> sep_splines 165.13 -0.34 #> sep_tree_cv 222.71  9.19 #> sep_rf_cv   226.42 21.88 #> sur_rf_cv   183.39 19.85"},{"path":"https://norskregnesentral.github.io/shapr/articles/regression.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Shapley value explanations using the regression paradigm","text":"vignette demonstrates rich possibilities regression paradigm tidymodels framework add shapr package. seen regression-based methods par outperform Monte Carlo-based methods regarding MSEv\\operatorname{MSE}_v evaluation criterion. Furthermore, seen regression-based methods relatively computationally fast parallelization can used speed computations.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"vaeac","dir":"Articles","previous_headings":"","what":"Vaeac","title":"More details and advanced usage of the `vaeac` approach","text":"approach supports mixed features Variational AutoEncoder Arbitrary Conditioning (Olsen et al. (2022)), abbreviated vaeac. vaeac extension regular variational autoencoder (Kingma Welling (2014)), instead giving probabilistic representation distribution p(ùê±)p(\\boldsymbol{x}) gives probabilistic representation conditional distribution p(ùê±ùíÆ‚Äæ‚à£ùê±ùíÆ)p(\\boldsymbol{x}_{\\bar{\\mathcal{S}}} \\mid \\boldsymbol{x}_{\\mathcal{S}}), possible feature subsets ùíÆ‚äÜ‚Ñ≥\\mathcal{S}\\subseteq\\mathcal{M} simultaneously, ‚Ñ≥\\mathcal{M} set features. , single vaeac model needed model conditional distributions. vaeac consists three neural networks: full encoder, masked encoder, decoder. encoders map full masked/conditional input representations, .e., ùê±\\boldsymbol{x} ùê±ùíÆ\\boldsymbol{x}_{\\mathcal{S}}, respectively, latent probabilistic representations. Sampled instances latent probabilistic representations sent decoder, maps back feature space provides sampleable probabilistic representation unconditioned features ùê±ùíÆ‚Äæ\\boldsymbol{x}_{\\bar{\\mathcal{S}}}. full encoder used training phase vaeac model guide training process masked encoder, former relies full input sample ùê±\\boldsymbol{x}, accessible deployment phase (generate Monte Carlo samples), access ùê±ùíÆ\\boldsymbol{x}_{\\mathcal{S}}. networks trained minimizing variational lower bound, see Section 3 Olsen et al. (2022) -depth introduction vaeac methodology. use vaeac model epoch obtains lowest validation IWAE score generate Monte Carlo samples used Shapley value computations. fit vaeac model using torch package ùñ±\\textsf{R} (Falbel Luraschi (2023)). main parameters number layers networks (vaeac.depth), width layers (vaeac.width), number dimensions latent space (vaeac.latent_dim), activation function layers networks (vaeac.activation_function), learning rate ADAM optimizer (vaeac.lr), number vaeac models initiate remedy poorly initiated model parameter values (vaeac.n_vaeacs_initialize), number learning epochs (vaeac.epochs). Call ?shapr::setup_approach.vaeac detailed description parameters. additional extra parameters can set including named list call explain() function. example, can change batch size 32 including vaeac.extra_parameters = list(vaeac.batch_size = 32) parameter call explain() function. See ?shapr::vaeac_get_extra_para_default description possible extra parameters vaeac approach. main parameters entered directly explain() function, extra parameters included named list called vaeac.extra_parameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"code","dir":"Articles","previous_headings":"","what":"Code Examples","title":"More details and advanced usage of the `vaeac` approach","text":"now demonstrate vaeac approach several different use cases. Note vignette runs CPU, code sections can run GPU . enable GPU, include vaeac.extra_parameters = list(vaeac.cuda = TRUE) calls explain() function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"basicexample","dir":"Articles","previous_headings":"Code Examples","what":"Basic Example","title":"More details and advanced usage of the `vaeac` approach","text":"go use vaeac approach data general usage First load shapr package First set model want explain.","code":"library(shapr) library(xgboost) library(data.table)  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\") y_var <- \"Ozone\"  ind_x_explain <- 1:6 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Fitting a basic xgboost model to the training data model <- xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 100,   verbose = FALSE )  # Specifying the phi_0, i.e. the expected prediction without any features phi0 <- mean(y_train)"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"first-vaeac-example","dir":"Articles","previous_headings":"Code Examples","what":"First vaeac example","title":"More details and advanced usage of the `vaeac` approach","text":"now going explain predictions made model using vaeac approach. can look Shapley values.","code":"n_MC_samples <- 25 # Low number of MC samples to make the vignette build faster vaeac.n_vaeacs_initialize <- 2 # Initialize several vaeacs to counteract bad initialization values vaeac.epochs <- 4 # The number of training epochs  explanation <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = n_MC_samples,   vaeac.epochs = vaeac.epochs,   vaeac.n_vaeacs_initialize = vaeac.n_vaeacs_initialize ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:08 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16726424c3c.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions. # Printing and plotting the Shapley values. # See ?shapr::explain for interpretation of the values. print(explanation$shapley_values_est) #>    explain_id   none  Solar.R      Wind     Temp    Month #>         <int>  <num>    <num>     <num>    <num>    <num> #> 1:          1 43.086  4.35827  -0.49487 -16.7173  0.55352 #> 2:          2 43.086 -2.06968  -2.76668 -17.3760 -1.84287 #> 3:          3 43.086  1.24259  -5.05865 -18.7919 -0.68187 #> 4:          4 43.086  5.20834 -10.03741  -8.4807 -1.28136 #> 5:          5 43.086  0.22127  -3.05847 -17.9177 -3.62080 #> 6:          6 43.086  4.25576  -9.58514 -18.7123  2.62017 plot(explanation)"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"pretrained_vaeac","dir":"Articles","previous_headings":"Code Examples","what":"Pre-trained vaeac","title":"More details and advanced usage of the `vaeac` approach","text":"user pre-trained vaeac model (previous run), user can send explain() function shapr skip training new vaeac model rather use provided vaeac model. useful want explain new predictions using combinations/coalitions previously, .e., new x_explain. Note new x_explain must features . vaeac model accessible via explanation$internal$parameters$vaeac. Note let 'vS_details' %% verbose explain(), shapr give message loads pretrained vaeac model instead training scratch. example, extract trained vaeac model previous example send explain().","code":"# Send the pre-trained vaeac model expl_pretrained_vaeac <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = n_MC_samples,   vaeac.extra_parameters = list(     vaeac.pretrained_vaeac_model = explanation$internal$parameters$vaeac   ) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:15 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16770a1f0ce.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Check that this version provides the same Shapley values all.equal(explanation$shapley_values_est, expl_pretrained_vaeac$shapley_values_est) #> [1] TRUE"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"pretrained_vaeac_path","dir":"Articles","previous_headings":"Code Examples","what":"Pre-trained vaeac (path)","title":"More details and advanced usage of the `vaeac` approach","text":"can also just provide path stored vaeac model. beneficial stored vaeac model computer whole explanation object. possible save paths stored explanation$internal$parameters$vaeac$model. Note let 'vS_details' %% verbose explain(), shapr give message loads pretrained vaeac model instead training scratch.","code":"# Call `explanation$internal$parameters$vaeac$model` to see possible vaeac models. We use `best` below. # Send the pre-trained vaeac path expl_pretrained_vaeac_path <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = n_MC_samples,   vaeac.extra_parameters = list(     vaeac.pretrained_vaeac_model = explanation$internal$parameters$vaeac$models$best   ) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:17 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d167239e7592.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Check that this version provides the same Shapley values all.equal(explanation$shapley_values_est, expl_pretrained_vaeac_path$shapley_values_est) #> [1] TRUE"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"n_coalitions","dir":"Articles","previous_headings":"Code Examples","what":"Specified max_n_coalitions","title":"More details and advanced usage of the `vaeac` approach","text":"section, discuss general shapr parameter explain() function method independent, namely, max_n_coalitions. user can limit Shapley value computations subset coalitions setting max_n_coalitions parameter value lower 2nfeatures2^{n_\\text{features}}. Note need train new vaeac model can use one trained 16 coalitions now using subset . applicable way around.  Note train vaeac model scratch setup , vaeac model use MCAR (missing completely random) mask generator, rather mask generator ensures vaeac model trained specified set coalitions. case, set sampled coalitions.","code":"# Send the pre-trained vaeac path expl_batches_combinations <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   max_n_coalitions = 10,   n_MC_samples = n_MC_samples,   vaeac.extra_parameters = list(     vaeac.pretrained_vaeac_model = explanation$internal$parameters$vaeac   ) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:21 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1674e77e85c.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 10 of 16 coalitions.  # Gives different Shapley values as the latter are based only on a subset of coalitions plot_SV_several_approaches(list(\"Original\" = explanation, \"Other combi.\" = expl_batches_combinations)) # Can compare that to the situation where we have exact computations (i.e., include all coalitions) explanation$internal$objects$X #> Index: <coalition_size> #>     id_coalition coalitions coalitions_str coalition_size     N shapley_weight #>            <int>     <list>         <char>          <int> <int>          <num> #>  1:            1                                        0     1       1.00e+06 #>  2:            2          1              1              1     4       2.50e-01 #>  3:            3          2              2              1     4       2.50e-01 #>  4:            4          3              3              1     4       2.50e-01 #>  5:            5          4              4              1     4       2.50e-01 #>  6:            6        1,2            1 2              2     6       1.25e-01 #>  7:            7        1,3            1 3              2     6       1.25e-01 #>  8:            8        1,4            1 4              2     6       1.25e-01 #>  9:            9        2,3            2 3              2     6       1.25e-01 #> 10:           10        2,4            2 4              2     6       1.25e-01 #> 11:           11        3,4            3 4              2     6       1.25e-01 #> 12:           12      1,2,3          1 2 3              3     4       2.50e-01 #> 13:           13      1,2,4          1 2 4              3     4       2.50e-01 #> 14:           14      1,3,4          1 3 4              3     4       2.50e-01 #> 15:           15      2,3,4          2 3 4              3     4       2.50e-01 #> 16:           16    1,2,3,4        1 2 3 4              4     1       1.00e+06 #>     sample_freq features approach #>          <lgcl>   <list>   <char> #>  1:          NA              <NA> #>  2:          NA        1    vaeac #>  3:          NA        2    vaeac #>  4:          NA        3    vaeac #>  5:          NA        4    vaeac #>  6:          NA      1,2    vaeac #>  7:          NA      1,3    vaeac #>  8:          NA      1,4    vaeac #>  9:          NA      2,3    vaeac #> 10:          NA      2,4    vaeac #> 11:          NA      3,4    vaeac #> 12:          NA    1,2,3    vaeac #> 13:          NA    1,2,4    vaeac #> 14:          NA    1,3,4    vaeac #> 15:          NA    2,3,4    vaeac #> 16:          NA  1,2,3,4     <NA> expl_batches_combinations_2 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   max_n_coalitions = 10,   n_MC_samples = n_MC_samples,   vaeac.n_vaeacs_initialize = 1,   vaeac.epochs = 3,   verbose = \"vS_details\" ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:26 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Extra info about the pretrained vaeac model ‚îÄ‚îÄ #>  #> Training the `vaeac` model with the provided parameters from scratch #> on CPU. #> Using 'specified_masks_mask_generator' with '8' coalitions. #> The vaeac model contains 17032 trainable parameters. #> Initializing vaeac model number 1 of 1. #> Best vaeac inititalization was number 1 (of 1) with a training VLB = #> -6.49 after 2 epochs. Continue to train this inititalization. #>  #> Results of the `vaeac` training process: #> Best epoch:             3.   VLB = -4.812    IWAE = -3.235   IWAE_running = -3.542 #> Best running avg epoch: 3.   VLB = -4.812    IWAE = -3.235   IWAE_running = -3.542 #> Last epoch:             3.   VLB = -4.812    IWAE = -3.235   IWAE_running = -3.542 #> ‚Ñπ The trained `vaeac` models are saved to folder '/tmp/RtmpT1hWbC' at #> '/tmp/RtmpT1hWbC/X2025.08.21.09.03.25.725002_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.03.25.725002_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best_running.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.03.25.725002_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_last.pt'"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"paired_sampling","dir":"Articles","previous_headings":"Code Examples","what":"Paired sampling","title":"More details and advanced usage of the `vaeac` approach","text":"vaeac approach can use paired sampling improve stability vaeac training procedure. using paired sampling, observation training batches duplicated, first version masked SS second version masked complement S‚Äæ\\bar{S}. masks taken explanation$internal$objects$S matrix. Note vaeac check complement also said matrix. means Shapley value explanations computed based subset coalitions, vaeac model might trained coalitions used computing Shapley values. considered redundant training increases stability performance vaeac model whole; hence, recommend using paired sampling (default). Furthermore, masks randomly selected observation batch. training time using paired sampling higher comparison random sampling due complex implementation. can compare results looking training validation errors MSEvMSE_v evaluation criterion. using plot_vaeac_eval_crit() plot_MSEv_eval_crit() functions shapr package, respectively.   looking time, see paired version takes (bit) longer time setup_computation phase, , training phase.","code":"expl_paired_sampling_TRUE <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = n_MC_samples,   vaeac.epochs = 10,   vaeac.n_vaeacs_initialize = 1,   vaeac.extra_parameters = list(vaeac.paired_sampling = TRUE) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:31 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1674c18fd31.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  expl_paired_sampling_FALSE <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = n_MC_samples,   vaeac.epochs = 10,   vaeac.n_vaeacs_initialize = 1,   vaeac.extra_parameters = list(vaeac.paired_sampling = FALSE) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:41 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: vaeac #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1674d64a275.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions. explanation_list <- list(\"Regular samp.\" = expl_paired_sampling_FALSE,                          \"Paired samp.\" = expl_paired_sampling_TRUE) plot_vaeac_eval_crit(explanation_list, plot_type = \"criterion\") plot_MSEv_eval_crit(explanation_list) rbind(   \"Paired\" = expl_paired_sampling_TRUE$timing$overall_timing_secs,   \"Regular\" = expl_paired_sampling_FALSE$timing$overall_timing_secs ) #>            setup test_prediction main_computation finalize_explanation #> Paired  0.056028        0.059795           9.9440             0.003880 #> Regular 0.091349        0.083601           9.2099             0.003351"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"progress_bar","dir":"Articles","previous_headings":"Code Examples","what":"Progressr","title":"More details and advanced usage of the `vaeac` approach","text":"discussed general usage, shapr package provides two ways receiving information progress approach. First, shapr package provides progress updates computation Shapley values progressr package. Second, user can also get various form information verbose explain(). letting 'vS_details' %% verbose, get extra information related vaeac approach. verbose parameter works independently progressr package. Meaning user can chose use none, either, options simultaneously. give two examples , refer reader general usage detailed information. setting c(\"basic\", \"vS_details\"), get basic messages explanation case messages estimation vaeac approach. visual information can use progressr package. can help us see detailed progress training step final vaeac model. Note default vS_details part verbose, meaning get messages vaeac approach get progress bars. See general usage examples change progress bar.","code":"expl_with_messages <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = n_MC_samples,   verbose = c(\"basic\",\"vS_details\"),   vaeac.epochs = 5,   vaeac.n_vaeacs_initialize = 2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:03:53 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 25 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1677f1a868f.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #>  #>  #> ‚îÄ‚îÄ Extra info about the pretrained vaeac model ‚îÄ‚îÄ #>  #>  #>  #> Training the `vaeac` model with the provided parameters from scratch #> on CPU. #>  #> Using 'mcar_mask_generator' with 'masking_ratio = 0.5'. #>  #> The vaeac model contains 17032 trainable parameters. #>  #> Initializing vaeac model number 1 of 2. #>  #> Initializing vaeac model number 2 of 2. #>  #> Best vaeac inititalization was number 2 (of 2) with a training VLB = #> -4.566 after 2 epochs. Continue to train this inititalization. #>  #>  #> Results of the `vaeac` training process: #> Best epoch:             5.   VLB = -3.318    IWAE = -3.049   IWAE_running = -3.149 #> Best running avg epoch: 5.   VLB = -3.318    IWAE = -3.049   IWAE_running = -3.149 #> Last epoch:             5.   VLB = -3.318    IWAE = -3.049   IWAE_running = -3.149 #>  #> ‚Ñπ The trained `vaeac` models are saved to folder '/tmp/RtmpT1hWbC' at #> '/tmp/RtmpT1hWbC/X2025.08.21.09.03.52.920419_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.03.52.920419_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best_running.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.03.52.920419_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_last.pt' library(progressr) progressr::handlers(\"cli\") # Use `progressr::handlers(\"void\")` to silence all `progressr` updates progressr::with_progress({   expl_with_progressr <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"vaeac\",     phi0 = phi0,     seed = 1,     n_MC_samples = n_MC_samples,     verbose = \"vS_details\",     vaeac.epochs = 5,     vaeac.n_vaeacs_initialize = 2   ) }) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:04:00 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Extra info about the pretrained vaeac model ‚îÄ‚îÄ #>  #> Training the `vaeac` model with the provided parameters from scratch #> on CPU. #> Using 'mcar_mask_generator' with 'masking_ratio = 0.5'. #> The vaeac model contains 17032 trainable parameters. #> Initializing vaeac model number 1 of 2. #>  [KInitializing vaeac model number 2 of 2. #> ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                        29% | Training vaeac (init. 1 of 2):‚Ä¶  [KBest vaeac inititalization was number 2 (of 2) with a training VLB = #> -4.566 after 2 epochs. Continue to train this inititalization. #> ‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†                57% | Training vaeac (init. 2 of 2):‚Ä¶ #> Results of the `vaeac` training process: #> Best epoch:             5.   VLB = -3.318    IWAE = -3.049   IWAE_running = -3.149 #> Best running avg epoch: 5.   VLB = -3.318    IWAE = -3.049   IWAE_running = -3.149 #> Last epoch:             5.   VLB = -3.318    IWAE = -3.049   IWAE_running = -3.149 #> ‚Ñπ The trained `vaeac` models are saved to folder '/tmp/RtmpT1hWbC' at #> '/tmp/RtmpT1hWbC/X2025.08.21.09.04.00.491651_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.04.00.491651_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best_running.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.04.00.491651_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_last.pt' all.equal(expl_with_messages$shapley_values_est, expl_with_progressr$shapley_values_est) #> [1] TRUE"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"continue_training","dir":"Articles","previous_headings":"Code Examples","what":"Continue the training of the vaeac approach","title":"More details and advanced usage of the `vaeac` approach","text":"case user set low number training epochs sees network still learning, user can continue train network stopped. Thus, good workflow can therefore call explain() function n_MC_samples = 1 (avoid spending much time generating MC samples), look training evaluation plots vaeac. satisfied, train . satisfied, call explain() function , time using extra parameter vaeac.pretrained_vaeac_model, illustrated . Note set number vaeac.epochs low example recommend using many epochs. can compare results looking training validation errors MSEvMSE_v evaluation criterion. using plot_vaeac_eval_crit() plot_MSEv_eval_crit() functions shapr package, respectively. also use plot_vaeac_imputed_ggpairs() function generates samples p(x)p(x), meant sanity check see vaeac model able follow general structure/distribution data. However, recall vaeac model never trained empty coalition, produced samples taken grain salt.      can see extra training decreased MSEv score. Shapley value explanations also changed, often comparable.","code":"expl_little_training <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   vaeac.epochs = 3,   vaeac.n_vaeacs_initialize = 2 )  # Look at the training and validation errors. Not happy and want to train more. plot_vaeac_eval_crit(list(\"Original\" = expl_little_training), plot_type = \"method\") # Can also see how well vaeac generates data from the full joint distribution. Quite good. plot_vaeac_imputed_ggpairs(   explanation = expl_little_training,   which_vaeac_model = \"best\",   x_true = x_train ) + ggplot2::labs(title = NULL) # Make a copy of the explanation object and continue to train the vaeac model some more epochs expl_train_more <- expl_little_training expl_train_more$internal$parameters$vaeac <-   vaeac_train_model_continue(     explanation = expl_train_more,     epochs_new = 5,     x_train = x_train   )  # Compute the Shapley values again but this time using the extra trained vaeac model expl_train_more_vaeac <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   vaeac.extra_parameters = list(     vaeac.pretrained_vaeac_model = expl_train_more$internal$parameters$vaeac   ) )  # Look at the training and validation errors and conclude that we want to train some more plot_vaeac_eval_crit(   list(\"Original\" = expl_little_training, \"More epochs\" = expl_train_more),   plot_type = \"method\" ) # Continue to train the vaeac model some more epochs expl_train_even_more <- expl_train_more expl_train_even_more$internal$parameters$vaeac <-   vaeac_train_model_continue(     explanation = expl_train_even_more,     epochs_new = 10,     x_train = x_train   )  # Compute the Shapley values again but this time using the even more trained vaeac model expl_train_even_more_vaeac <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   vaeac.extra_parameters = list(     vaeac.pretrained_vaeac_model = expl_train_even_more$internal$parameters$vaeac   ) )  # Look at the training and validation errors. plot_vaeac_eval_crit(   list(     \"Original\" = expl_little_training,     \"More epochs\" = expl_train_more,     \"Even more epochs\" = expl_train_even_more   ),   plot_type = \"method\" ) # Can also see how well vaeac generates data from the full joint distribution plot_vaeac_imputed_ggpairs(   explanation = expl_train_even_more,   which_vaeac_model = \"best\",   x_true = x_train ) + ggplot2::labs(title = NULL) plot_MSEv_eval_crit(list(   \"Few epochs\" = expl_little_training,   \"More epochs\" = expl_train_more_vaeac,   \"Even more epochs\" = expl_train_even_more_vaeac )) # We see that the Shapley values have changed, but they are often comparable plot_SV_several_approaches(list(   \"Few epochs\" = expl_little_training,   \"More epochs\" = expl_train_more_vaeac,   \"Even more epochs\" = expl_train_even_more_vaeac ))"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"early_stopping","dir":"Articles","previous_headings":"Code Examples","what":"Vaeac with early stopping","title":"More details and advanced usage of the `vaeac` approach","text":"want specify number epochs, uncertain many epochs take vaeac model properly trained, good choice rather use early stopping. means can set vaeac.epochs large number let vaeac.epochs_early_stopping example 5. means vaeac model stop training procedure improvement validation score 5 epochs.  However, can train fixed amount epochs desired. can setting happy IWAE curve feel set vaeac.epochs_early_stopping low value max number epochs (vaeac.epochs) reached.  can use extra trained version compute Shapley value explanations compare previous version used early stopping. see non-significant difference.","code":"# Low value for `vaeac.epochs_early_stopping` here to build the vignette faster expl_early_stopping <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   verbose = c(\"basic\",\"vS_details\"),   vaeac.epochs = 1000, # Set it to a big number   vaeac.n_vaeacs_initialize = 2,   vaeac.extra_parameters = list(vaeac.epochs_early_stopping = 2) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:05:30 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 250 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1675e369bad.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #>  #>  #> ‚îÄ‚îÄ Extra info about the pretrained vaeac model ‚îÄ‚îÄ #>  #>  #>  #> Training the `vaeac` model with the provided parameters from scratch #> on CPU. #>  #> Using 'mcar_mask_generator' with 'masking_ratio = 0.5'. #>  #> The vaeac model contains 17032 trainable parameters. #>  #> Initializing vaeac model number 1 of 2. #>  #> Initializing vaeac model number 2 of 2. #>  #> Best vaeac inititalization was number 2 (of 2) with a training VLB = #> -4.566 after 2 epochs. Continue to train this inititalization. #>  #> No IWAE improvment in 2 epochs. Apply early stopping at epoch 14. #>  #>  #> Results of the `vaeac` training process: #> Best epoch:             12.  VLB = -2.958    IWAE = -2.930   IWAE_running = -2.991 #> Best running avg epoch: 12.  VLB = -2.958    IWAE = -2.930   IWAE_running = -2.991 #> Last epoch:             14.  VLB = -2.971    IWAE = -2.955   IWAE_running = -2.996 #>  #> ‚Ñπ The trained `vaeac` models are saved to folder '/tmp/RtmpT1hWbC' at #> '/tmp/RtmpT1hWbC/X2025.08.21.09.05.30.233223_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.05.30.233223_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best_running.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.05.30.233223_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_last.pt'  # Look at the training and validation errors. We are quite happy with it. plot_vaeac_eval_crit(   list(\"Vaeac early stopping\" = expl_early_stopping),   plot_type = \"method\" ) # Make a copy of the explanation object which we are to train further. expl_early_stopping_train_more <- expl_early_stopping  # Continue to train the vaeac model some more epochs expl_early_stopping_train_more$internal$parameters$vaeac <-   vaeac_train_model_continue(     explanation = expl_early_stopping_train_more,     epochs_new = 15,     x_train = x_train,     verbose = NULL   )  # Can even do it twice if desired expl_early_stopping_train_more$internal$parameters$vaeac <-   vaeac_train_model_continue(     explanation = expl_early_stopping_train_more,     epochs_new = 10,     x_train = x_train,     verbose = NULL   )  # Look at the training and validation errors. We see some improvement plot_vaeac_eval_crit(   list(     \"Vaeac early stopping\" = expl_early_stopping,     \"Vaeac early stopping more epochs\" = expl_early_stopping_train_more   ),   plot_type = \"method\" ) # Use extra trained vaeac model to compute Shapley values again. expl_early_stopping_train_more <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   vaeac.extra_parameters = list(     vaeac.pretrained_vaeac_model = expl_early_stopping_train_more$internal$parameters$vaeac   ) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:06:16 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: vaeac #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 250 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d16736a9c26c.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # We can compare their MSEv scores plot_MSEv_eval_crit(list(   \"Vaeac early stopping\" = expl_early_stopping,   \"Vaeac early stopping more epochs\" = expl_early_stopping_train_more )) # We see that the Shapley values have changed, but only slightly plot_SV_several_approaches(list(   \"Vaeac early stopping\" = expl_early_stopping,   \"Vaeac early stopping more epochs\" = expl_early_stopping_train_more ))"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"grouping_of_features","dir":"Articles","previous_headings":"Code Examples","what":"Grouping of features","title":"More details and advanced usage of the `vaeac` approach","text":"train vaeac model explain groups features, vaeac model use ‚ÄúSpecified_masks_mask_generator‚Äù, ensures vaeac model trains specified set coalitions. case, ensure features group always either conditioned unconditioned. goes group B. Note setup, 4 possible coalitions, vaeac trains 2 coalitions empty grand coalitions needed Shapley value computations.","code":"expl_group <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   group = list(A = c(\"Temp\", \"Month\"), B = c(\"Wind\", \"Solar.R\")),   n_MC_samples = n_MC_samples,   verbose = \"vS_details\",   vaeac.epochs = 4,   vaeac.n_vaeacs_initialize = 2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:06:40 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Extra info about the pretrained vaeac model ‚îÄ‚îÄ #>  #> Training the `vaeac` model with the provided parameters from scratch #> on CPU. #> Using 'specified_masks_mask_generator' with '2' coalitions. #> The vaeac model contains 17032 trainable parameters. #> Initializing vaeac model number 1 of 2. #> Initializing vaeac model number 2 of 2. #> Best vaeac inititalization was number 2 (of 2) with a training VLB = #> -4.814 after 2 epochs. Continue to train this inititalization. #>  #> Results of the `vaeac` training process: #> Best epoch:             3.   VLB = -3.935    IWAE = -3.124   IWAE_running = -3.267 #> Best running avg epoch: 4.   VLB = -3.619    IWAE = -3.138   IWAE_running = -3.235 #> Last epoch:             4.   VLB = -3.619    IWAE = -3.138   IWAE_running = -3.235 #> ‚Ñπ The trained `vaeac` models are saved to folder '/tmp/RtmpT1hWbC' at #> '/tmp/RtmpT1hWbC/X2025.08.21.09.06.40.187257_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.06.40.187257_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_best_running.pt' #> '/tmp/RtmpT1hWbC/X2025.08.21.09.06.40.187257_n_features_4_n_train_105_depth_3_width_32_latent_8_lr_0.001_epoch_last.pt'  # Plot the resulting explanations plot(expl_group)"},{"path":"https://norskregnesentral.github.io/shapr/articles/vaeac.html","id":"mixed_data","dir":"Articles","previous_headings":"Code Examples","what":"Mixed Data","title":"More details and advanced usage of the `vaeac` approach","text":"look setup mixed data, .e., data contains categorical continuous features. First set data model. compute explanations using ctree vaeac approaches. vaeac approach, consider two setups: default architecture, simpler one without skip connections. illustrate skip connections improve vaeac method. use ctree default parameters.","code":"library(ranger) #> ranger 0.17.0 using 2 threads (default). Change with num.threads in ranger() and predict(), options(Ncpus = N), options(ranger.num.threads = N) or environment variable R_RANGER_NUM_THREADS. data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  # Convert the month variable to a factor data[, Month_factor := as.factor(Month)]  x_var_cat <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month_factor\") y_var <- \"Ozone\"  ind_x_explain <- 1:6  data_train_cat <- data[-ind_x_explain, ] x_train_cat <- data_train_cat[, ..x_var_cat] x_explain_cat <- data[ind_x_explain, ][, ..x_var_cat]  # Fit a random forest model to the training data model <- ranger(as.formula(paste0(y_var, \" ~ \", paste0(x_var_cat, collapse = \" + \"))),   data = data_train_cat )  # Specifying the phi_0, i.e. the expected prediction without any features phi0 <- mean(data_train_cat[, get(y_var)]) # Here we use the ctree approach expl_ctree <- explain(   model = model,   x_explain = x_explain_cat,   x_train = x_train_cat,   approach = \"ctree\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:06:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <ranger> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: ctree #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 250 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1671ad95d5f.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Then we use the vaeac approach expl_vaeac_with <- explain(   model = model,   x_explain = x_explain_cat,   x_train = x_train_cat,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   vaeac.epochs = 50,   vaeac.n_vaeacs_initialize = 4 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:06:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <ranger> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: vaeac #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 250 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1675bc73b0f.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Then we use the vaeac approach expl_vaeac_without <- explain(   model = model,   x_explain = x_explain_cat,   x_train = x_train_cat,   approach = \"vaeac\",   phi0 = phi0,   seed = 1,   n_MC_samples = 250,   vaeac.epochs = 50,   vaeac.n_vaeacs_initialize = 4,   vaeac.extra_parameters = list(     vaeac.skip_conn_layer = FALSE,     vaeac.skip_conn_masked_enc_dec = FALSE   ) ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-21 09:07:38 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <ranger> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: vaeac #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 250 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpT1hWbC/shapr_obj_6d1673347bdac.rds' #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  # We see that the `vaeac` model without the skip connections performs worse plot_vaeac_eval_crit(   list(     \"Vaeac w.o. skip-con.\" = expl_vaeac_without,     \"Vaeac w. skip-con.\" = expl_vaeac_with   ),   plot_type = \"criterion\" ) # The `vaeac` model with skip connections has the lowest/best MSE_Frye evaluation criterion score plot_MSEv_eval_crit(list(   \"Vaeac w.o. skip-con.\" = expl_vaeac_without,   \"Vaeac w. skip-con.\" = expl_vaeac_with,   \"Ctree\" = expl_ctree )) # Can compare the Shapley values. Ctree and vaeac with skip connections produce similar explanations. plot_SV_several_approaches(   list(     \"Vaeac w.o. skip-con.\" = expl_vaeac_without,     \"Vaeac w. skip-con.\" = expl_vaeac_with,     \"Ctree\" = expl_ctree   ),   index_explicands = 1:6 )"},{"path":"https://norskregnesentral.github.io/shapr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Martin Jullum. Maintainer, author. Lars Henry Berge Olsen. Author. Annabelle Redelmeier. Author. Jon Lachmann. Author. Nikolai Sellereite. Author. Anders L√∏land. Contributor. Jens Christian Wahl. Contributor. Camilla Lingj√¶rde. Contributor. Norsk Regnesentral. Copyright holder, funder.","code":""},{"path":"https://norskregnesentral.github.io/shapr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Martin Jullum, Lars Henry Berge Olsen, Jon Lachmann, Annabelle Redelmeier (2025). ‚Äúshapr: Explaining Machine Learning Models Conditional Shapley Values R Python.‚Äù arXiv preprint arXiv:2504.01842. Sellereite N. & Jullum M. (2019). ‚Äúshapr: R-package explaining machine learning models dependence-aware Shapley values.‚Äù Journal Open Source Software, 5(46), 2027. doi:10.21105/joss.02027.","code":"@Article{,   title = {shapr: Explaining Machine Learning Models with Conditional Shapley Values in R and Python},   author = {{Martin Jullum, Lars Henry Berge Olsen, Jon Lachmann, Annabelle Redelmeier}},   journal = {arXiv preprint arXiv:2504.01842},   year = {2025}, } @Article{,   title = {shapr: An R-package for explaining machine learning models with dependence-aware Shapley values},   author = {{Sellereite N. & Jullum M.}},   journal = {Journal of Open Source Software},   year = {2019},   volume = {5},   number = {46},   pages = {2027},   doi = {10.21105/joss.02027}, }"},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"shapr-","dir":"","previous_headings":"","what":"Prediction Explanation with Dependence-Aware Shapley Values","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"See pkgdown site norskregnesentral.github.io/shapr/ complete introduction examples documentation package. overview methodology capabilities package (per shapr v1.0.4), see software paper Jullum et al. (2025), available preprint .","code":""},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"news","dir":"","previous_headings":"","what":"NEWS","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"shapr version 1.0.0 (GitHub , Nov 2024) version 1.0.1 (CRAN, Jan 2025), package underwent major update, providing full restructuring code base, full suite new functionality, including: long list approaches estimating contribution/value function v(S)v(S), including Variational Autoencoders regression-based methods Iterative Shapley value estimation convergence detection Parallelized computations progress updates Reweighted Kernel SHAP faster convergence New function explain_forecast() explaining forecasts Asymmetric causal Shapley values Several methodological, computational user-experience improvements Python wrapper shaprpy making core functionality shapr available Python See NEWS complete list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"coming-from-shapr--100","dir":"","previous_headings":"NEWS","what":"Coming from shapr < 1.0.0?","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"shapr version >= 1.0.0 comes number breaking changes. notably, moved using two functions (shapr() explain()) one function (explain()). addition, custom models now explained passing prediction function directly explain(). Several input arguments renamed, functions edge cases removed simplify code base. Click view version README old syntax (v0.2.2).","code":""},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"python-wrapper","dir":"","previous_headings":"NEWS","what":"Python wrapper","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"provide Python wrapper (shaprpy) allows explaining Python models methodology implemented shapr, directly Python. wrapper calls R internally therefore requires installation R. See installation instructions examples.","code":""},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"the-package","dir":"","previous_headings":"","what":"The package","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"shapr R package implements enhanced version Kernel SHAP method approximating Shapley values, strong focus conditional Shapley values. core idea remain completely model-agnostic offering variety methods estimating contribution functions, enabling accurate computation conditional Shapley values across different feature types, dependencies, distributions. package also includes evaluation metrics compare various approaches. features like parallelized computations, convergence detection, progress updates, extensive plotting options, shapr highly efficient user-friendly tool, delivering precise estimates conditional Shapley values, critical understanding features truly contribute predictions. basic example provided . Otherwise, refer pkgdown website vignettes details examples.","code":""},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"shapr available CRAN can installed R : install development version shapr, available GitHub, use also install dependencies, use","code":"install.packages(\"shapr\") remotes::install_github(\"NorskRegnesentral/shapr\") remotes::install_github(\"NorskRegnesentral/shapr\", dependencies = TRUE)"},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"shapr supports computation Shapley values predictive model takes set numeric features produces numeric outcome. following example shows simple xgboost model trained using airquality dataset, shapr explains individual predictions. first enable parallel computation progress updates following code chunk. optional, recommended improved performance user-friendliness, particularly problems many features. actual example:  See Jullum et al.¬†(2025) (preprint available ) software paper overview methodology capabilities package (v1.0.4). See general usage vignette basic usage examples brief introductions methodology. thorough information underlying methodology, see methodological papers Aas, Jullum, L√∏land (2021), Redelmeier, Jullum, Aas (2020), Jullum, Redelmeier, Aas (2021), Olsen et al. (2022), Olsen et al. (2024). See also Sellereite Jullum (2019) brief paper previous version (v0.1.1) package (different structure, syntax, significantly less functionality).","code":"# Enable parallel computation # Requires the future and future_lapply packages future::plan(\"multisession\", workers = 2) # Increase the number of workers for increased performance with many features  # Enable progress updates of the v(S) computations # Requires the progressr package progressr::handlers(global = TRUE) progressr::handlers(\"cli\") # Using the cli package as backend (recommended for the estimates of the remaining time) library(xgboost) library(shapr)  data(\"airquality\") data <- data.table::as.data.table(airquality) data <- data[complete.cases(data), ]  x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\") y_var <- \"Ozone\"  ind_x_explain <- 1:6 x_train <- data[-ind_x_explain, ..x_var] y_train <- data[-ind_x_explain, get(y_var)] x_explain <- data[ind_x_explain, ..x_var]  # Look at the dependence between the features cor(x_train) #>            Solar.R       Wind       Temp      Month #> Solar.R  1.0000000 -0.1243826  0.3333554 -0.0710397 #> Wind    -0.1243826  1.0000000 -0.5152133 -0.2013740 #> Temp     0.3333554 -0.5152133  1.0000000  0.3400084 #> Month   -0.0710397 -0.2013740  0.3400084  1.0000000  # Fit a basic xgboost model to the training data model <- xgboost(   data = as.matrix(x_train),   label = y_train,   nround = 20,   verbose = FALSE )  # Specify phi_0, i.e., the expected prediction without any features p0 <- mean(y_train)  # Compute Shapley values with Kernel SHAP, accounting for feature dependence using # the empirical (conditional) distribution approach with bandwidth parameter sigma = 0.1 (default) explanation <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p0,   seed = 1 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-20 15:08:39 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contains `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than or `2^n_features = 16`, and #>   is therefore set to `2^n_features = 16`. #>  #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #>  #>  #> ‚Ä¢ Model class: <xgb.Booster> #>  #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #>  #> ‚Ä¢ Approach: empirical #>  #> ‚Ä¢ Procedure: Non-iterative #>  #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #>  #> ‚Ä¢ Number of feature-wise Shapley values: 4 #>  #> ‚Ä¢ Number of observations to explain: 6 #>  #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpnBYv2R/shapr_obj_2aa833a1e2267.rds' #>  #>  #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #>  #>  #> ‚Ñπ Using 16 of 16 coalitions.  # Print the Shapley values for the observations to explain. print(explanation) #>    explain_id  none Solar.R  Wind  Temp  Month #>         <int> <num>   <num> <num> <num>  <num> #> 1:          1  43.1  13.212  4.79 -25.6  -5.60 #> 2:          2  43.1  -9.973  5.83 -11.0  -7.83 #> 3:          3  43.1  -2.292 -7.05 -10.2  -4.45 #> 4:          4  43.1   3.325 -3.24 -10.2  -6.66 #> 5:          5  43.1   4.304 -2.63 -14.2 -12.27 #> 6:          6  43.1   0.479 -5.25 -12.6  -6.65  # Provide a formatted summary of the shapr object summary(explanation) #>  #> ‚îÄ‚îÄ Summary of Shapley value explanation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ä¢ Computed with`shapr::explain()` in 2.2 seconds, started 2025-08-20 #> 15:08:39 #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 6 #> ‚Ä¢ Number of coalitions used: 16 (of total 16) #> ‚Ä¢ Computations (temporary) saved at: #> '/tmp/RtmpnBYv2R/shapr_obj_2aa833a1e2267.rds' #>  #> ‚îÄ‚îÄ Estimated Shapley values  #>    explain_id   none Solar.R   Wind   Temp  Month #>         <int> <char>  <char> <char> <char> <char> #> 1:          1  43.09   13.21   4.79 -25.57  -5.60 #> 2:          2  43.09   -9.97   5.83 -11.04  -7.83 #> 3:          3  43.09   -2.29  -7.05 -10.15  -4.45 #> 4:          4  43.09    3.33  -3.24 -10.22  -6.66 #> 5:          5  43.09    4.30  -2.63 -14.15 -12.27 #> 6:          6  43.09    0.48  -5.25 -12.55  -6.65 #> ‚îÄ‚îÄ Estimated MSEv  #> Estimated MSE of v(S) = 144 (with sd = 64)  # Finally, we plot the resulting explanations plot(explanation)"},{"path":"https://norskregnesentral.github.io/shapr/index.html","id":"contribution","dir":"","previous_headings":"","what":"Contribution","title":"Prediction Explanation with Dependence-Aware Shapley Values","text":"feedback suggestions welcome. Details contribute can found . questions comments, feel free open issue . Please note shapr project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/reference/additional_regression_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Additional setup for regression-based methods ‚Äî additional_regression_setup","title":"Additional setup for regression-based methods ‚Äî additional_regression_setup","text":"Additional setup regression-based methods","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/additional_regression_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Additional setup for regression-based methods ‚Äî additional_regression_setup","text":"","code":"additional_regression_setup(internal, model, predict_model)"},{"path":"https://norskregnesentral.github.io/shapr/reference/additional_regression_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Additional setup for regression-based methods ‚Äî additional_regression_setup","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/additional_regression_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Additional setup for regression-based methods ‚Äî additional_regression_setup","text":"(updated) internal list","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"AICc formula for several sets, alternative definition ‚Äî aicc_full_cpp","title":"AICc formula for several sets, alternative definition ‚Äî aicc_full_cpp","text":"AICc formula several sets, alternative definition","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AICc formula for several sets, alternative definition ‚Äî aicc_full_cpp","text":"","code":"aicc_full_cpp(h, X_list, mcov_list, S_scale_dist, y_list, negative)"},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AICc formula for several sets, alternative definition ‚Äî aicc_full_cpp","text":"h numeric specifying scaling (sigma) X_list List. Contains matrices appropriate features training data mcov_list List. Contains covariance matrices matrices X_list S_scale_dist Logical. Indicates whether Mahalanobis distance scaled number variables. y_list List. Contains appropriate (temporary) response variables. negative Logical. Whether return negative AICc value.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AICc formula for several sets, alternative definition ‚Äî aicc_full_cpp","text":"Scalar numeric value AICc formula","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"AICc formula for several sets, alternative definition ‚Äî aicc_full_cpp","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_single_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Temp-function for computing the full AICc with several X's etc ‚Äî aicc_full_single_cpp","title":"Temp-function for computing the full AICc with several X's etc ‚Äî aicc_full_single_cpp","text":"Temp-function computing full AICc several X's etc","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_single_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temp-function for computing the full AICc with several X's etc ‚Äî aicc_full_single_cpp","text":"","code":"aicc_full_single_cpp(X, mcov, S_scale_dist, h, y)"},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_single_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temp-function for computing the full AICc with several X's etc ‚Äî aicc_full_single_cpp","text":"X matrix. mcov matrix covariance matrix X. S_scale_dist logical. Indicating whether Mahalanobis distance scaled number variables h numeric specifying scaling (sigma) y Vector Representing (temporary) response variable","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_single_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temp-function for computing the full AICc with several X's etc ‚Äî aicc_full_single_cpp","text":"Scalar numeric value AICc formula.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/aicc_full_single_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Temp-function for computing the full AICc with several X's etc ‚Äî aicc_full_single_cpp","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/append_vS_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Appends the new vS_list to the prev vS_list ‚Äî append_vS_list","title":"Appends the new vS_list to the prev vS_list ‚Äî append_vS_list","text":"Appends new vS_list prev vS_list","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/append_vS_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Appends the new vS_list to the prev vS_list ‚Äî append_vS_list","text":"","code":"append_vS_list(vS_list, internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/append_vS_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Appends the new vS_list to the prev vS_list ‚Äî append_vS_list","text":"vS_list List. Output compute_vS(). internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/append_vS_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Appends the new vS_list to the prev vS_list ‚Äî append_vS_list","text":"vS_list merged previously computed vS_lists (stored internal)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/categorical_to_one_hot_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a categorical_to_one_hot_layer ‚Äî categorical_to_one_hot_layer","title":"A torch::nn_module() Representing a categorical_to_one_hot_layer ‚Äî categorical_to_one_hot_layer","text":"categorical_to_one_hot_layer module/layer expands categorical features one-hot vectors, multi-layer perceptrons known work better data representation. also replaces NaNs zeros order layers may work correctly.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/categorical_to_one_hot_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a categorical_to_one_hot_layer ‚Äî categorical_to_one_hot_layer","text":"","code":"categorical_to_one_hot_layer(   one_hot_max_sizes,   add_nans_map_for_columns = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/categorical_to_one_hot_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a categorical_to_one_hot_layer ‚Äî categorical_to_one_hot_layer","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. add_nans_map_for_columns Optional list contains indices columns is_nan masks appended result tensor. option necessary full encoder distinguish whether value reconstructed .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/categorical_to_one_hot_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A torch::nn_module() Representing a categorical_to_one_hot_layer ‚Äî categorical_to_one_hot_layer","text":"Note module works mixed data represented 2-dimensional inputs works correctly missing values groundtruth long represented NaNs.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/categorical_to_one_hot_layer.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a categorical_to_one_hot_layer ‚Äî categorical_to_one_hot_layer","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_categorical_valid_MCsamp.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that all explicands has at least one valid MC sample in causal Shapley values ‚Äî check_categorical_valid_MCsamp","title":"Check that all explicands has at least one valid MC sample in causal Shapley values ‚Äî check_categorical_valid_MCsamp","text":"Check explicands least one valid MC sample causal Shapley values","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_categorical_valid_MCsamp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that all explicands has at least one valid MC sample in causal Shapley values ‚Äî check_categorical_valid_MCsamp","text":"","code":"check_categorical_valid_MCsamp(dt, n_explain, n_MC_samples, joint_prob_dt)"},{"path":"https://norskregnesentral.github.io/shapr/reference/check_categorical_valid_MCsamp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that all explicands has at least one valid MC sample in causal Shapley values ‚Äî check_categorical_valid_MCsamp","text":"dt Data.table containing generated MC samples (conditional values) sampling step n_MC_samples Positive integer. approaches, indicates maximum number samples use Monte Carlo integration every conditional expectation. approach=\"ctree\", n_MC_samples corresponds number samples leaf node (see exception related ctree.sample argument setup_approach.ctree()). approach=\"empirical\", n_MC_samples \\(K\\) parameter equations (14-15) Aas et al. (2021), .e. maximum number observations (largest weights) used, see also empirical.eta argument setup_approach.empirical().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_categorical_valid_MCsamp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check that all explicands has at least one valid MC sample in causal Shapley values ‚Äî check_categorical_valid_MCsamp","text":"undocumented arguments, see setup_approach.categorical().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_categorical_valid_MCsamp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check that all explicands has at least one valid MC sample in causal Shapley values ‚Äî check_categorical_valid_MCsamp","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_convergence.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks the convergence according to the convergence threshold ‚Äî check_convergence","title":"Checks the convergence according to the convergence threshold ‚Äî check_convergence","text":"Checks convergence according convergence threshold","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_convergence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks the convergence according to the convergence threshold ‚Äî check_convergence","text":"","code":"check_convergence(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/check_convergence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks the convergence according to the convergence threshold ‚Äî check_convergence","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_convergence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks the convergence according to the convergence threshold ‚Äî check_convergence","text":"(updated) internal list","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that the group parameter has the right form and content ‚Äî check_groups","title":"Check that the group parameter has the right form and content ‚Äî check_groups","text":"Check group parameter right form content","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that the group parameter has the right form and content ‚Äî check_groups","text":"","code":"check_groups(feature_names, group)"},{"path":"https://norskregnesentral.github.io/shapr/reference/check_verbose.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks the verbose parameter ‚Äî check_verbose","title":"Function that checks the verbose parameter ‚Äî check_verbose","text":"Function checks verbose parameter","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_verbose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks the verbose parameter ‚Äî check_verbose","text":"","code":"check_verbose(verbose)"},{"path":"https://norskregnesentral.github.io/shapr/reference/check_verbose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks the verbose parameter ‚Äî check_verbose","text":"verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\").","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_verbose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks the verbose parameter ‚Äî check_verbose","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/check_verbose.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks the verbose parameter ‚Äî check_verbose","text":"Lars Henry Berge Olsen, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_compute_vS.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing messages in compute_vS with cli ‚Äî cli_compute_vS","title":"Printing messages in compute_vS with cli ‚Äî cli_compute_vS","text":"Printing messages compute_vS cli","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_compute_vS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing messages in compute_vS with cli ‚Äî cli_compute_vS","text":"","code":"cli_compute_vS(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_compute_vS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing messages in compute_vS with cli ‚Äî cli_compute_vS","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_compute_vS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing messages in compute_vS with cli ‚Äî cli_compute_vS","text":"return value (prints compute_vS messages cli)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing messages in iterative procedure with cli ‚Äî cli_iter","title":"Printing messages in iterative procedure with cli ‚Äî cli_iter","text":"Printing messages iterative procedure cli","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing messages in iterative procedure with cli ‚Äî cli_iter","text":"","code":"cli_iter(verbose, internal, iter)"},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing messages in iterative procedure with cli ‚Äî cli_iter","text":"verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). internal List. used directly, passed explain(). iter Integer. iteration number. used internally.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_iter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing messages in iterative procedure with cli ‚Äî cli_iter","text":"return value (prints iterative messages cli)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_startup.html","id":null,"dir":"Reference","previous_headings":"","what":"Printing startup messages with cli ‚Äî cli_startup","title":"Printing startup messages with cli ‚Äî cli_startup","text":"Printing startup messages cli","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_startup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Printing startup messages with cli ‚Äî cli_startup","text":"","code":"cli_startup(internal, verbose)"},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_startup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Printing startup messages with cli ‚Äî cli_startup","text":"internal List. used directly, passed explain(). verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\").","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_startup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Printing startup messages with cli ‚Äî cli_startup","text":"return value (prints startup messages cli)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_topline.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a header topline with cli ‚Äî cli_topline","title":"Create a header topline with cli ‚Äî cli_topline","text":"Create header topline cli","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_topline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a header topline with cli ‚Äî cli_topline","text":"","code":"cli_topline(verbose, testing, init_time, type, is_python)"},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_topline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a header topline with cli ‚Äî cli_topline","text":"verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). testing Logical. used remove random components, like timing, output comparing testthat. Defaults FALSE. init_time POSIXct. time explain() function called, returned Sys.time(). Used calculate total time explain() call. type Character. Either \"regular\" \"forecast\", matching function call originated , thus type explanation generate. is_python Logical. Indicates whether function called Python wrapper. Default FALSE, never changed calling function via explain() R. parameter later used disallow running AICc versions empirical method, requires data-based optimization, supported shaprpy.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/cli_topline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a header topline with cli ‚Äî cli_topline","text":"return value (prints header cli unless verbose NULL)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/coalition_matrix_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get coalition matrix ‚Äî coalition_matrix_cpp","title":"Get coalition matrix ‚Äî coalition_matrix_cpp","text":"Get coalition matrix","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/coalition_matrix_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get coalition matrix ‚Äî coalition_matrix_cpp","text":"","code":"coalition_matrix_cpp(coalitions, m)"},{"path":"https://norskregnesentral.github.io/shapr/reference/coalition_matrix_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get coalition matrix ‚Äî coalition_matrix_cpp","text":"coalitions List. elements equals integer vector representing valid combination features/feature groups. m Integer. Number features/feature groups.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/coalition_matrix_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get coalition matrix ‚Äî coalition_matrix_cpp","text":"Matrix","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/coalition_matrix_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get coalition matrix ‚Äî coalition_matrix_cpp","text":"Nikolai Sellereite, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"Compute mean squared error (MSEv) contribution function v(S) proposed Frye et al. (2019) used Olsen et al. (2022).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"","code":"compute_MSEv_eval_crit(   internal,   dt_vS,   MSEv_uniform_comb_weights,   MSEv_skip_empty_full_comb = TRUE )"},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. dt_vS Data.table dimension n_coalitions times n_explain + 1 containing contribution function estimates. first column assumed named id_coalition containing ids coalitions. last row assumed full coalition, .e., contains predicted responses observations explained. MSEv_uniform_comb_weights Logical. TRUE (default), function weights coalitions uniformly computing MSEv criterion. FALSE, function use Shapley kernel weights weight coalitions computing MSEv criterion. Note Shapley kernel weights replaced sampling frequency coalitions considered. MSEv_skip_empty_full_comb Logical. TRUE (default), exclude empty grand coalitions computing MSEv evaluation criterion. reasonable identical methods, .e., contribution function independent method used (special cases affected approach). FALSE, include empty grand coalitions. case, recommend setting MSEv_uniform_comb_weights = TRUE; otherwise large weights empty grand coalitions outweigh others make MSEv criterion uninformative.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"List containing: MSEv data.table overall MSEv evaluation criterion averaged coalitions observations/explicands. data.table also contains standard deviation MSEv values explicand (averaged coalitions) divided square root number explicands. MSEv_explicand data.table mean squared error explicand, .e., averaged coalitions. MSEv_coalition data.table mean squared error coalition, .e., averaged explicands/observations. data.table also contains standard deviation MSEv values coalition divided square root number explicands.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"MSEv evaluation criterion rely access true contribution functions true Shapley values. lower value indicates better approximations; however, scale magnitude MSEv directly interpretable regarding precision final estimated Shapley values. Olsen et al. (2024) illustrates (Figure 11) fairly strong linear relationship MSEv MAE estimated true Shapley values simulation study. Note: explicands observations whose predictions explain.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"Frye, C., de Mijolla, D., Begley, T., Cowton, L., Stanley, M., & Feige, . (2021). Shapley explainability data manifold. International Conference Learning Representations. Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51 Olsen, L. H. B., Glad, . K., Jullum, M., & Aas, K. (2024). comparative study methods estimating model-agnostic Shapley value explanations. Data Mining Knowledge Discovery, 1-48","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_MSEv_eval_crit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mean squared error of the contribution function v(S) ‚Äî compute_MSEv_eval_crit","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Shapley values and their standard deviation given v(S) ‚Äî compute_estimates","title":"Compute the Shapley values and their standard deviation given v(S) ‚Äî compute_estimates","text":"Compute Shapley values standard deviation given v(S)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Shapley values and their standard deviation given v(S) ‚Äî compute_estimates","text":"","code":"compute_estimates(internal, vS_list)"},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Shapley values and their standard deviation given v(S) ‚Äî compute_estimates","text":"internal List. used directly, passed explain(). vS_list List. Output compute_vS().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Shapley values and their standard deviation given v(S) ‚Äî compute_estimates","text":"(updated) internal list","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_shapley.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Shapley values ‚Äî compute_shapley","title":"Compute Shapley values ‚Äî compute_shapley","text":"Compute Shapley values","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_shapley.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Shapley values ‚Äî compute_shapley","text":"","code":"compute_shapley(internal, dt_vS)"},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_shapley.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Shapley values ‚Äî compute_shapley","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. dt_vS contribution matrix.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_shapley.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Shapley values ‚Äî compute_shapley","text":"data.table Shapley values test observation.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather and compute the timing of the different parts of the explain function. ‚Äî compute_time","title":"Gather and compute the timing of the different parts of the explain function. ‚Äî compute_time","text":"Gather compute timing different parts explain function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather and compute the timing of the different parts of the explain function. ‚Äî compute_time","text":"","code":"compute_time(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather and compute the timing of the different parts of the explain function. ‚Äî compute_time","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather and compute the timing of the different parts of the explain function. ‚Äî compute_time","text":"list reformatted timing information.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_vS.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes v(S) for all feature subsets S. ‚Äî compute_vS","title":"Computes v(S) for all feature subsets S. ‚Äî compute_vS","text":"Computes v(S) feature subsets S.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_vS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes v(S) for all feature subsets S. ‚Äî compute_vS","text":"","code":"compute_vS(internal, model, predict_model)"},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_vS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes v(S) for all feature subsets S. ‚Äî compute_vS","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/compute_vS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes v(S) for all feature subsets S. ‚Äî compute_vS","text":"List v(S) different coalitions S, optionally including samples used estimate v(S).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/convert_feature_name_to_idx.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert feature names into feature indices ‚Äî convert_feature_name_to_idx","title":"Convert feature names into feature indices ‚Äî convert_feature_name_to_idx","text":"Functions takes causal_ordering specified using strings convert strings feature indices.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/convert_feature_name_to_idx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert feature names into feature indices ‚Äî convert_feature_name_to_idx","text":"","code":"convert_feature_name_to_idx(causal_ordering, labels, feat_group_txt)"},{"path":"https://norskregnesentral.github.io/shapr/reference/convert_feature_name_to_idx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert feature names into feature indices ‚Äî convert_feature_name_to_idx","text":"causal_ordering List. applicable (regular) non-causal asymmetric explanations. causal_ordering unnamed list vectors specifying components partial causal ordering coalitions must respect. vector represents component contains one features/groups identified names (strings) indices (integers). causal_ordering NULL (default), causal ordering assumed possible coalitions allowed. causal ordering equivalent causal ordering single component includes features (list(1:n_features)) groups (list(1:n_groups)) feature-wise group-wise Shapley values, respectively. feature-wise Shapley values causal_ordering = list(c(1, 2), c(3, 4)), interpretation features 1 2 ancestors features 3 4, features 3 4 level. Note: features/groups must included causal_ordering without duplicates. labels Vector strings containing (order ) feature names. feat_group_txt String either \"feature\" \"group\" based shapr computing feature- group-wise Shapley values","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/convert_feature_name_to_idx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert feature names into feature indices ‚Äî convert_feature_name_to_idx","text":"causal_ordering list, feature indices (w.r.t. labels) instead feature names.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/convert_feature_name_to_idx.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert feature names into feature indices ‚Äî convert_feature_name_to_idx","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/correction_matrix_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Correction term with trace_input in AICc formula ‚Äî correction_matrix_cpp","title":"Correction term with trace_input in AICc formula ‚Äî correction_matrix_cpp","text":"Correction term trace_input AICc formula","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/correction_matrix_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correction term with trace_input in AICc formula ‚Äî correction_matrix_cpp","text":"","code":"correction_matrix_cpp(tr_H, n)"},{"path":"https://norskregnesentral.github.io/shapr/reference/correction_matrix_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correction term with trace_input in AICc formula ‚Äî correction_matrix_cpp","text":"tr_H numeric trace H n numeric number rows H","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/correction_matrix_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correction term with trace_input in AICc formula ‚Äî correction_matrix_cpp","text":"Scalar","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/correction_matrix_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Correction term with trace_input in AICc formula ‚Äî correction_matrix_cpp","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_coalition_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Define coalitions, and fetch additional information about each unique coalition ‚Äî create_coalition_table","title":"Define coalitions, and fetch additional information about each unique coalition ‚Äî create_coalition_table","text":"Define coalitions, fetch additional information unique coalition","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_coalition_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define coalitions, and fetch additional information about each unique coalition ‚Äî create_coalition_table","text":"","code":"create_coalition_table(   m,   exact = TRUE,   n_coalitions = 200,   n_coal_each_size = choose(m, seq(m - 1)),   weight_zero_m = 10^6,   paired_shap_sampling = TRUE,   prev_X = NULL,   n_samps_scale = 10,   coal_feature_list = as.list(seq_len(m)),   approach0 = \"gaussian\",   kernelSHAP_reweighting = \"none\",   semi_deterministic_sampling = FALSE,   dt_coal_samp_info = NULL,   dt_valid_causal_coalitions = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/create_coalition_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define coalitions, and fetch additional information about each unique coalition ‚Äî create_coalition_table","text":"m Positive integer. Total number features/groups. exact Logical. TRUE 2^m coalitions generated, otherwise subsample coalitions used. n_coalitions Positive integer. Note exact = TRUE, n_coalitions ignored. n_coal_each_size Vector integers length m-1. number valid coalitions coalition size 1, 2,..., m-1. symmetric Shapley values, choose(m, seq(m-1)) (default). asymmetric Shapley values, number valid coalitions size causal ordering. Used correctly normalize Shapley weights. weight_zero_m Numeric. value use replacement infinite coalition weights numerical operations. paired_shap_sampling Logical. Whether paired sampling coalitions. prev_X data.table. X data.table previous iteration. n_samps_scale Positive integer. Integer scales number coalitions n_coalitions sample sampling cheap, checking n_coalitions unique coalitions expensive, thus sample number coalitions factor n_samps_scale determine n_coalitions unique coalitions use coalitions point throw away remaining coalitions. coal_feature_list List. list mapping coalition features contains. approach0 Character vector. Contains approach used estimation coalition size. approach explain(). kernelSHAP_reweighting String. reweight sampling frequency weights kernelSHAP solution sampling. aim reduce randomness thereby variance Shapley value estimates. options one 'none', 'on_N', 'on_all', 'on_all_cond' (default). 'none' means reweighting, .e. sampling frequency weights used . 'on_N' means sampling frequencies averaged coalitions original sampling probabilities. 'on_all' means original sampling probabilities used coalitions. 'on_all_cond' means original sampling probabilities used coalitions, adjusting probability sampled least . 'on_all_cond' preferred performs best simulation studies, see Olsen & Jullum (2024). semi_deterministic_sampling Logical. FALSE (default), sample coalitions. TRUE, sampling coalitions semi-deterministic, .e. sampling done way ensures coalitions expected sampled based number coalitions deterministically included sample among fewer coalitions. done reduce variance Shapley value estimates, corresponds PySHAP* strategy paper Olsen & Jullum (2024). dt_coal_samp_info data.table. data.table contains information coalitions deterministically included can sampled, addition sampling probabilities available coalition size, weight given sampled deterministically included coalitions (excluding empty grand coalitions given weight_zero_m weight). dt_valid_causal_coalitions data.table. applicable asymmetric Shapley value explanations, NULL symmetric Shapley values. data.table contains information coalitions respects causal ordering.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_coalition_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define coalitions, and fetch additional information about each unique coalition ‚Äî create_coalition_table","text":"data.table info coalitions use","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_coalition_table.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Define coalitions, and fetch additional information about each unique coalition ‚Äî create_coalition_table","text":"Nikolai Sellereite, Martin Jullum, Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_ctree.html","id":null,"dir":"Reference","previous_headings":"","what":"Build all the conditional inference trees ‚Äî create_ctree","title":"Build all the conditional inference trees ‚Äî create_ctree","text":"Build conditional inference trees","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_ctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build all the conditional inference trees ‚Äî create_ctree","text":"","code":"create_ctree(   given_ind,   x_train,   mincriterion,   minsplit,   minbucket,   use_partykit = \"on_error\" )"},{"path":"https://norskregnesentral.github.io/shapr/reference/create_ctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build all the conditional inference trees ‚Äî create_ctree","text":"given_ind Integer vector. Indicates features conditioned . x_train Data.table training data. use_partykit String. semi-rare cases party::ctree() runs error related LINPACK used R. get around problem, one may fall back using newer (slower) partykit::ctree() function, reimplementation method. Setting parameter \"on_error\" (default) falls back  partykit::ctree(), party::ctree() fails. options \"never\", always uses party::ctree(), \"always\", always uses partykit::ctree(). warning message created whenever partykit::ctree() used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_ctree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build all the conditional inference trees ‚Äî create_ctree","text":"List conditional inference tree variables conditioned/conditioned .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_ctree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build all the conditional inference trees ‚Äî create_ctree","text":"See documentation setup_approach.ctree() function undocumented parameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_ctree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Build all the conditional inference trees ‚Äî create_ctree","text":"Annabelle Redelmeier, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","title":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","text":"function used generate marginal data categorical approach several sampling steps. need treat separately, marginal step make feature values combination feature values condition S categorical.joint_prob_dt. , progress chain sampling steps. E.g., X1 (1,2,3), X2 (1,2,3), X3 (1,2,3). know X2 = 2, let causal structure X1 -> X2 -> X3. Assume P(X1 = 1, X2 = 2, X = 3) = P(X1 = 2, X2 = 2, X = 3) = 1/2. point generating X1 = 3, generate X3. solution generate values can proceed whole chain sampling steps. , ensure marginal sampling respects valid feature coalitions sets conditional features, .e., features features_steps_cond_on. sample valid coalitions using MARGINAL probabilities.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","text":"","code":"create_marginal_data_cat(   n_MC_samples,   x_explain,   Sbar_features,   S_original,   joint_prob_dt )"},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","text":"n_MC_samples Positive integer. approaches, indicates maximum number samples use Monte Carlo integration every conditional expectation. approach=\"ctree\", n_MC_samples corresponds number samples leaf node (see exception related ctree.sample argument setup_approach.ctree()). approach=\"empirical\", n_MC_samples \\(K\\) parameter equations (14-15) Aas et al. (2021), .e. maximum number observations (largest weights) used, see also empirical.eta argument setup_approach.empirical(). x_explain Matrix data.frame/data.table. Features predictions explained. Sbar_features Vector integers containing features indices generate marginal observations . , Sbar_features c(1,4), sample n_MC_samples observations \\(P(X_1, X_4)\\). , sample first fourth feature values valid feature coalition using marginal probability, break dependence . S_original Vector integers containing features indices original coalition S. .e., features current sampling step, features known us starting chain sampling steps.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","text":"Data table dimension \\((`n_MC_samples` * `nrow(x_explain)`) \\times `length(Sbar_features)`\\) sampled observations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_cat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","text":"undocumented arguments, see setup_approach.categorical().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_cat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create marginal categorical data for causal Shapley values ‚Äî create_marginal_data_cat","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_gaussian.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate marginal Gaussian data using Cholesky decomposition ‚Äî create_marginal_data_gaussian","title":"Generate marginal Gaussian data using Cholesky decomposition ‚Äî create_marginal_data_gaussian","text":"Given multivariate Gaussian distribution, function creates data specified marginals said distribution.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_gaussian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate marginal Gaussian data using Cholesky decomposition ‚Äî create_marginal_data_gaussian","text":"","code":"create_marginal_data_gaussian(n_MC_samples, Sbar_features, mu, cov_mat)"},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_gaussian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate marginal Gaussian data using Cholesky decomposition ‚Äî create_marginal_data_gaussian","text":"n_MC_samples Integer. number samples generate. Sbar_features Vector integers indicating marginals sample . mu Numeric vector containing expected values features multivariate Gaussian distribution. cov_mat Numeric matrix containing covariance features multivariate Gaussian distribution.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_gaussian.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate marginal Gaussian data using Cholesky decomposition ‚Äî create_marginal_data_gaussian","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_training.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that samples data from the empirical marginal training distribution ‚Äî create_marginal_data_training","title":"Function that samples data from the empirical marginal training distribution ‚Äî create_marginal_data_training","text":"Sample observations empirical distribution P(X) using training dataset.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_training.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that samples data from the empirical marginal training distribution ‚Äî create_marginal_data_training","text":"","code":"create_marginal_data_training(   x_train,   n_explain,   Sbar_features,   n_MC_samples = 1000,   stable_version = TRUE )"},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_training.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that samples data from the empirical marginal training distribution ‚Äî create_marginal_data_training","text":"x_train Data.table training data. Sbar_features Vector integers containing features indices generate marginal observations . , Sbar_features c(1,4), sample n_MC_samples observations \\(P(X_1, X_4)\\) using empirical training observations (replacements). , sample first fourth feature values training observation, break dependence . stable_version Logical. TRUE n_MC_samples > n_train, include training observation n_MC_samples %/% n_train times sample remaining n_MC_samples %% n_train samples. latter done n_MC_samples < n_train. done separately explicand. FALSE, randomly sample observations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_training.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that samples data from the empirical marginal training distribution ‚Äî create_marginal_data_training","text":"Data table dimension n_MC_samples \\(\\times\\) length(Sbar_features) sampled observations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/create_marginal_data_training.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that samples data from the empirical marginal training distribution ‚Äî create_marginal_data_training","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_export.html","id":null,"dir":"Reference","previous_headings":"","what":"Exported documentation helper function. ‚Äî default_doc_export","title":"Exported documentation helper function. ‚Äî default_doc_export","text":"Exported documentation helper function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_export.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exported documentation helper function. ‚Äî default_doc_export","text":"","code":"default_doc_export(internal, iter, index_features, digits)"},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_export.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exported documentation helper function. ‚Äî default_doc_export","text":"internal List. used directly, passed explain(). iter Integer. iteration number. used internally. index_features Positive integer vector. Specifies id_coalition apply present method. NULL means coalitions. used internally. digits Integer. (Maximum) number digits displayed decimal point. Defaults 2.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Unexported documentation helper function. ‚Äî default_doc_internal","title":"Unexported documentation helper function. ‚Äî default_doc_internal","text":"Unexported documentation helper function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unexported documentation helper function. ‚Äî default_doc_internal","text":"","code":"default_doc_internal(   internal,   model,   predict_model,   x_explain,   x_train,   n_features,   W_kernel,   S,   dt_vS,   model_class,   output_size,   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_internal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unexported documentation helper function. ‚Äî default_doc_internal","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. model Objects. model object explained. See documentation explain() details. predict_model Function. prediction function used model natively supported. See documentation explain() details. x_explain Data.table features observation whose predictions explained (test data). x_train Data.table training data. n_features Positive integer. number features. W_kernel Numeric matrix. Contains non-scaled weights training test observations coalitions. dimension equals n_train x m. S Integer matrix dimension n_coalitions x m, n_coalitions m equals total number sampled/non-sampled coalitions total number unique features, respectively. Note m = ncol(x_train). dt_vS Data.table dimension n_coalitions times n_explain + 1 containing contribution function estimates. first column assumed named id_coalition containing ids coalitions. last row assumed full coalition, .e., contains predicted responses observations explained. model_class Character string. class model object, e.g., \"lm\", \"glm\", \"xgboost\", etc. obtained class(model)[1]. output_size Scalar integer. Specifies dimension output prediction model every observation. ... arguments passed approach-specific functions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/default_doc_internal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unexported documentation helper function. ‚Äî default_doc_internal","text":"internal list. holds parameters, data, computed objects used within explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/exact_coalition_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get table with all (exact) coalitions ‚Äî exact_coalition_table","title":"Get table with all (exact) coalitions ‚Äî exact_coalition_table","text":"Get table (exact) coalitions","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/exact_coalition_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get table with all (exact) coalitions ‚Äî exact_coalition_table","text":"","code":"exact_coalition_table(   m,   max_fixed_coal_size = ceiling((m - 1)/2),   dt_valid_causal_coalitions = NULL,   weight_zero_m = 10^6 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/exact_coalition_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get table with all (exact) coalitions ‚Äî exact_coalition_table","text":"m Positive integer. Total number features/groups. dt_valid_causal_coalitions data.table. applicable asymmetric Shapley value explanations, NULL symmetric Shapley values. data.table contains information coalitions respects causal ordering. weight_zero_m Numeric. value use replacement infinite coalition weights numerical operations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":null,"dir":"Reference","previous_headings":"","what":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"Compute dependence-aware Shapley values observations x_explain specified model using method specified approach estimate conditional expectation. See Aas et al. (2021) thorough introduction dependence-aware prediction explanation Shapley values. overview methodology capabilities package, see software paper Jullum et al. (2025), pkgdown site norskregnesentral.github.io/shapr/.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"","code":"explain(   model,   x_explain,   x_train,   approach,   phi0,   iterative = NULL,   max_n_coalitions = NULL,   group = NULL,   n_MC_samples = 1000,   seed = NULL,   verbose = \"basic\",   predict_model = NULL,   get_model_specs = NULL,   prev_shapr_object = NULL,   asymmetric = FALSE,   causal_ordering = NULL,   confounding = NULL,   extra_computation_args = list(),   iterative_args = list(),   output_args = list(),   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"model Model object. model whose predictions want explain. Run get_supported_models() table models explain supports natively. Unsupported models can still explained passing predict_model (optionally) get_model_specs, see details information. x_explain Matrix data.frame/data.table. Features predictions explained. x_train Matrix data.frame/data.table. Data used estimate (conditional) feature distributions needed properly estimate conditional expectations Shapley formula. approach Character vector length 1 one less number features. elements either \"gaussian\", \"copula\", \"empirical\", \"ctree\", \"vaeac\", \"categorical\", \"timeseries\", \"independence\", \"regression_separate\", \"regression_surrogate\". two regression approaches combined approach. See details information. phi0 Numeric. prediction value unseen data, .e., estimate expected prediction without conditioning features. Typically set equal mean response training data, alternatives mean training predictions also reasonable. iterative Logical NULL. NULL (default), set TRUE 5 features/groups, FALSE otherwise. TRUE, Shapley values estimated iteratively faster, sufficiently accurate results. First initial number coalitions sampled, bootstrapping estimates variance Shapley values. convergence criterion determines variances sufficiently small. , additional samples added. process repeats variances threshold. Specifics iterative process convergence criterion set via iterative_args. max_n_coalitions Integer. Upper limit number unique feature/group coalitions use iterative procedure (iterative = TRUE). iterative = FALSE, represents number feature/group coalitions use directly. quantity refers number unique feature coalitions group = NULL, group coalitions group != NULL. max_n_coalitions = NULL corresponds 2^n_features. group List. NULL, regular feature-wise Shapley values computed. provided, group-wise Shapley values computed. group length equal number groups. list element contains character vectors features included corresponding group. See Jullum et al. (2021) information group-wise Shapley values. n_MC_samples Positive integer. approaches, indicates maximum number samples use Monte Carlo integration every conditional expectation. approach=\"ctree\", n_MC_samples corresponds number samples leaf node (see exception related ctree.sample argument setup_approach.ctree()). approach=\"empirical\", n_MC_samples \\(K\\) parameter equations (14-15) Aas et al. (2021), .e. maximum number observations (largest weights) used, see also empirical.eta argument setup_approach.empirical(). seed Positive integer. Specifies seed code involving randomness run. NULL (default), seed set calling environment. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). predict_model Function. Prediction function use model natively supported. (Run get_supported_models() list natively supported models.) function must two arguments, model newdata, specify model data.frame/data.table compute predictions , respectively. function must give prediction numeric vector. NULL (default) uses functions specified internally. Can also used override default function natively supported model classes. get_model_specs Function. optional function checking model/data consistency model natively supported. (Run get_supported_models() list natively supported models.) function takes model argument provides list 3 elements: labels Character vector names feature. classes Character vector class feature. factor_levels Character vector levels categorical features. NULL (default), internal functions used natively supported model classes, checking disabled unsupported model classes. Can also used override default function natively supported model classes. prev_shapr_object shapr object string. object class shapr provided, string path intermediate results stored, function use previous object continue computation. useful computation interrupted want higher accuracy already obtained, therefore want continue iterative estimation. See general usage vignette examples. asymmetric Logical. applicable (regular) non-causal explanations. FALSE (default), explain computes regular symmetric Shapley values. TRUE, explain computes asymmetric Shapley values based (partial) causal ordering given causal_ordering. , explain uses feature coalitions respect causal ordering. asymmetric TRUE confounding NULL (default), explain computes asymmetric conditional Shapley values specified  Frye et al. (2020). confounding provided, .e., NULL, explain computes asymmetric causal Shapley values specified  Heskes et al. (2020). causal_ordering List. applicable (regular) non-causal asymmetric explanations. causal_ordering unnamed list vectors specifying components partial causal ordering coalitions must respect. vector represents component contains one features/groups identified names (strings) indices (integers). causal_ordering NULL (default), causal ordering assumed possible coalitions allowed. causal ordering equivalent causal ordering single component includes features (list(1:n_features)) groups (list(1:n_groups)) feature-wise group-wise Shapley values, respectively. feature-wise Shapley values causal_ordering = list(c(1, 2), c(3, 4)), interpretation features 1 2 ancestors features 3 4, features 3 4 level. Note: features/groups must included causal_ordering without duplicates. confounding Logical vector. applicable (regular) non-causal asymmetric explanations. confounding logical vector specifying whether confounding assumed component causal_ordering. NULL (default), assumption confounding structure made explain computes asymmetric/symmetric conditional Shapley values, depending asymmetric. confounding single logical (FALSE TRUE), assumption set globally components causal ordering. Otherwise, confounding must length causal_ordering, indicating confounding assumption component. confounding specified, explain computes asymmetric/symmetric causal Shapley values, depending asymmetric. approach regression_separate regression_surrogate, regression-based approaches applicable causal Shapley methodology. extra_computation_args Named list. Specifies extra arguments related computation Shapley values. See get_extra_comp_args_default() description arguments default values. iterative_args Named list. Specifies arguments iterative procedure. See get_iterative_args_default() description arguments default values. output_args Named list. Specifies certain arguments related output function. See get_output_args_default() description arguments default values. ... Arguments passed setup_approach.categorical, setup_approach.copula, setup_approach.ctree, setup_approach.empirical, setup_approach.gaussian, setup_approach.independence, setup_approach.regression_separate, setup_approach.regression_surrogate, setup_approach.timeseries, setup_approach.vaeac categorical.joint_prob_dt Data.table. (Optional) Containing joint probability distribution combination feature values. NULL means estimated x_train x_explain. categorical.epsilon Numeric value. (Optional) categorical.joint_prob_dt supplied, probabilities/frequencies estimated using x_train. certain observations occur x_explain x_train, epsilon used proportion times observations occur training data. theory, proportion zero, causes error later Shapley computation. internal List. used directly, passed explain(). ctree.mincriterion Numeric scalar vector. Either scalar vector length equal number features model. value equal 1 - \\(\\alpha\\) \\(\\alpha\\) nominal level conditional independence tests. vector, indicates value use conditioning various numbers features. default value 0.95. ctree.minsplit Numeric scalar. Determines minimum value sum left right daughter nodes must reach split. default value 20. ctree.minbucket Numeric scalar. Determines minimum sum weights terminal node required split. default value 7. ctree.sample Boolean. TRUE (default), method always samples n_MC_samples observations leaf nodes (replacement). FALSE number observations leaf node less n_MC_samples, method take observations leaf. FALSE number observations leaf node n_MC_samples, method sample n_MC_samples observations (replacement). means always sampling leaf unless sample = FALSE number obs node less n_MC_samples. empirical.type Character. (default = \"fixed_sigma\") Must one \"independence\", \"fixed_sigma\", \"AICc_each_k\", \"AICc_full\". Note: \"empirical.type = independence\" deprecated; use approach = \"independence\" instead. \"fixed_sigma\" uses fixed bandwidth (set empirical.fixed_sigma) kernel density estimation. \"AICc_each_k\" \"AICc_full\" optimize bandwidth using AICc criterion, respectively one bandwidth per coalition size one bandwidth coalition sizes. empirical.eta Numeric scalar. Needs 0 < eta <= 1. default value 0.95. Represents minimum proportion total empirical weight data samples use. example, eta = .8, choose K samples largest weights sum weights accounts 80\\ eta \\(\\eta\\) parameter equation (15) Aas et al. (2021). empirical.fixed_sigma Positive numeric scalar. default value 0.1. Represents kernel bandwidth distance computation used conditioning different coalitions. used empirical.type = \"fixed_sigma\" empirical.n_samples_aicc Positive integer. Number samples consider AICc optimization. default value 1000. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.eval_max_aicc Positive integer. Maximum number iterations optimizing AICc. default value 20. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.start_aicc Numeric. Start value sigma parameter optimizing AICc. default value 0.1. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.cov_mat Numeric matrix. (Optional) covariance matrix data generating distribution used define Mahalanobis distance. NULL means estimated x_train. gaussian.mu Numeric vector. (Optional) Containing mean data generating distribution. NULL means estimated x_train. gaussian.cov_mat Numeric matrix. (Optional) Containing covariance matrix data generating distribution. NULL means estimated x_train. regression.model tidymodels object class model_specs. Default linear regression model, .e., parsnip::linear_reg(). See tidymodels possible models, see vignette add new/models. Note, make easier call explain() Python, regression.model parameter can also string specifying model parsed evaluated. example, \"parsnip::rand_forest(mtry = hardhat::tune(), trees = 100, engine = \"ranger\", mode = \"regression\")\" also valid input. essential include package prefix package loaded. regression.tune_values Either NULL (default), data.frame/data.table/tibble, function. data.frame must contain possible hyperparameter value combinations try. column names must match names tunable parameters specified regression.model. regression.tune_values function, take one argument x training data current coalition returns data.frame/data.table/tibble properties described . Using function allows hyperparameter values change based size coalition See regression vignette several examples. Note, make easier call explain() Python, regression.tune_values can also string containing R function. example, \"function(x) return(dials::grid_regular(dials::mtry(c(1, ncol(x)))), levels = 3))\" also valid input. essential include package prefix package loaded. regression.vfold_cv_para Either NULL (default) named list containing parameters sent rsample::vfold_cv(). See regression vignette several examples. regression.recipe_func Either NULL (default) function takes recipes::recipe() object returns modified recipes::recipe() potentially additional recipe steps. See regression vignette several examples. Note, make easier call explain() Python, regression.recipe_func can also string containing R function. example, \"function(recipe) return(recipes::step_ns(recipe, recipes::all_numeric_predictors(), deg_free = 2))\" also valid input. essential include package prefix package loaded. regression.surrogate_n_comb Positive integer. Specifies number unique coalitions apply training observation. default number sampled coalitions present iteration. integer 1 default allowed. Larger values requires memory, may improve surrogate model. user sets value lower maximum, sample amount unique coalitions separately training observations. , average, coalitions equally trained. timeseries.fixed_sigma Positive numeric scalar. Represents kernel bandwidth distance computation. default value 2. timeseries.bounds Numeric vector length two. Specifies lower upper bounds timeseries. default c(NULL, NULL), .e. bounds. one bounds NULL, restrict sampled time series bounds. useful underlying time series scaled 0 1, example. vaeac.depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. vaeac.width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. vaeac.latent_dim Positive integer (default 8). number dimensions latent space. vaeac.lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. vaeac.activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu() (default), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid(). vaeac.n_vaeacs_initialize Positive integer (default 4). number different vaeac models initiate start. Pick best performing one vaeac.extra_parameters$epochs_initiation_phase epochs (default 2) continue training one. vaeac.epochs Positive integer (default 100). number epochs train final vaeac model. includes vaeac.extra_parameters$epochs_initiation_phase, default 2. vaeac.extra_parameters Named list extra parameters vaeac approach. See vaeac_get_extra_para_default() description possible additional parameters default values.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"Object class c(\"shapr\", \"list\"). Contains following items: shapley_values_est data.table estimated Shapley values explained observation rows features along columns. column none prediction devoted features (given argument phi0) shapley_values_sd data.table standard deviation Shapley values reflecting uncertainty coalition sampling part kernelSHAP procedure. , definition, 0 coalitions used. present extra_computation_args$compute_sd=TRUE, default iterative = TRUE. internal List different parameters, data, functions output used internally. pred_explain Numeric vector predictions explained observations. MSEv List values MSEv evaluation criterion approach. See MSEv evaluation section general usage vignette details. timing List containing timing information different parts computation. summary contains time stamps start end time addition total execution time. overall_timing_secs gives time spent different parts explanation computation. main_computation_timing_secs decomposes main computation time different parts computation iteration iterative estimation routine, used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"shapr package implements kernelSHAP estimation dependence-aware Shapley values eight different Monte Carlo-based approaches estimating conditional distributions data. introduced general usage vignette. (R: vignette(\"general_usage\", package = \"shapr\")). overview methodology capabilities package, please also see software paper Jullum et al. (2025). Moreover, Aas et al. (2021) gives general introduction dependence-aware Shapley values approaches \"empirical\", \"gaussian\", \"copula\", also discusses \"independence\".  Redelmeier et al. (2020) introduces approach \"ctree\". Olsen et al. (2022) introduces \"vaeac\" approach. Approach \"timeseries\" discussed Jullum et al. (2021). shapr also implemented two regression-based approaches \"regression_separate\" \"regression_surrogate\", described Olsen et al. (2024). also possible combine different approaches, see  general usage vignette information. package also supports computation causal asymmetric Shapley values introduced  Heskes et al. (2020)  Frye et al. (2020). Asymmetric Shapley values proposed  Frye et al. (2020) way incorporate causal knowledge real world restricting possible feature combinations/coalitions computing Shapley values consistent (partial) causal ordering. Causal Shapley values proposed  Heskes et al. (2020) way explain total effect features prediction, taking account causal relationships, adapting sampling procedure shapr. package allows parallelized computation progress updates tightly connected future::future progressr::progressr packages. See examples . iterative estimation (iterative=TRUE), intermediate results may printed console (according verbose argument). Moreover, intermediate results written disk. combined batch computation v(S) values enables fast accurate estimation Shapley values memory-friendly manner.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"Jullum, M., Olsen, L. H. B., Lachmann, J., & Redelmeier, . (2025). shapr: Explaining Machine Learning Models Conditional Shapley Values R Python. arXiv preprint arXiv:2504.01842. Aas, K., Jullum, M., & L√∏land, . (2021). Explaining individual predictions features dependent: accurate approximations Shapley values. Artificial Intelligence, 298, 103502 Frye, C., Rowat, C., & Feige, . (2020). Asymmetric Shapley values: incorporating causal knowledge model-agnostic explainability. Advances neural information processing systems, 33, 1229-1239 Heskes, T., Sijben, E., Bucur, . G., & Claassen, T. (2020). Causal shapley values: Exploiting causal knowledge explain individual predictions complex models. Advances neural information processing systems, 33, 4778-4789 Jullum, M., Redelmeier, . & Aas, K. (2021). Efficient simple prediction explanations groupShapley: practical perspective. Italian Workshop Explainable Artificial Intelligence 2021. Redelmeier, ., Jullum, M., & Aas, K. (2020). Explaining predictive models mixed features using Shapley values conditional inference trees. Machine Learning Knowledge Extraction: International Cross-Domain Conference, CD-MAKE 2020, Dublin, Ireland, August 25-28, 2020, Proceedings 4 (pp. 117-137). Springer International Publishing. Sellereite N., & Jullum, M. (2019). shapr: R-package explaining machine learning models dependence-aware Shapley values. Journal Open Source Software, 5(46), 2027 Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51 Olsen, L. H. B., Glad, . K., Jullum, M., & Aas, K. (2024). comparative study methods estimating model-agnostic Shapley value explanations. Data Mining Knowledge Discovery, 1-48 Olsen, L. H. B., & Jullum, M. (2024). Improving Sampling Strategy KernelSHAP. arXiv e-prints, arXiv-2410","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"Martin Jullum, Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explain the output of machine learning models with dependence-aware (conditional/observational) Shapley values ‚Äî explain","text":"","code":"# \\donttest{  # Load example data data(\"airquality\") airquality <- airquality[complete.cases(airquality), ] x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\") y_var <- \"Ozone\"  # Split data into test and training data data_train <- head(airquality, -3) data_explain <- tail(airquality, 3)  x_train <- data_train[, x_var] x_explain <- data_explain[, x_var]  # Fit a linear model lm_formula <- as.formula(paste0(y_var, \" ~ \", paste0(x_var, collapse = \" + \"))) model <- lm(lm_formula, data = data_train)  # Explain predictions p <- mean(data_train[, y_var])  # (Optionally) enable parallelization via the future package if (requireNamespace(\"future\", quietly = TRUE)) {   future::plan(\"multisession\", workers = 2) }  # (Optionally) enable progress updates within every iteration via the progressr package if (requireNamespace(\"progressr\", quietly = TRUE)) {   progressr::handlers(global = TRUE) } #> Error in globalCallingHandlers(condition = global_progression_handler): should not be called with handlers on the stack  # Empirical approach explain1 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"empirical\",   phi0 = p,   n_MC_samples = 1e2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:07:46 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f12565baf5b.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   # Gaussian approach explain2 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p,   n_MC_samples = 1e2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:07:49 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f12728f219d.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   # Gaussian copula approach explain3 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"copula\",   phi0 = p,   n_MC_samples = 1e2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:07:50 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: copula #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f121cf372f4.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   if (requireNamespace(\"party\", quietly = TRUE)) {   # ctree approach   explain4 <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"ctree\",     phi0 = p,     n_MC_samples = 1e2   ) } #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:07:52 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f12113d245a.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   # Combined approach approach <- c(\"gaussian\", \"gaussian\", \"empirical\") explain5 <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = approach,   phi0 = p,   n_MC_samples = 1e2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:07:55 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian, gaussian, and empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f124cd373e3.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   ## Printing print(explain1) # The Shapley values #>    explain_id  none Solar.R   Wind   Temp Month #>         <int> <num>   <num>  <num>  <num> <num> #> 1:          1  42.8    6.12 -20.14  -5.03 -5.99 #> 2:          2  42.8   -1.47  11.53  -9.49 -5.60 #> 3:          3  42.8    3.52  -5.34 -16.60 -8.70 print(explain1) # The Shapley values #>    explain_id  none Solar.R   Wind   Temp Month #>         <int> <num>   <num>  <num>  <num> <num> #> 1:          1  42.8    6.12 -20.14  -5.03 -5.99 #> 2:          2  42.8   -1.47  11.53  -9.49 -5.60 #> 3:          3  42.8    3.52  -5.34 -16.60 -8.70  # The MSEv criterion (+sd). Smaller values indicate a better approach. print(explain1, what = \"MSEv\") #>     MSEv MSEv_sd #>    <num>   <num> #> 1:   233    81.6 print(explain2, what = \"MSEv\") #>     MSEv MSEv_sd #>    <num>   <num> #> 1:   276    99.7 print(explain3, what = \"MSEv\") #>     MSEv MSEv_sd #>    <num>   <num> #> 1:   224    78.9  ## Summary summary1 <- summary(explain1) #>  #> ‚îÄ‚îÄ Summary of Shapley value explanation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ä¢ Computed with`shapr::explain()` in 3.2 seconds, started 2025-08-25 14:07:46 #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Number of coalitions used: 16 (of total 16) #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f12565baf5b.rds #>  #> ‚îÄ‚îÄ Estimated Shapley values  #>    explain_id   none Solar.R   Wind   Temp  Month #>         <int> <char>  <char> <char> <char> <char> #> 1:          1  42.79    6.12 -20.14  -5.03  -5.99 #> 2:          2  42.79   -1.47  11.53  -9.49  -5.60 #> 3:          3  42.79    3.52  -5.34 -16.60  -8.70 #>  #> ‚îÄ‚îÄ Estimated MSEv  #> Estimated MSE of v(S) = 233 (with sd = 82)  # Various additional info stored in the summary object # Examples summary1$shapley_est # A data.table with the Shapley values #>    explain_id     none   Solar.R       Wind       Temp     Month #>         <int>    <num>     <num>      <num>      <num>     <num> #> 1:          1 42.78704  6.124296 -20.137653  -5.033967 -5.987303 #> 2:          2 42.78704 -1.470838  11.525868  -9.487924 -5.597657 #> 3:          3 42.78704  3.524599  -5.335059 -16.599988 -8.703929 summary1$timing$total_time_secs # Total computation time in seconds #> NULL summary1$parameters$n_MC_samples # Number of Monte Carlo samples used for the numerical integration #> [1] 100 summary1$parameters$empirical.type # Type of empirical approach used #> [1] \"fixed_sigma\"  # Plot the results if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   plot(explain1)   plot(explain1, plot_type = \"waterfall\") }   # Group-wise explanations group_list <- list(A = c(\"Temp\", \"Month\"), B = c(\"Wind\", \"Solar.R\"))  explain_groups <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   group = group_list,   approach = \"empirical\",   phi0 = p,   n_MC_samples = 1e2 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:07:58 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_groups = 4`, and is #>   therefore set to `2^n_groups = 4`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of group-wise Shapley values: 2 #> ‚Ä¢ Feature groups: A: {\"Temp\", \"Month\"}; B: {\"Wind\", \"Solar.R\"} #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f12689fef5b.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 4 of 4 coalitions.   print(explain_groups) #>    explain_id  none     A      B #>         <int> <num> <num>  <num> #> 1:          1  42.8 -11.6 -13.40 #> 2:          2  42.8 -10.4   5.34 #> 3:          3  42.8 -25.8  -1.32  # Separate and surrogate regression approaches with linear regression models. req_pkgs <- c(\"parsnip\", \"recipes\", \"workflows\", \"rsample\", \"tune\", \"yardstick\") if (requireNamespace(req_pkgs, quietly = TRUE)) {   explain_separate_lm <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     phi0 = p,     approach = \"regression_separate\",     regression.model = parsnip::linear_reg()   )    explain_surrogate_lm <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     phi0 = p,     approach = \"regression_surrogate\",     regression.model = parsnip::linear_reg()   ) } #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:00 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_separate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f124bdb046.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:03 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Regression #> ‚Ä¢ Approach: regression_surrogate #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f127a3c831.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   # Iterative estimation # For illustration only. By default not used for such small dimensions as here. # Restricting the initial and maximum number of coalitions as well.  explain_iterative <- explain(   model = model,   x_explain = x_explain,   x_train = x_train,   approach = \"gaussian\",   phi0 = p,   iterative = TRUE,   iterative_args = list(initial_n_coalitions = 8),   max_n_coalitions = 12 ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:05 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f1232ec2b48.rds #>  #> ‚îÄ‚îÄ Iterative computation started ‚îÄ‚îÄ #>  #> ‚îÄ‚îÄ Iteration 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 8 of 16 coalitions, 8 new.  #>  #> ‚îÄ‚îÄ Iteration 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 10 of 16 coalitions, 2 new.  #>  #> ‚îÄ‚îÄ Iteration 3 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Using 12 of 16 coalitions, 2 new.   # When not using all coalitions, we can also get the SD of the Shapley values, # reflecting uncertainty in the coalition sampling part of the procedure. print(explain_iterative, what = \"shapley_sd\") #>    explain_id  none Solar.R  Wind  Temp Month #>         <int> <num>   <num> <num> <num> <num> #> 1:          1     0   0.359  1.60  1.84 0.720 #> 2:          2     0   0.406  2.67  2.62 0.855 #> 3:          3     0   0.400  3.07  2.99 0.925  ## Summary # For iterative estimation, convergence info is also provided summary_iterative <- summary(explain_iterative) #>  #> ‚îÄ‚îÄ Summary of Shapley value explanation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ä¢ Computed with`shapr::explain()` in 7.6 seconds, started 2025-08-25 14:08:05 #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 3 #> ‚Ä¢ Number of coalitions used: 12 (of total 16) #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f1232ec2b48.rds #>  #> ‚îÄ‚îÄ Convergence info  #> ‚úî Iterative Shapley value estimation stopped at 12 coalitions after 3 iterations, due to: #> Maximum number of coalitions (12) reached! #>  #> ‚îÄ‚îÄ Estimated Shapley values (sd in parentheses)  #>    explain_id      none      Solar.R          Wind          Temp        Month #>         <int>    <char>       <char>        <char>        <char>       <char> #> 1:          1 42.79 (0)  1.67 (0.36) -19.09 (1.60)  -7.02 (1.84) -0.60 (0.72) #> 2:          2 42.79 (0) -3.65 (0.41)   8.98 (2.67)  -9.46 (2.62) -0.90 (0.85) #> 3:          3 42.79 (0)  5.00 (0.40)  -4.65 (3.07) -25.88 (2.99) -1.58 (0.93) #>  #> ‚îÄ‚îÄ Estimated MSEv  #> Estimated MSE of v(S) = 248 (with sd = 100) # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"Computes dependence-aware Shapley values observations explain_idx specified model using method specified approach estimate conditional expectation. See Aas, et. al (2021) thorough introduction dependence-aware prediction explanation Shapley values. overview methodology capabilities shapr package, see software paper Jullum et al. (2025), pkgdown site norskregnesentral.github.io/shapr/.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"","code":"explain_forecast(   model,   y,   xreg = NULL,   train_idx = NULL,   explain_idx,   explain_y_lags,   explain_xreg_lags = explain_y_lags,   horizon,   approach,   phi0,   max_n_coalitions = NULL,   iterative = NULL,   group_lags = TRUE,   group = NULL,   n_MC_samples = 1000,   seed = NULL,   predict_model = NULL,   get_model_specs = NULL,   verbose = \"basic\",   extra_computation_args = list(),   iterative_args = list(),   output_args = list(),   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"model Model object. model whose predictions want explain. Run get_supported_models() table models explain supports natively. Unsupported models can still explained passing predict_model (optionally) get_model_specs, see details information. y Matrix, data.frame/data.table numeric vector. Contains endogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. xreg Matrix, data.frame/data.table numeric vector. Contains exogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. exogenous variables used contemporaneously producing forecast, item contain nrow(y) + horizon rows. train_idx Numeric vector. row indices data reg denoting points time use estimating conditional expectations Shapley value formula. train_idx = NULL (default) indices selected explained used. explain_idx Numeric vector. row indices data reg denoting points time explain. explain_y_lags Numeric vector. Denotes number lags used variable y making forecast. explain_xreg_lags Numeric vector. xreg != NULL, denotes number lags used variable xreg making forecast. horizon Numeric. forecast horizon explain. Passed predict_model function. approach Character vector length 1 one less number features. elements either \"gaussian\", \"copula\", \"empirical\", \"ctree\", \"vaeac\", \"categorical\", \"timeseries\", \"independence\", \"regression_separate\", \"regression_surrogate\". two regression approaches combined approach. See details information. phi0 Numeric. prediction value unseen data, .e., estimate expected prediction without conditioning features. Typically set equal mean response training data, alternatives mean training predictions also reasonable. max_n_coalitions Integer. Upper limit number unique feature/group coalitions use iterative procedure (iterative = TRUE). iterative = FALSE, represents number feature/group coalitions use directly. quantity refers number unique feature coalitions group = NULL, group coalitions group != NULL. max_n_coalitions = NULL corresponds 2^n_features. iterative Logical NULL. NULL (default), set TRUE 5 features/groups, FALSE otherwise. TRUE, Shapley values estimated iteratively faster, sufficiently accurate results. First initial number coalitions sampled, bootstrapping estimates variance Shapley values. convergence criterion determines variances sufficiently small. , additional samples added. process repeats variances threshold. Specifics iterative process convergence criterion set via iterative_args. group_lags Logical. TRUE lags variable grouped together explained group. FALSE lags variable explained individually. group List. NULL, regular feature-wise Shapley values computed. provided, group-wise Shapley values computed. group length equal number groups. list element contains character vectors features included corresponding group. See Jullum et al. (2021) information group-wise Shapley values. n_MC_samples Positive integer. approaches, indicates maximum number samples use Monte Carlo integration every conditional expectation. approach=\"ctree\", n_MC_samples corresponds number samples leaf node (see exception related ctree.sample argument setup_approach.ctree()). approach=\"empirical\", n_MC_samples \\(K\\) parameter equations (14-15) Aas et al. (2021), .e. maximum number observations (largest weights) used, see also empirical.eta argument setup_approach.empirical(). seed Positive integer. Specifies seed code involving randomness run. NULL (default), seed set calling environment. predict_model Function. Prediction function use model natively supported. (Run get_supported_models() list natively supported models.) function must two arguments, model newdata, specify model data.frame/data.table compute predictions , respectively. function must give prediction numeric vector. NULL (default) uses functions specified internally. Can also used override default function natively supported model classes. get_model_specs Function. optional function checking model/data consistency model natively supported. (Run get_supported_models() list natively supported models.) function takes model argument provides list 3 elements: labels Character vector names feature. classes Character vector class feature. factor_levels Character vector levels categorical features. NULL (default), internal functions used natively supported model classes, checking disabled unsupported model classes. Can also used override default function natively supported model classes. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). extra_computation_args Named list. Specifies extra arguments related computation Shapley values. See get_extra_comp_args_default() description arguments default values. iterative_args Named list. Specifies arguments iterative procedure. See get_iterative_args_default() description arguments default values. output_args Named list. Specifies certain arguments related output function. See get_output_args_default() description arguments default values. ... Arguments passed setup_approach.categorical, setup_approach.copula, setup_approach.ctree, setup_approach.empirical, setup_approach.gaussian, setup_approach.independence, setup_approach.timeseries, setup_approach.vaeac categorical.joint_prob_dt Data.table. (Optional) Containing joint probability distribution combination feature values. NULL means estimated x_train x_explain. categorical.epsilon Numeric value. (Optional) categorical.joint_prob_dt supplied, probabilities/frequencies estimated using x_train. certain observations occur x_explain x_train, epsilon used proportion times observations occur training data. theory, proportion zero, causes error later Shapley computation. internal List. used directly, passed explain(). ctree.mincriterion Numeric scalar vector. Either scalar vector length equal number features model. value equal 1 - \\(\\alpha\\) \\(\\alpha\\) nominal level conditional independence tests. vector, indicates value use conditioning various numbers features. default value 0.95. ctree.minsplit Numeric scalar. Determines minimum value sum left right daughter nodes must reach split. default value 20. ctree.minbucket Numeric scalar. Determines minimum sum weights terminal node required split. default value 7. ctree.sample Boolean. TRUE (default), method always samples n_MC_samples observations leaf nodes (replacement). FALSE number observations leaf node less n_MC_samples, method take observations leaf. FALSE number observations leaf node n_MC_samples, method sample n_MC_samples observations (replacement). means always sampling leaf unless sample = FALSE number obs node less n_MC_samples. empirical.type Character. (default = \"fixed_sigma\") Must one \"independence\", \"fixed_sigma\", \"AICc_each_k\", \"AICc_full\". Note: \"empirical.type = independence\" deprecated; use approach = \"independence\" instead. \"fixed_sigma\" uses fixed bandwidth (set empirical.fixed_sigma) kernel density estimation. \"AICc_each_k\" \"AICc_full\" optimize bandwidth using AICc criterion, respectively one bandwidth per coalition size one bandwidth coalition sizes. empirical.eta Numeric scalar. Needs 0 < eta <= 1. default value 0.95. Represents minimum proportion total empirical weight data samples use. example, eta = .8, choose K samples largest weights sum weights accounts 80\\ eta \\(\\eta\\) parameter equation (15) Aas et al. (2021). empirical.fixed_sigma Positive numeric scalar. default value 0.1. Represents kernel bandwidth distance computation used conditioning different coalitions. used empirical.type = \"fixed_sigma\" empirical.n_samples_aicc Positive integer. Number samples consider AICc optimization. default value 1000. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.eval_max_aicc Positive integer. Maximum number iterations optimizing AICc. default value 20. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.start_aicc Numeric. Start value sigma parameter optimizing AICc. default value 0.1. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.cov_mat Numeric matrix. (Optional) covariance matrix data generating distribution used define Mahalanobis distance. NULL means estimated x_train. gaussian.mu Numeric vector. (Optional) Containing mean data generating distribution. NULL means estimated x_train. gaussian.cov_mat Numeric matrix. (Optional) Containing covariance matrix data generating distribution. NULL means estimated x_train. timeseries.fixed_sigma Positive numeric scalar. Represents kernel bandwidth distance computation. default value 2. timeseries.bounds Numeric vector length two. Specifies lower upper bounds timeseries. default c(NULL, NULL), .e. bounds. one bounds NULL, restrict sampled time series bounds. useful underlying time series scaled 0 1, example. vaeac.depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. vaeac.width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. vaeac.latent_dim Positive integer (default 8). number dimensions latent space. vaeac.lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. vaeac.activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu() (default), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid(). vaeac.n_vaeacs_initialize Positive integer (default 4). number different vaeac models initiate start. Pick best performing one vaeac.extra_parameters$epochs_initiation_phase epochs (default 2) continue training one. vaeac.epochs Positive integer (default 100). number epochs train final vaeac model. includes vaeac.extra_parameters$epochs_initiation_phase, default 2. vaeac.extra_parameters Named list extra parameters vaeac approach. See vaeac_get_extra_para_default() description possible additional parameters default values.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"Object class c(\"shapr\", \"list\"). Contains following items: shapley_values_est data.table estimated Shapley values explained observation rows features along columns. column none prediction devoted features (given argument phi0) shapley_values_sd data.table standard deviation Shapley values reflecting uncertainty coalition sampling part kernelSHAP procedure. , definition, 0 coalitions used. present extra_computation_args$compute_sd=TRUE, default iterative = TRUE. internal List different parameters, data, functions output used internally. pred_explain Numeric vector predictions explained observations. MSEv List values MSEv evaluation criterion approach. See MSEv evaluation section general usage vignette details. timing List containing timing information different parts computation. summary contains time stamps start end time addition total execution time. overall_timing_secs gives time spent different parts explanation computation. main_computation_timing_secs decomposes main computation time different parts computation iteration iterative estimation routine, used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"function explains forecast length horizon. argument train_idx analogous x_train explain(), however, just contains time indices data forecast start training sample. way explain_idx defines time index (indices) precede forecast explained. autoregressive forecast model require set lags make forecast arbitrary point time, explain_y_lags explain_xreg_lags define many lags required \"refit\" model given time index. allows different approaches work way time-invariant models. See  forecasting section general usage vignette details. See also software paper Jullum et al. (2025, Sec. 6) detailed introduction methodology, additional examples.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"Jullum, M., Olsen, L. H. B., Lachmann, J., & Redelmeier, . (2025). shapr: Explaining Machine Learning Models Conditional Shapley Values R Python. arXiv preprint arXiv:2504.01842. Aas, K., Jullum, M., & L√∏land, . (2021). Explaining individual predictions features dependent: accurate approximations Shapley values. Artificial Intelligence, 298, 103502 Frye, C., Rowat, C., & Feige, . (2020). Asymmetric Shapley values: incorporating causal knowledge model-agnostic explainability. Advances neural information processing systems, 33, 1229-1239 Heskes, T., Sijben, E., Bucur, . G., & Claassen, T. (2020). Causal shapley values: Exploiting causal knowledge explain individual predictions complex models. Advances neural information processing systems, 33, 4778-4789 Jullum, M., Redelmeier, . & Aas, K. (2021). Efficient simple prediction explanations groupShapley: practical perspective. Italian Workshop Explainable Artificial Intelligence 2021. Redelmeier, ., Jullum, M., & Aas, K. (2020). Explaining predictive models mixed features using Shapley values conditional inference trees. Machine Learning Knowledge Extraction: International Cross-Domain Conference, CD-MAKE 2020, Dublin, Ireland, August 25-28, 2020, Proceedings 4 (pp. 117-137). Springer International Publishing. Sellereite N., & Jullum, M. (2019). shapr: R-package explaining machine learning models dependence-aware Shapley values. Journal Open Source Software, 5(46), 2027 Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51 Olsen, L. H. B., Glad, . K., Jullum, M., & Aas, K. (2024). comparative study methods estimating model-agnostic Shapley value explanations. Data Mining Knowledge Discovery, 1-48 Olsen, L. H. B., & Jullum, M. (2024). Improving Sampling Strategy KernelSHAP. arXiv e-prints, arXiv-2410","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"Jon Lachmann, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/explain_forecast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explain a forecast from time series models with dependence-aware (conditional/observational) Shapley values ‚Äî explain_forecast","text":"","code":"# \\donttest{ # Load example data data(\"airquality\") data <- data.table::as.data.table(airquality)  # Fit an AR(2) model. model_ar_temp <- ar(data$Temp, order = 2)  # Calculate the zero prediction values for a three step forecast. p0_ar <- rep(mean(data$Temp), 3)  # Empirical approach, explaining forecasts starting at T = 152 and T = 153. explain_forecast(   model = model_ar_temp,   y = data[, \"Temp\"],   train_idx = 2:151,   explain_idx = 152:153,   explain_y_lags = 2,   horizon = 3,   approach = \"empirical\",   phi0 = p0_ar,   group_lags = FALSE ) #>  #> ‚îÄ‚îÄ Starting `shapr::explain_forecast()` at 2025-08-25 14:08:15 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature names extracted from the model contain `NA`. #>   Consistency checks between model and data are therefore disabled. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 4`, and is #>   therefore set to `2^n_features = 4`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <ar> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 1000 #> ‚Ä¢ Number of feature-wise Shapley values: 2 #> ‚Ä¢ Number of observations to explain: 2 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f1232692a97.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 4 of 4 coalitions.  #>    explain_idx horizon  none Temp.1 Temp.2 #>          <int>   <int> <num>  <num>  <num> #> 1:         152       1  77.9 -0.397 -1.391 #> 2:         153       1  77.9 -6.618 -0.184 #> 3:         152       2  77.9 -0.329 -1.203 #> 4:         153       2  77.9 -6.021 -0.337 #> 5:         152       3  77.9 -0.291 -1.055 #> 6:         153       3  77.9 -5.212 -0.255 # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/finalize_explanation.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather the final output to create the explanation object ‚Äî finalize_explanation","title":"Gather the final output to create the explanation object ‚Äî finalize_explanation","text":"Gather final output create explanation object","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/finalize_explanation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather the final output to create the explanation object ‚Äî finalize_explanation","text":"","code":"finalize_explanation(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/finalize_explanation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather the final output to create the explanation object ‚Äî finalize_explanation","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/finalize_explanation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gather the final output to create the explanation object ‚Äî finalize_explanation","text":"List reformatted output information extracted internal.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_convergence_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to extract formatted info about the (current) convergence state of the shapr call ‚Äî format_convergence_info","title":"Internal function to extract formatted info about the (current) convergence state of the shapr call ‚Äî format_convergence_info","text":"used print_iter() summary.shapr","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_convergence_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to extract formatted info about the (current) convergence state of the shapr call ‚Äî format_convergence_info","text":"","code":"format_convergence_info(internal, iter)"},{"path":"https://norskregnesentral.github.io/shapr/reference/format_convergence_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to extract formatted info about the (current) convergence state of the shapr call ‚Äî format_convergence_info","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. iter Integer. iteration number. used internally.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_info_basic.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to extract a vector with formatted info about the shapr call ‚Äî format_info_basic","title":"Internal function to extract a vector with formatted info about the shapr call ‚Äî format_info_basic","text":"used cli_startup() summary.shapr()","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_info_basic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to extract a vector with formatted info about the shapr call ‚Äî format_info_basic","text":"","code":"format_info_basic(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/format_info_basic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to extract a vector with formatted info about the shapr call ‚Äî format_info_basic","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_info_extra.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to extract some extra formatted info about the shapr call ‚Äî format_info_extra","title":"Internal function to extract some extra formatted info about the shapr call ‚Äî format_info_extra","text":"used summary.shapr()","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_info_extra.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to extract some extra formatted info about the shapr call ‚Äî format_info_extra","text":"","code":"format_info_extra(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/format_info_extra.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to extract some extra formatted info about the shapr call ‚Äî format_info_extra","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_round.html","id":null,"dir":"Reference","previous_headings":"","what":"Format numbers with rounding ‚Äî format_round","title":"Format numbers with rounding ‚Äî format_round","text":"Format numbers rounding","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_round.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format numbers with rounding ‚Äî format_round","text":"","code":"format_round(x, digits = 2L)"},{"path":"https://norskregnesentral.github.io/shapr/reference/format_round.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format numbers with rounding ‚Äî format_round","text":"x Numeric vector. numbers format. digits Integer. (Maximum) number digits displayed decimal point. Defaults 2.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_round.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format numbers with rounding ‚Äî format_round","text":"Character vector. formatted numbers.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_shapley_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to extract the formatted Shapley value table ‚Äî format_shapley_info","title":"Internal function to extract the formatted Shapley value table ‚Äî format_shapley_info","text":"used print_iter() summary.shapr()","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/format_shapley_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to extract the formatted Shapley value table ‚Äî format_shapley_info","text":"","code":"format_shapley_info(internal, iter, digits = 2L)"},{"path":"https://norskregnesentral.github.io/shapr/reference/format_shapley_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to extract the formatted Shapley value table ‚Äî format_shapley_info","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. iter Integer. iteration number. used internally. digits Integer. (Maximum) number digits displayed decimal point. Defaults 2.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a gauss_cat_loss ‚Äî gauss_cat_loss","title":"A torch::nn_module() Representing a gauss_cat_loss ‚Äî gauss_cat_loss","text":"gauss_cat_loss module layer computes log probability groundtruth object given mask distribution parameters. , log-likelihoods true/full training observations based generative distributions parameters distr_params inferred masked versions observations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a gauss_cat_loss ‚Äî gauss_cat_loss","text":"","code":"gauss_cat_loss(one_hot_max_sizes, min_sigma = 1e-04, min_prob = 1e-04)"},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a gauss_cat_loss ‚Äî gauss_cat_loss","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. min_sigma stability might desirable minimal sigma close zero. min_prob stability might desirable minimal probability close zero.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A torch::nn_module() Representing a gauss_cat_loss ‚Äî gauss_cat_loss","text":"Note module works mixed data represented 2-dimensional inputs works correctly missing values groundtruth long represented NaNs.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_loss.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a gauss_cat_loss ‚Äî gauss_cat_loss","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a gauss_cat_parameters ‚Äî gauss_cat_parameters","title":"A torch::nn_module() Representing a gauss_cat_parameters ‚Äî gauss_cat_parameters","text":"gauss_cat_parameters module extracts parameters inferred generative Gaussian categorical distributions continuous categorical features, respectively. one_hot_max_sizes \\([4, 1, 1, 2]\\), inferred distribution parameters one observation vector \\([p_{00}, p_{01}, p_{02}, p_{03}, \\mu_1, \\sigma_1, \\mu_2, \\sigma_2, p_{30}, p_{31}]\\), \\(\\operatorname{Softmax}([p_{00}, p_{01}, p_{02}, p_{03}])\\) \\(\\operatorname{Softmax}([p_{30}, p_{31}])\\) probabilities first fourth feature categories respectively model generative distribution, Gaussian(\\(\\mu_1, \\sigma_1^2\\)) Gaussian(\\(\\mu_2, \\sigma_2^2\\)) model generative distributions second third features.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a gauss_cat_parameters ‚Äî gauss_cat_parameters","text":"","code":"gauss_cat_parameters(one_hot_max_sizes, min_sigma = 1e-04, min_prob = 1e-04)"},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a gauss_cat_parameters ‚Äî gauss_cat_parameters","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. min_sigma stability might desirable minimal sigma close zero. min_prob stability might desirable minimal probability close zero.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_parameters.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a gauss_cat_parameters ‚Äî gauss_cat_parameters","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_most_likely.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a gauss_cat_sampler_most_likely ‚Äî gauss_cat_sampler_most_likely","title":"A torch::nn_module() Representing a gauss_cat_sampler_most_likely ‚Äî gauss_cat_sampler_most_likely","text":"gauss_cat_sampler_most_likely generates likely samples generative distribution defined output vaeac. .e., layer return mean probable class Gaussian (continuous features) categorical (categorical features) distributions, respectively.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_most_likely.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a gauss_cat_sampler_most_likely ‚Äî gauss_cat_sampler_most_likely","text":"","code":"gauss_cat_sampler_most_likely(   one_hot_max_sizes,   min_sigma = 1e-04,   min_prob = 1e-04 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_most_likely.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a gauss_cat_sampler_most_likely ‚Äî gauss_cat_sampler_most_likely","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. min_sigma stability might desirable minimal sigma close zero. min_prob stability might desirable minimal probability close zero.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_most_likely.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A torch::nn_module() Representing a gauss_cat_sampler_most_likely ‚Äî gauss_cat_sampler_most_likely","text":"gauss_cat_sampler_most_likely object.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_most_likely.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a gauss_cat_sampler_most_likely ‚Äî gauss_cat_sampler_most_likely","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_random.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a gauss_cat_sampler_random ‚Äî gauss_cat_sampler_random","title":"A torch::nn_module() Representing a gauss_cat_sampler_random ‚Äî gauss_cat_sampler_random","text":"gauss_cat_sampler_random generates random samples generative distribution defined output vaeac. random sample generated sampling inferred Gaussian categorical distributions continuous categorical features, respectively.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_random.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a gauss_cat_sampler_random ‚Äî gauss_cat_sampler_random","text":"","code":"gauss_cat_sampler_random(   one_hot_max_sizes,   min_sigma = 1e-04,   min_prob = 1e-04 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_random.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a gauss_cat_sampler_random ‚Äî gauss_cat_sampler_random","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. min_sigma stability might desirable minimal sigma close zero. min_prob stability might desirable minimal probability close zero.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gauss_cat_sampler_random.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a gauss_cat_sampler_random ‚Äî gauss_cat_sampler_random","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Transforms a sample to standardized normal distribution ‚Äî gaussian_transform","title":"Transforms a sample to standardized normal distribution ‚Äî gaussian_transform","text":"Transforms sample standardized normal distribution","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transforms a sample to standardized normal distribution ‚Äî gaussian_transform","text":"","code":"gaussian_transform(x)"},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transforms a sample to standardized normal distribution ‚Äî gaussian_transform","text":"x Numeric vector.data transformed standard normal distribution.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transforms a sample to standardized normal distribution ‚Äî gaussian_transform","text":"Numeric vector length length(x)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Transforms a sample to standardized normal distribution ‚Äî gaussian_transform","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform_separate.html","id":null,"dir":"Reference","previous_headings":"","what":"Transforms new data to standardized normal (dimension 1) based on other data transformations ‚Äî gaussian_transform_separate","title":"Transforms new data to standardized normal (dimension 1) based on other data transformations ‚Äî gaussian_transform_separate","text":"Transforms new data standardized normal (dimension 1) based data transformations","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform_separate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transforms new data to standardized normal (dimension 1) based on other data transformations ‚Äî gaussian_transform_separate","text":"","code":"gaussian_transform_separate(yx, n_y)"},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform_separate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transforms new data to standardized normal (dimension 1) based on other data transformations ‚Äî gaussian_transform_separate","text":"yx Numeric vector. first n_y items data transformed, last part data original transformation. n_y Positive integer. Number elements yx belongs Gaussian data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform_separate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transforms new data to standardized normal (dimension 1) based on other data transformations ‚Äî gaussian_transform_separate","text":"Vector back-transformed Gaussian data","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/gaussian_transform_separate.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Transforms new data to standardized normal (dimension 1) based on other data transformations ‚Äî gaussian_transform_separate","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_S_causal_steps.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the steps for generating MC samples for coalitions following a causal ordering ‚Äî get_S_causal_steps","title":"Get the steps for generating MC samples for coalitions following a causal ordering ‚Äî get_S_causal_steps","text":"Get steps generating MC samples coalitions following causal ordering","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_S_causal_steps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the steps for generating MC samples for coalitions following a causal ordering ‚Äî get_S_causal_steps","text":"","code":"get_S_causal_steps(S, causal_ordering, confounding, as_string = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_S_causal_steps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the steps for generating MC samples for coalitions following a causal ordering ‚Äî get_S_causal_steps","text":"S Integer matrix dimension n_coalitions_valid x m, n_coalitions_valid equals total number valid coalitions respect causal ordering given causal_ordering m equals total number features. causal_ordering List. applicable (regular) non-causal asymmetric explanations. causal_ordering unnamed list vectors specifying components partial causal ordering coalitions must respect. vector represents component contains one features/groups identified names (strings) indices (integers). causal_ordering NULL (default), causal ordering assumed possible coalitions allowed. causal ordering equivalent causal ordering single component includes features (list(1:n_features)) groups (list(1:n_groups)) feature-wise group-wise Shapley values, respectively. feature-wise Shapley values causal_ordering = list(c(1, 2), c(3, 4)), interpretation features 1 2 ancestors features 3 4, features 3 4 level. Note: features/groups must included causal_ordering without duplicates. confounding Logical vector. applicable (regular) non-causal asymmetric explanations. confounding logical vector specifying whether confounding assumed component causal_ordering. NULL (default), assumption confounding structure made explain computes asymmetric/symmetric conditional Shapley values, depending asymmetric. confounding single logical (FALSE TRUE), assumption set globally components causal ordering. Otherwise, confounding must length causal_ordering, indicating confounding assumption component. confounding specified, explain computes asymmetric/symmetric causal Shapley values, depending asymmetric. approach regression_separate regression_surrogate, regression-based approaches applicable causal Shapley methodology. as_string Boolean. returned object list lists integers list vectors strings.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_S_causal_steps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the steps for generating MC samples for coalitions following a causal ordering ‚Äî get_S_causal_steps","text":"Depends value parameter as_string. string, results[j] vector specifying process generating samples coalition j. length results[j] number steps, results[j][] string form features_to_sample|features_to_condition_on. features_to_condition_on part blank, sample marginal distribution. as_string == FALSE, rather return vector results[[j]][[]] contains elements Sbar S representing features sample condition , respectively.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_S_causal_steps.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the steps for generating MC samples for coalitions following a causal ordering ‚Äî get_S_causal_steps","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_cov_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"get_cov_mat ‚Äî get_cov_mat","title":"get_cov_mat ‚Äî get_cov_mat","text":"get_cov_mat","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_cov_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_cov_mat ‚Äî get_cov_mat","text":"","code":"get_cov_mat(x_train, min_eigen_value = 1e-06)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_cov_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_cov_mat ‚Äî get_cov_mat","text":"x_train Matrix data.frame/data.table. Data used estimate (conditional) feature distributions needed properly estimate conditional expectations Shapley formula. min_eigen_value Numeric Specifies smallest allowed eigen value covariance matrix x_train assumed positive definite, Matrix::nearPD() used find nearest one.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up data for explain_forecast ‚Äî get_data_forecast","title":"Set up data for explain_forecast ‚Äî get_data_forecast","text":"Set data explain_forecast","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up data for explain_forecast ‚Äî get_data_forecast","text":"","code":"get_data_forecast(   y,   xreg,   train_idx,   explain_idx,   explain_y_lags,   explain_xreg_lags,   horizon )"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up data for explain_forecast ‚Äî get_data_forecast","text":"y Matrix, data.frame/data.table numeric vector. Contains endogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. xreg Matrix, data.frame/data.table numeric vector. Contains exogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. exogenous variables used contemporaneously producing forecast, item contain nrow(y) + horizon rows. train_idx Numeric vector. row indices data reg denoting points time use estimating conditional expectations Shapley value formula. train_idx = NULL (default) indices selected explained used. explain_idx Numeric vector. row indices data reg denoting points time explain. explain_y_lags Numeric vector. Denotes number lags used variable y making forecast. explain_xreg_lags Numeric vector. xreg != NULL, denotes number lags used variable xreg making forecast. horizon Numeric. forecast horizon explain. Passed predict_model function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_forecast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up data for explain_forecast ‚Äî get_data_forecast","text":"list containing data.frames x_train x_explain holds lagged data examples. numeric, n_endo denoting many columns endogenous x_train x_explain. list, group groupings variable explain per variable per variable lag.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_specs.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetches feature information from a given data set ‚Äî get_data_specs","title":"Fetches feature information from a given data set ‚Äî get_data_specs","text":"Fetches feature information given data set","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_specs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetches feature information from a given data set ‚Äî get_data_specs","text":"","code":"get_data_specs(x)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_specs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetches feature information from a given data set ‚Äî get_data_specs","text":"x data.frame data.table. data extract feature information .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_specs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetches feature information from a given data set ‚Äî get_data_specs","text":"list following elements: labels character vector feature names compute Shapley values classes named character vector labels names class types elements factor_levels named list labels names character vectors factor levels elements (NULL feature factor)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_specs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetches feature information from a given data set ‚Äî get_data_specs","text":"function used extract feature information checked corresponding information extracted model data sets. function called internally","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_data_specs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fetches feature information from a given data set ‚Äî get_data_specs","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_comp_args_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","title":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","text":"Gets default values extra computation arguments","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_comp_args_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","text":"","code":"get_extra_comp_args_default(   internal,   paired_shap_sampling = isFALSE(internal$parameters$asymmetric),   semi_deterministic_sampling = FALSE,   kernelSHAP_reweighting = \"on_all_cond\",   compute_sd = isFALSE(internal$parameters$exact),   n_boot_samps = 100,   vS_batching_method = \"future\",   max_batch_size = 10,   min_n_batches = 10 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_comp_args_default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","text":"internal List. used directly, passed explain(). paired_shap_sampling Logical. TRUE paired versions sampled coalitions also included computation. , 5 features e.g. coalitions (1,3,5) sampled, also coalition (2,4) used computing Shapley values. done reduce variance Shapley value estimates. TRUE default recommended highest accuracy. asymmetric, FALSE default legal value. semi_deterministic_sampling Logical. FALSE (default), sample coalitions. TRUE, sampling coalitions semi-deterministic, .e. sampling done way ensures coalitions expected sampled based number coalitions deterministically included sample among fewer coalitions. done reduce variance Shapley value estimates, corresponds PySHAP* strategy paper Olsen & Jullum (2024). kernelSHAP_reweighting String. reweight sampling frequency weights kernelSHAP solution sampling. aim reduce randomness thereby variance Shapley value estimates. options one 'none', 'on_N', 'on_all', 'on_all_cond' (default). 'none' means reweighting, .e. sampling frequency weights used . 'on_N' means sampling frequencies averaged coalitions original sampling probabilities. 'on_all' means original sampling probabilities used coalitions. 'on_all_cond' means original sampling probabilities used coalitions, adjusting probability sampled least . 'on_all_cond' preferred performs best simulation studies, see Olsen & Jullum (2024). compute_sd Logical. Whether estimate standard deviations Shapley value estimates. TRUE whenever sampling based kernelSHAP applied (either iteratively fixed number coalitions). n_boot_samps Integer. number bootstrapped samples (.e. samples replacement) set coalitions used estimate standard deviations Shapley value estimates. vS_batching_method String. method used perform batch computing vS. \"future\" (default), utilizes future.apply::future_apply (via future::future package), enabling parallelized computation progress updates via progressr::progressr. Alternatively, \"forloop\" can used straightforward sequential computation, mainly useful package development debugging purposes. max_batch_size Integer. maximum number coalitions estimate simultaneously within iteration. larger number requires memory, may slight computational advantage. min_n_batches Integer. minimum number batches split computation within iteration. Larger numbers give frequent progress updates. parallelization applied, set smaller number parallel workers.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_comp_args_default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","text":"list default values extra computation arguments.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_comp_args_default.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","text":"Olsen, L. H. B., & Jullum, M. (2024). Improving Sampling Strategy KernelSHAP. arXiv preprint arXiv:2410.04883.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_comp_args_default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gets the default values for the extra computation arguments ‚Äî get_extra_comp_args_default","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"This includes both extra parameters and other objects ‚Äî get_extra_parameters","title":"This includes both extra parameters and other objects ‚Äî get_extra_parameters","text":"includes extra parameters objects","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_extra_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This includes both extra parameters and other objects ‚Äî get_extra_parameters","text":"","code":"get_extra_parameters(internal, type)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_feature_specs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get feature specifications from the model ‚Äî get_feature_specs","title":"Get feature specifications from the model ‚Äî get_feature_specs","text":"Get feature specifications model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_feature_specs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get feature specifications from the model ‚Äî get_feature_specs","text":"","code":"get_feature_specs(get_model_specs, model)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_feature_specs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get feature specifications from the model ‚Äî get_feature_specs","text":"get_model_specs Function. optional function checking model/data consistency model natively supported. (Run get_supported_models() list natively supported models.) function takes model argument provides list 3 elements: labels Character vector names feature. classes Character vector class feature. factor_levels Character vector levels categorical features. NULL (default), internal functions used natively supported model classes, checking disabled unsupported model classes. Can also used override default function natively supported model classes. model Model object. model whose predictions want explain. Run get_supported_models() table models explain supports natively. Unsupported models can still explained passing predict_model (optionally) get_model_specs, see details information.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_iterative_args_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","title":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","text":"Function specify arguments iterative estimation procedure","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_iterative_args_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","text":"","code":"get_iterative_args_default(   internal,   initial_n_coalitions = ceiling(min(200, max(5, internal$parameters$n_features,     (2^internal$parameters$n_features)/10), internal$parameters$max_n_coalitions)),   fixed_n_coalitions_per_iter = NULL,   max_iter = 20,   convergence_tol = 0.02,   n_coal_next_iter_factor_vec = c(seq(0.1, 1, by = 0.1), rep(1, max_iter - 10)) )"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_iterative_args_default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","text":"internal List. used directly, passed explain(). initial_n_coalitions Integer. Number coalitions use first estimation iteration. fixed_n_coalitions_per_iter Integer. Number n_coalitions use iteration. NULL (default) means setting based estimates based set convergence threshold. max_iter Integer. Maximum number estimation iterations convergence_tol Numeric. t variable convergence threshold formula page 6 paper Covert Lee (2021), 'Improving KernelSHAP: Practical Shapley Value Estimation via Linear Regression' https://arxiv.org/pdf/2012.01536. Smaller values requires coalitions convergence reached. n_coal_next_iter_factor_vec Numeric vector. number n_coalitions must used reach convergence next iteration estimated. number n_coalitions actually used next iteration set estimate multiplied n_coal_next_iter_factor_vec[] iteration . wise start smaller numbers avoid using many n_coalitions due uncertain estimates first iterations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_iterative_args_default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","text":"list default values iterative estimation procedure","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_iterative_args_default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","text":"functions sets default values iterative estimation procedure, according function defaults. argument iterative explain() FALSE, sets parameters corresponding use non-iterative estimation procedure","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_iterative_args_default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to specify arguments of the iterative estimation procedure ‚Äî get_iterative_args_default","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_max_n_coalitions_causal.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","title":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","text":"Get number coalitions respects causal ordering","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_max_n_coalitions_causal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","text":"","code":"get_max_n_coalitions_causal(causal_ordering)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_max_n_coalitions_causal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","text":"causal_ordering List. applicable (regular) non-causal asymmetric explanations. causal_ordering unnamed list vectors specifying components partial causal ordering coalitions must respect. vector represents component contains one features/groups identified names (strings) indices (integers). causal_ordering NULL (default), causal ordering assumed possible coalitions allowed. causal ordering equivalent causal ordering single component includes features (list(1:n_features)) groups (list(1:n_groups)) feature-wise group-wise Shapley values, respectively. feature-wise Shapley values causal_ordering = list(c(1, 2), c(3, 4)), interpretation features 1 2 ancestors features 3 4, features 3 4 level. Note: features/groups must included causal_ordering without duplicates.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_max_n_coalitions_causal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","text":"Integer. (maximum) number coalitions respects causal ordering.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_max_n_coalitions_causal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","text":"function computes number coalitions respects causal ordering computing number coalitions partial causal component summing . compute number coalitions \\(\\)th partial causal component \\(2^n - 1\\), \\(n\\) number features \\(\\)th partial causal component subtract one want include situation features \\(\\)th partial causal component present. end, add 1 empty coalition.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_max_n_coalitions_causal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the number of coalitions that respects the causal ordering ‚Äî get_max_n_coalitions_causal","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetches feature information from natively supported models ‚Äî get_model_specs","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"function used extract feature information model checked corresponding feature information data passed explain(). NOTE: never need call function explicitly. exported just easier accessible users, see details.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"","code":"get_model_specs(x)  # Default S3 method get_model_specs(x)  # S3 method for class 'ar' get_model_specs(x)  # S3 method for class 'Arima' get_model_specs(x)  # S3 method for class 'forecast_ARIMA' get_model_specs(x)  # S3 method for class 'glm' get_model_specs(x)  # S3 method for class 'lm' get_model_specs(x)  # S3 method for class 'gam' get_model_specs(x)  # S3 method for class 'ranger' get_model_specs(x)  # S3 method for class 'workflow' get_model_specs(x)  # S3 method for class 'xgb.Booster' get_model_specs(x)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"x Model object model explained.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"list following elements: labels character vector feature names compute Shapley values classes named character vector labels names class type elements factor_levels named list labels names character vectors factor levels elements (NULL feature factor)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"explaining model supported natively, may (optionally) enable checking creating function passing explain().","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_model_specs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetches feature information from natively supported models ‚Äî get_model_specs","text":"","code":"# Load example data data(\"airquality\") airquality <- airquality[complete.cases(airquality), ] # Split data into test- and training data x_train <- head(airquality, -3) x_explain <- tail(airquality, 3) # Fit a linear model model <- lm(Ozone ~ Solar.R + Wind + Temp + Month, data = x_train) get_model_specs(model) #> $labels #> [1] \"Solar.R\" \"Wind\"    \"Temp\"    \"Month\"   #>  #> $classes #>   Solar.R      Wind      Temp     Month  #> \"numeric\" \"numeric\" \"numeric\" \"numeric\"  #>  #> $factor_levels #> $factor_levels$Solar.R #> NULL #>  #> $factor_levels$Wind #> NULL #>  #> $factor_levels$Temp #> NULL #>  #> $factor_levels$Month #> NULL #>  #>"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_mu_vec.html","id":null,"dir":"Reference","previous_headings":"","what":"get_mu_vec ‚Äî get_mu_vec","title":"get_mu_vec ‚Äî get_mu_vec","text":"get_mu_vec","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_mu_vec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_mu_vec ‚Äî get_mu_vec","text":"","code":"get_mu_vec(x_train)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_mu_vec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_mu_vec ‚Äî get_mu_vec","text":"x_train Matrix data.frame/data.table. Data used estimate (conditional) feature distributions needed properly estimate conditional expectations Shapley formula.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_nice_time.html","id":null,"dir":"Reference","previous_headings":"","what":"Reformat seconds into a human-readable format. ‚Äî get_nice_time","title":"Reformat seconds into a human-readable format. ‚Äî get_nice_time","text":"Reformat seconds human-readable format.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_nice_time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reformat seconds into a human-readable format. ‚Äî get_nice_time","text":"","code":"get_nice_time(secs)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_nice_time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reformat seconds into a human-readable format. ‚Äî get_nice_time","text":"secs Numeric vector seconds reformat.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_nice_time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reformat seconds into a human-readable format. ‚Äî get_nice_time","text":"character string representing time human-readable format.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_output_args_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the default values for the output arguments ‚Äî get_output_args_default","title":"Gets the default values for the output arguments ‚Äî get_output_args_default","text":"Gets default values output arguments","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_output_args_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the default values for the output arguments ‚Äî get_output_args_default","text":"","code":"get_output_args_default(   keep_samp_for_vS = FALSE,   MSEv_uniform_comb_weights = TRUE,   saving_path = tempfile(\"shapr_obj_\", fileext = \".rds\") )"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_output_args_default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the default values for the output arguments ‚Äî get_output_args_default","text":"keep_samp_for_vS Logical. Indicates whether samples used Monte Carlo estimation v(S) returned (internal$output). used approach=\"regression_separate\" approach=\"regression_surrogate\". MSEv_uniform_comb_weights Logical. TRUE (default), function weights coalitions uniformly computing MSEv criterion. FALSE, function use Shapley kernel weights weight coalitions computing MSEv criterion. Note Shapley kernel weights replaced sampling frequency coalitions considered. saving_path String. path directory results iterative estimation procedure saved. Defaults temporary directory.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_output_args_default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets the default values for the output arguments ‚Äî get_output_args_default","text":"list default output arguments.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_output_args_default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gets the default values for the output arguments ‚Äî get_output_args_default","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_predict_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Get predict_model function ‚Äî get_predict_model","title":"Get predict_model function ‚Äî get_predict_model","text":"Get predict_model function","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_predict_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get predict_model function ‚Äî get_predict_model","text":"","code":"get_predict_model(predict_model, model)"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_predict_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get predict_model function ‚Äî get_predict_model","text":"predict_model Function. prediction function used model natively supported. See documentation explain() details. model Objects. model object explained. See documentation explain() details.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract components from a shapr object ‚Äî get_results","title":"Extract components from a shapr object ‚Äî get_results","text":"Extract components shapr object","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract components from a shapr object ‚Äî get_results","text":"","code":"get_results(   x,   what = c(\"calling_function\", \"approach\", \"shapley_est\", \"shapley_sd\", \"pred_explain\",     \"MSEv\", \"MSEv_explicand\", \"MSEv_coalition\", \"iterative_info\",     \"iterative_shapley_est\", \"iterative_shapley_sd\", \"saving_path\", \"timing_summary\",     \"timing_details\", \"parameters\", \"x_train\", \"x_explain\", \"dt_vS\", \"dt_samp_for_vS\",     \"dt_used_coalitions\", \"dt_valid_causal_coalitions\", \"dt_coal_samp_info\"),   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract components from a shapr object ‚Äî get_results","text":"x shapr object Character vector specifying one components extract. Options: \"calling_function\", \"approach\", \"shapley_est\", \"shapley_sd\", \"pred_explain\", \"MSEv\", \"MSEv_explicand\", \"MSEv_coalition\", \"iterative_info\", \"iterative_shapley_est\", \"iterative_shapley_sd\", \"saving_path\", \"timing_summary\", \"timing_details\", \"parameters\", \"x_train\", \"x_explain\", \"dt_vS\", \"dt_samp_for_vS\", \"dt_used_coalitions\", \"dt_valid_causal_coalitions\", \"dt_coal_samp_info\". default return components. See details component contains. ... used","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract components from a shapr object ‚Äî get_results","text":"single component requested, returns object. multiple requested, returns named list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_results.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract components from a shapr object ‚Äî get_results","text":"function extracts full suite information related computation Shapley values shapr object. allowed characters provides information follows: calling_function Name function called create shapr object, (explain() explain_forecast()). approach Approach used estimate conditional expectations. shapley_est data.table estimated Shapley values. shapley_sd data.table standard deviation Shapley values reflecting uncertainty coalition sampling part kernelSHAP procedure. pred_explain Numeric vector predictions explained observations. MSEv/MSEv_explicand/MSEv_coalition Data.tables MSEv evaluation criterion values overall/ per explicand/per coalition. Smaller values indicate better estimates v(S). See MSEv evaluation section general usage vignette details. iterative_info Data.table information iterative estimation procedure. iterative_shapley_est/iterative_shapley_sd Data.tables estimated Shapley values/standard deviation iteration (using iterative estimation procedure). saving_path Character string path (temporary) results saved. timing_summary Data.table one row three columns: init_time end_time give time stamps start end computation, respectively, total_time_secs gives total time seconds full computation. timing_details List containing timing information different parts computation. summary contains information timing_summary. overall_timing_secs gives time spent different parts explanation computation. main_computation_timing_secs decomposes main computation time different parts computation iteration iterative estimation routine, used. parameters List parameters used computation. x_train/x_explain Data.tables training data used computation/observations explain. dt_vS Data.table contribution function (v(S)) estimates coalition. dt_samp_for_vS Data.table samples used Monte Carlo estimation contribution function (v(S)). available output_args_default$keep_samp_for_vS = TRUE (defaults FALSE) explain(). dt_used_coalitions Data.table overview coalitions used computation. dt_valid_causal_coalitions Data.table valid causal coalitions used computation. dt_coal_samp_info Data.table information related coalition sampling procedure used. Note summary.shapr() function provides nicely formatted printout important information, invisibly return output present function. print.shapr() allows direct printing main results.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_supported_approaches.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the implemented approaches ‚Äî get_supported_approaches","title":"Gets the implemented approaches ‚Äî get_supported_approaches","text":"Gets implemented approaches","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_supported_approaches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the implemented approaches ‚Äî get_supported_approaches","text":"","code":"get_supported_approaches()"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_supported_approaches.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets the implemented approaches ‚Äî get_supported_approaches","text":"Character vector. names implemented approaches can passed argument approach explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_supported_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Provides a data.table with the supported models ‚Äî get_supported_models","title":"Provides a data.table with the supported models ‚Äî get_supported_models","text":"Provides data.table supported models","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_supported_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provides a data.table with the supported models ‚Äî get_supported_models","text":"","code":"get_supported_models()"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_supported_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Provides a data.table with the supported models ‚Äî get_supported_models","text":"data.table supported models.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_valid_causal_coalitions.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all coalitions satisfying the causal ordering ‚Äî get_valid_causal_coalitions","title":"Get all coalitions satisfying the causal ordering ‚Äî get_valid_causal_coalitions","text":"function relevant computing asymmetric Shapley values. symmetric Shapley values (regular causal), coalitions allowed.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_valid_causal_coalitions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all coalitions satisfying the causal ordering ‚Äî get_valid_causal_coalitions","text":"","code":"get_valid_causal_coalitions(   causal_ordering,   sort_features_in_coalitions = TRUE )"},{"path":"https://norskregnesentral.github.io/shapr/reference/get_valid_causal_coalitions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get all coalitions satisfying the causal ordering ‚Äî get_valid_causal_coalitions","text":"causal_ordering List. applicable (regular) non-causal asymmetric explanations. causal_ordering unnamed list vectors specifying components partial causal ordering coalitions must respect. vector represents component contains one features/groups identified names (strings) indices (integers). causal_ordering NULL (default), causal ordering assumed possible coalitions allowed. causal ordering equivalent causal ordering single component includes features (list(1:n_features)) groups (list(1:n_groups)) feature-wise group-wise Shapley values, respectively. feature-wise Shapley values causal_ordering = list(c(1, 2), c(3, 4)), interpretation features 1 2 ancestors features 3 4, features 3 4 level. Note: features/groups must included causal_ordering without duplicates. sort_features_in_coalitions Boolean. TRUE, feature indices coalitions sorted increasing order. FALSE, function maintains order features within group given causal_ordering.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_valid_causal_coalitions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all coalitions satisfying the causal ordering ‚Äî get_valid_causal_coalitions","text":"List vectors containing coalitions respects causal ordering.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/get_valid_causal_coalitions.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get all coalitions satisfying the causal ordering ‚Äî get_valid_causal_coalitions","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/group_forecast_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up user provided groups for explanation in a forecast model. ‚Äî group_forecast_setup","title":"Set up user provided groups for explanation in a forecast model. ‚Äî group_forecast_setup","text":"Set user provided groups explanation forecast model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/group_forecast_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up user provided groups for explanation in a forecast model. ‚Äî group_forecast_setup","text":"","code":"group_forecast_setup(group, horizon_features)"},{"path":"https://norskregnesentral.github.io/shapr/reference/group_forecast_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up user provided groups for explanation in a forecast model. ‚Äî group_forecast_setup","text":"group list groups explained. horizon_features list features per horizon, split appropriate groups .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/group_forecast_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up user provided groups for explanation in a forecast model. ‚Äî group_forecast_setup","text":"list containing group list group entries differ per horizon split accordingly. horizon_group list groups applicable per horizon.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/hat_matrix_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Computing single H matrix in AICc-function using the Mahalanobis distance ‚Äî hat_matrix_cpp","title":"Computing single H matrix in AICc-function using the Mahalanobis distance ‚Äî hat_matrix_cpp","text":"Computing single H matrix AICc-function using Mahalanobis distance","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/hat_matrix_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computing single H matrix in AICc-function using the Mahalanobis distance ‚Äî hat_matrix_cpp","text":"","code":"hat_matrix_cpp(X, mcov, S_scale_dist, h)"},{"path":"https://norskregnesentral.github.io/shapr/reference/hat_matrix_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computing single H matrix in AICc-function using the Mahalanobis distance ‚Äî hat_matrix_cpp","text":"X matrix. mcov matrix covariance matrix X. S_scale_dist logical. Indicating whether Mahalanobis distance scaled number variables h numeric specifying scaling (sigma)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/hat_matrix_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computing single H matrix in AICc-function using the Mahalanobis distance ‚Äî hat_matrix_cpp","text":"Matrix dimension ncol(X)*ncol(X)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/hat_matrix_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Computing single H matrix in AICc-function using the Mahalanobis distance ‚Äî hat_matrix_cpp","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/inv_gaussian_transform_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Transforms new data to a standardized normal distribution ‚Äî inv_gaussian_transform_cpp","title":"Transforms new data to a standardized normal distribution ‚Äî inv_gaussian_transform_cpp","text":"Transforms new data standardized normal distribution","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/inv_gaussian_transform_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transforms new data to a standardized normal distribution ‚Äî inv_gaussian_transform_cpp","text":"","code":"inv_gaussian_transform_cpp(z, x)"},{"path":"https://norskregnesentral.github.io/shapr/reference/inv_gaussian_transform_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transforms new data to a standardized normal distribution ‚Äî inv_gaussian_transform_cpp","text":"z arma::mat. data Gaussian Monte Carlos samples transform. x arma::mat. data original transformation. Used conduct transformation z.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/inv_gaussian_transform_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transforms new data to a standardized normal distribution ‚Äî inv_gaussian_transform_cpp","text":"arma::mat dimension z","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/inv_gaussian_transform_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Transforms new data to a standardized normal distribution ‚Äî inv_gaussian_transform_cpp","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/lag_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Lag a matrix of variables a specific number of lags for each variables. ‚Äî lag_data","title":"Lag a matrix of variables a specific number of lags for each variables. ‚Äî lag_data","text":"Lag matrix variables specific number lags variables.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/lag_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lag a matrix of variables a specific number of lags for each variables. ‚Äî lag_data","text":"","code":"lag_data(x, lags)"},{"path":"https://norskregnesentral.github.io/shapr/reference/lag_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lag a matrix of variables a specific number of lags for each variables. ‚Äî lag_data","text":"x matrix variables (one variable per column). lags numeric vector denoting many lags variable .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/lag_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lag a matrix of variables a specific number of lags for each variables. ‚Äî lag_data","text":"list two items matrix, lagged lagged data. list, group, groupings lagged data per variable.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mahalanobis_distance_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"(Generalized) Mahalanobis distance ‚Äî mahalanobis_distance_cpp","title":"(Generalized) Mahalanobis distance ‚Äî mahalanobis_distance_cpp","text":"Used get Euclidean distance well setting mcov = diag(m).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mahalanobis_distance_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Generalized) Mahalanobis distance ‚Äî mahalanobis_distance_cpp","text":"","code":"mahalanobis_distance_cpp(   featureList,   Xtrain_mat,   Xexplain_mat,   mcov,   S_scale_dist )"},{"path":"https://norskregnesentral.github.io/shapr/reference/mahalanobis_distance_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Generalized) Mahalanobis distance ‚Äî mahalanobis_distance_cpp","text":"featureList List. Contains vectors indicating factor combinations included computations. Assumes first one empty. Xtrain_mat Matrix Training data matrix form Xexplain_mat Matrix Explanation data matrix form. mcov matrix covariance matrix X. S_scale_dist logical. Indicating whether Mahalanobis distance scaled number variables","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mahalanobis_distance_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Generalized) Mahalanobis distance ‚Äî mahalanobis_distance_cpp","text":"Array three dimensions. Contains squared distance training test observations feature combinations passed function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mahalanobis_distance_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"(Generalized) Mahalanobis distance ‚Äî mahalanobis_distance_cpp","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mcar_mask_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","title":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","text":"mask generator masks entries input completely random.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mcar_mask_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","text":"","code":"mcar_mask_generator(masking_ratio = 0.5, paired_sampling = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/mcar_mask_generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","text":"masking_ratio Numeric 0 1. probability entry generated mask 1 (masked). paired_sampling Boolean. paired sampling. include S \\(\\bar{S}\\). TRUE, batch must sampled using paired_sampler() ensures batch contains two instances original observation. , batch \\(= [X_1, X_1, X_2, X_2, X_3, X_3, ...]\\), entry \\(X_j\\) row dimension \\(p\\) (.e., number features).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mcar_mask_generator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","text":"mask generator mask element batch (N x p) using component-wise independent Bernoulli distribution probability masking_ratio. Default values masking_ratio 0.5, masks equally likely generated, including empty full masks. function returns mask shape input batch, batch can contain missing values, indicated \"NaN\" token, always masked.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mcar_mask_generator.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","text":"Input: \\((N, p)\\) N number observations batch \\(p\\) number features. Output: \\((N, p)\\), shape input","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/mcar_mask_generator.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Missing Completely at Random (MCAR) Mask Generator ‚Äî mcar_mask_generator","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/memory_layer.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a Memory Layer ‚Äî memory_layer","title":"A torch::nn_module() Representing a Memory Layer ‚Äî memory_layer","text":"layer used make skip-connections inside torch::nn_sequential() network several torch::nn_sequential() networks without unnecessary code complication.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/memory_layer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a Memory Layer ‚Äî memory_layer","text":"","code":"memory_layer(id, shared_env, output = FALSE, add = FALSE, verbose = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/memory_layer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a Memory Layer ‚Äî memory_layer","text":"id unique id use key storage list. shared_env shared environment instances memory_layer inputs stored. output Boolean variable indicating memory layer store input storage extract storage. add Boolean variable indicating extracted value added concatenated input. applicable output = TRUE. verbose Boolean variable indicating want give printouts user.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/memory_layer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A torch::nn_module() Representing a Memory Layer ‚Äî memory_layer","text":"output = FALSE, layer stores input shared_env key id passes input next layer. .e., memory layer used masked encoder. output = TRUE, layer takes stored tensor storage. .e., memory layer used decoder. add = TRUE, returns sum stored vector input, otherwise returns concatenation. tensor specified id storage layer output = TRUE called, cause exception.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/memory_layer.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a Memory Layer ‚Äî memory_layer","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/model_checker.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that the type of model is supported by the native implementation of the model class ‚Äî model_checker","title":"Check that the type of model is supported by the native implementation of the model class ‚Äî model_checker","text":"function checks whether model given x supported. x supported model function return error message, otherwise return NULL (meaning types models class supported)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/model_checker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that the type of model is supported by the native implementation of the model class ‚Äî model_checker","text":"","code":"model_checker(x)  # Default S3 method model_checker(x)  # S3 method for class 'ar' model_checker(x)  # S3 method for class 'Arima' model_checker(x)  # S3 method for class 'forecast_ARIMA' model_checker(x)  # S3 method for class 'glm' model_checker(x)  # S3 method for class 'lm' model_checker(x)  # S3 method for class 'gam' model_checker(x)  # S3 method for class 'ranger' model_checker(x)  # S3 method for class 'workflow' model_checker(x)  # S3 method for class 'xgb.Booster' model_checker(x)"},{"path":"https://norskregnesentral.github.io/shapr/reference/model_checker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that the type of model is supported by the native implementation of the model class ‚Äî model_checker","text":"x Model object model explained.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/model_checker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that the type of model is supported by the native implementation of the model class ‚Äî model_checker","text":"Error NULL","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/reference/num_str.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a character to a numeric class ‚Äî num_str","title":"Convert a character to a numeric class ‚Äî num_str","text":"used cli calls like cli::cli_text(\"{.val {shapr:::num_str('12.10')}}\") format character strings typically represent number numeric. May also used strings representing number.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/num_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a character to a numeric class ‚Äî num_str","text":"","code":"num_str(x)"},{"path":"https://norskregnesentral.github.io/shapr/reference/num_str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a character to a numeric class ‚Äî num_str","text":"x Character. single character represents number, vector characters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/num_str.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a character to a numeric class ‚Äî num_str","text":"numeric class object value string.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate permutations of training data using test observations ‚Äî observation_impute","title":"Generate permutations of training data using test observations ‚Äî observation_impute","text":"Generate permutations training data using test observations","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate permutations of training data using test observations ‚Äî observation_impute","text":"","code":"observation_impute(   W_kernel,   S,   x_train,   x_explain,   empirical.eta = 0.7,   n_MC_samples = 1000 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate permutations of training data using test observations ‚Äî observation_impute","text":"W_kernel Numeric matrix. Contains non-scaled weights training test observations coalitions. dimension equals n_train x m. S Integer matrix dimension n_coalitions x m, n_coalitions m equals total number sampled/non-sampled coalitions total number unique features, respectively. Note m = ncol(x_train). x_train Data.table training data. x_explain Data.table features observation whose predictions explained (test data).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate permutations of training data using test observations ‚Äî observation_impute","text":"data.table","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate permutations of training data using test observations ‚Äî observation_impute","text":"Nikolai Sellereite","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Get imputed data ‚Äî observation_impute_cpp","title":"Get imputed data ‚Äî observation_impute_cpp","text":"Get imputed data","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get imputed data ‚Äî observation_impute_cpp","text":"","code":"observation_impute_cpp(index_xtrain, index_s, x_train, x_explain, S)"},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get imputed data ‚Äî observation_impute_cpp","text":"index_xtrain Positive integer. Represents sequence row indices x_train, .e. min(index_xtrain) >= 1 max(index_xtrain) <= nrow(x_train). index_s Positive integer. Represents sequence row indices S, .e. min(index_s) >= 1 max(index_s) <= nrow(S). x_train Matrix. Contains training data. x_explain Matrix 1 row. Contains features observation single prediction. S arma::mat. Matrix dimension (n_coalitions, n_features) containing binary representations used coalitions. S contain empty grand coalition, .e., row containing zeros ones. problem internally shapr empty grand coalitions treated differently.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get imputed data ‚Äî observation_impute_cpp","text":"Numeric matrix","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get imputed data ‚Äî observation_impute_cpp","text":"S(, j) = 1 feature j present feature combination , otherwise S(, j) = 0. .e. m = 3, 2^3 = 8 unique ways combine features. case dim(S) = c(8, 3). call features x1, x2, x3 take closer look combination represented s = c(x1, x2). combination represented second row, following true: S[2, 1:3] = c(1, 1, 0). returned object, X, numeric matrix dim(X) = c(length(index_xtrain), ncol(x_train)). feature j present k-th observation, S[index_[k], j] == 1, X[k, j] = x_explain[1, j]. Otherwise X[k, j] = x_train[index_xtrain[k], j].","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/observation_impute_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get imputed data ‚Äî observation_impute_cpp","text":"Nikolai Sellereite","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/paired_sampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampling Paired Observations ‚Äî paired_sampler","title":"Sampling Paired Observations ‚Äî paired_sampler","text":"sampler used samples batches instances sampled twice","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/paired_sampler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sampling Paired Observations ‚Äî paired_sampler","text":"","code":"paired_sampler(vaeac_dataset_object, shuffle = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/paired_sampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sampling Paired Observations ‚Äî paired_sampler","text":"vaeac_dataset_object vaeac_dataset() object containing data. shuffle Boolean. TRUE, data shuffled. FALSE, data returned chronological order.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/paired_sampler.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sampling Paired Observations ‚Äî paired_sampler","text":"sampler object allows paired sampling always including observation vaeac_dataset() twice. torch::sampler() object can used torch::dataloader() creating batches torch dataset torch::dataset(). See https://rdrr.io/cran/torch/src/R/utils-data-sampler.R information. function use batch iterators, might increase speed.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/paired_sampler.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sampling Paired Observations ‚Äî paired_sampler","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of the Shapley value explanations ‚Äî plot.shapr","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"Plots individual prediction explanations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"","code":"# S3 method for class 'shapr' plot(   x,   plot_type = \"bar\",   digits = 3,   index_x_explain = NULL,   top_k_features = NULL,   col = NULL,   bar_plot_phi0 = TRUE,   bar_plot_order = \"largest_first\",   scatter_features = NULL,   scatter_hist = TRUE,   include_group_feature_means = FALSE,   beeswarm_cex = 1/length(index_x_explain)^(1/4),   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"x shapr object. output explain(). plot_type Character. Specifies type plot produce. \"bar\" (default) gives regular horizontal bar plot Shapley value magnitudes. \"waterfall\" gives waterfall plot indicating changes prediction score due feature's contribution (Shapley values). \"scatter\" plots feature values x-axis Shapley values y-axis, well (optionally) background scatter_hist showing distribution feature data. \"beeswarm\" summarizes distribution Shapley values along x-axis features. point gives Shapley value given instance, points colored feature value instance. digits Integer. Number significant digits use feature description. Applicable plot_type \"bar\" \"waterfall\" index_x_explain Integer vector. test observations plot. example, explained 10 observations using explain(), can generate plot first five observations setting index_x_explain = 1:5. top_k_features Integer. many features include plot. E.g. 15 features model can plot 5 important features, explanation, setting top_k_features = 1:5. Applicable plot_type \"bar\" \"waterfall\" col Character vector (length depends plot type). color codes (hex codes names understood ggplot2::ggplot()) positive negative Shapley values, respectively. default col=NULL, plotting default colors respective plot type. plot_type = \"bar\" plot_type = \"waterfall\", default c(\"#00BA38\",\"#F8766D\"). plot_type = \"beeswarm\", default c(\"#F8766D\",\"yellow\",\"#00BA38\"). plot_type = \"scatter\", default \"#619CFF\". want alter colors plot, length col vector depends plot type. plot_type = \"bar\" plot_type = \"waterfall\", two colors provided, first positive negative Shapley values. plot_type = \"beeswarm\", either two three colors can given. two colors given, first color determines color points high feature values , second determines color points low feature values. three colors given, first colors high feature values, second colors mid-range feature values, third colors low feature values. instance, col = c(\"red\", \"yellow\", \"blue\") make high values red, mid-range values yellow, low values blue. plot_type = \"scatter\", single color given, determines color points scatter plot. bar_plot_phi0 Logical. Whether include phi0 plot  plot_type = \"bar\". bar_plot_order Character. Specifies order plot features respect magnitude Shapley values plot_type = \"bar\": \"largest_first\" (default) plots features ordered largest smallest absolute Shapley value. \"smallest_first\" plots features ordered smallest largest absolute Shapley value. \"original\" plots features original order data table. scatter_features Integer character vector. used plot_type = \"scatter\". Specifies features include scatter plot. Can numerical vector indicating feature index, character vector, indicating name(s) feature(s) plot. scatter_hist Logical. used plot_type = \"scatter\". Whether include scatter_hist indicating distribution data making scatter plot. Note bins scaled bins stacked fit span y-axis plot. include_group_feature_means Logical. Whether include average feature value group y-axis . FALSE (default), value shown groups. TRUE, shapr includes mean features group. beeswarm_cex Numeric. cex argument ggbeeswarm::geom_beeswarm(), controlling spacing beeswarm plots. ... arguments passed underlying functions, like ggbeeswarm::geom_beeswarm() plot_type = \"beeswarm\".","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"ggplot object plots Shapley value explanations","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"See examples , vignette(\"general_usage\", package = \"shapr\") examples use function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"Martin Jullum, Vilde Ung, Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot.shapr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of the Shapley value explanations ‚Äî plot.shapr","text":"","code":"# \\donttest{ if (requireNamespace(\"party\", quietly = TRUE)) {   data(\"airquality\")   airquality <- airquality[complete.cases(airquality), ]   x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\")   y_var <- \"Ozone\"    # Split data into test- and training data   data_train <- head(airquality, -50)   data_explain <- tail(airquality, 50)    x_train <- data_train[, x_var]   x_explain <- data_explain[, x_var]    # Fit a linear model   lm_formula <- as.formula(paste0(y_var, \" ~ \", paste0(x_var, collapse = \" + \")))   model <- lm(lm_formula, data = data_train)    # Explain predictions   p <- mean(data_train[, y_var])    # Empirical approach   x <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"empirical\",     phi0 = p,     n_MC_samples = 1e2   )    if (requireNamespace(c(\"ggplot2\", \"ggbeeswarm\"), quietly = TRUE)) {     # The default plotting option is a bar plot of the Shapley values     # We draw bar plots for the first 4 observations     plot(x, index_x_explain = 1:4)      # We can also make waterfall plots     plot(x, plot_type = \"waterfall\", index_x_explain = 1:4)     # And only showing the two features with the largest contributions     plot(x, plot_type = \"waterfall\", index_x_explain = 1:4, top_k_features = 2)      # Or scatter plots showing the distribution of the Shapley values and feature values     plot(x, plot_type = \"scatter\")     # And only for a specific feature     plot(x, plot_type = \"scatter\", scatter_features = \"Temp\")      # Or a beeswarm plot summarising the Shapley values and feature values for all features     plot(x, plot_type = \"beeswarm\")     plot(x, plot_type = \"beeswarm\", col = c(\"red\", \"black\")) # we can change colors      # Additional arguments can be passed to ggbeeswarm::geom_beeswarm() using the '...' argument.     # For instance, sometimes the beeswarm plots overlap too much.     # This can be fixed with the 'corral=\"wrap\" argument.     # See ?ggbeeswarm::geom_beeswarm for more information.     plot(x, plot_type = \"beeswarm\", corral = \"wrap\")   }    # Example of scatter and beeswarm plot with factor variables   airquality$Month_factor <- as.factor(month.abb[airquality$Month])   airquality <- airquality[complete.cases(airquality), ]   x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month_factor\")   y_var <- \"Ozone\"    # Split data into test- and training data   data_train <- airquality   data_explain <- tail(airquality, 50)    x_train <- data_train[, x_var]   x_explain <- data_explain[, x_var]    # Fit a linear model   lm_formula <- as.formula(paste0(y_var, \" ~ \", paste0(x_var, collapse = \" + \")))   model <- lm(lm_formula, data = data_train)    # Explain predictions   p <- mean(data_train[, y_var])    # Empirical approach   x <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"ctree\",     phi0 = p,     n_MC_samples = 1e2   )    if (requireNamespace(c(\"ggplot2\", \"ggbeeswarm\"), quietly = TRUE)) {     plot(x, plot_type = \"scatter\")     plot(x, plot_type = \"beeswarm\")   } } #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:24 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: empirical #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 50 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f123ca13689.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:31 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <lm> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 50 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f124b8255ae.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_MSEv_eval_crit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","title":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","text":"Make plots visualize compare MSEv evaluation criterion list explain() objects applied data model. function creates bar plots line plots points illustrate overall MSEv evaluation criterion, also observation/explicand coalition averaging coalitions observations/explicands, respectively.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_MSEv_eval_crit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","text":"","code":"plot_MSEv_eval_crit(   explanation_list,   index_x_explain = NULL,   id_coalition = NULL,   CI_level = if (length(explanation_list[[1]]$pred_explain) < 20) NULL else 0.95,   geom_col_width = 0.9,   plot_type = \"overall\" )"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_MSEv_eval_crit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","text":"explanation_list list explain() objects applied data model. entries list named, function use names. Otherwise, default approach names (integer suffix duplicates) explanation objects explanation_list. index_x_explain Integer vector. test observations plot. example, explained 10 observations using explain(), can generate plot first five observations setting index_x_explain = 1:5. id_coalition Integer vector. coalitions plot. E.g. used n_coalitions = 16 explain(), can generate plot first 5 coalitions 10th setting id_coalition = c(1:5, 10). CI_level Positive numeric zero one. Default 0.95 number observations explain larger 20, otherwise CI_level = NULL, removes confidence intervals. level approximate confidence intervals overall MSEv MSEv_coalition. confidence intervals based MSEv scores means observations/explicands, means approximation normal. Since standard deviations estimated, use quantile t T distribution N_explicands - 1 degrees freedom corresponding provided level. , N_explicands number observations/explicands. MSEv +/- tSD(MSEv)/sqrt(N_explicands). Note explain() function already scales standard deviation sqrt(N_explicands), thus, CI MSEv \\/- tMSEv_sd, values MSEv MSEv_sd extracted MSEv data.tables objects explanation_list. geom_col_width Numeric. Bar width. default, set 90% ggplot2::resolution() data. plot_type Character vector. possible options \"overall\" (default), \"comb\", \"explicand\". plot_type = \"overall\", plot (one bar plot) associated overall MSEv evaluation criterion method created, .e., averaging coalitions observations/explicands. plot_type = \"comb\", plots (one line plot one bar plot) associated MSEv evaluation criterion coalition created, .e., average observations/explicands. plot_type = \"explicand\", plots (one line plot one bar plot) associated MSEv evaluation criterion observations/explicands created, .e., average coalitions. plot_type vector one several \"overall\", \"comb\", \"explicand\", associated plots created.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_MSEv_eval_crit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","text":"Either single ggplot2::ggplot() object MSEv criterion plot_type = \"overall\", list ggplot2::ggplot() objects based plot_type parameter.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_MSEv_eval_crit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_MSEv_eval_crit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots of the MSEv Evaluation Criterion ‚Äî plot_MSEv_eval_crit","text":"","code":"# \\donttest{ if (requireNamespace(\"xgboost\", quietly = TRUE) && requireNamespace(\"ggplot2\", quietly = TRUE)) {   # Get the data   data(\"airquality\")   data <- data.table::as.data.table(airquality)   data <- data[complete.cases(data), ]    #' Define the features and the response   x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\")   y_var <- \"Ozone\"    # Split data into test and training data set   ind_x_explain <- 1:25   x_train <- data[-ind_x_explain, ..x_var]   y_train <- data[-ind_x_explain, get(y_var)]   x_explain <- data[ind_x_explain, ..x_var]    # Fitting a basic xgboost model to the training data   model <- xgboost::xgboost(     data = as.matrix(x_train),     label = y_train,     nround = 20,     verbose = FALSE   )    # Specifying the phi_0, i.e. the expected prediction without any features   phi0 <- mean(y_train)    # Independence approach   explanation_independence <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"independence\",     phi0 = phi0,     n_MC_samples = 1e2   )    # Gaussian 1e1 approach   explanation_gaussian_1e1 <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"gaussian\",     phi0 = phi0,     n_MC_samples = 1e1   )    # Gaussian 1e2 approach   explanation_gaussian_1e2 <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"gaussian\",     phi0 = phi0,     n_MC_samples = 1e2   )    # ctree approach   explanation_ctree <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"ctree\",     phi0 = phi0,     n_MC_samples = 1e2   )    # Combined approach   explanation_combined <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = c(\"gaussian\", \"independence\", \"ctree\"),     phi0 = phi0,     n_MC_samples = 1e2   )    # Create a list of explanations with names   explanation_list_named <- list(     \"Ind.\" = explanation_independence,     \"Gaus. 1e1\" = explanation_gaussian_1e1,     \"Gaus. 1e2\" = explanation_gaussian_1e2,     \"Ctree\" = explanation_ctree,     \"Combined\" = explanation_combined   )    # Create the default MSEv plot where we average over both the coalitions and observations   # with approximate 95% confidence intervals   plot_MSEv_eval_crit(explanation_list_named, CI_level = 0.95, plot_type = \"overall\")    # Can also create plots of the MSEv criterion averaged only over the coalitions or observations.   MSEv_figures <- plot_MSEv_eval_crit(explanation_list_named,     CI_level = 0.95,     plot_type = c(\"overall\", \"comb\", \"explicand\")   )   MSEv_figures$MSEv_bar   MSEv_figures$MSEv_coalition_bar   MSEv_figures$MSEv_explicand_bar    # When there are many coalitions or observations, then it can be easier to look at line plots   MSEv_figures$MSEv_coalition_line_point   MSEv_figures$MSEv_explicand_line_point    # We can specify which observations or coalitions to plot   plot_MSEv_eval_crit(explanation_list_named,     plot_type = \"explicand\",     index_x_explain = c(1, 3:4, 6),     CI_level = 0.95   )$MSEv_explicand_bar   plot_MSEv_eval_crit(explanation_list_named,     plot_type = \"comb\",     id_coalition = c(3, 4, 9, 13:15),     CI_level = 0.95   )$MSEv_coalition_bar    # We can alter the figures if other palette schemes or design is wanted   bar_text_n_decimals <- 1   MSEv_figures$MSEv_bar +     ggplot2::scale_x_discrete(limits = rev(levels(MSEv_figures$MSEv_bar$data$Method))) +     ggplot2::coord_flip() +     ggplot2::scale_fill_discrete() + #' Default ggplot2 palette     ggplot2::theme_minimal() + #' This must be set before the other theme call     ggplot2::theme(       plot.title = ggplot2::element_text(size = 10),       legend.position = \"bottom\"     ) +     ggplot2::guides(fill = ggplot2::guide_legend(nrow = 1, ncol = 6)) +     ggplot2::geom_text(       ggplot2::aes(label = sprintf(         paste(\"%.\", sprintf(\"%d\", bar_text_n_decimals), \"f\", sep = \"\"),         round(MSEv, bar_text_n_decimals)       )),       vjust = -1.1, # This value must be altered based on the plot dimension       hjust = 1.1, # This value must be altered based on the plot dimension       color = \"black\",       position = ggplot2::position_dodge(0.9),       size = 5     ) } #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:36 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: independence #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f124eadf7f8.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:37 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 10 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f12461a87c6.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:37 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f122294b109.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:38 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: ctree #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f1240378387.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.  #>  #> ‚îÄ‚îÄ Starting `shapr::explain()` at 2025-08-25 14:08:39 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ #> ‚Ñπ Feature classes extracted from the model contain `NA`. #>   Assuming feature classes from the data are correct. #> ‚Ñπ `max_n_coalitions` is `NULL` or larger than `2^n_features = 16`, and is #>   therefore set to `2^n_features = 16`. #>  #> ‚îÄ‚îÄ Explanation overview ‚îÄ‚îÄ #>  #> ‚Ä¢ Model class: <xgb.Booster> #> ‚Ä¢ v(S) estimation class: Monte Carlo integration #> ‚Ä¢ Approach: gaussian, independence, and ctree #> ‚Ä¢ Procedure: Non-iterative #> ‚Ä¢ Number of Monte Carlo integration samples: 100 #> ‚Ä¢ Number of feature-wise Shapley values: 4 #> ‚Ä¢ Number of observations to explain: 25 #> ‚Ä¢ Computations (temporary) saved at: /tmp/Rtmp1me5uE/shapr_obj_1f123255fe1a.rds #>  #> ‚îÄ‚îÄ Main computation started ‚îÄ‚îÄ #>  #> ‚Ñπ Using 16 of 16 coalitions.   # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_SV_several_approaches.html","id":null,"dir":"Reference","previous_headings":"","what":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","title":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","text":"Make plots visualize compare estimated Shapley values list explain() objects applied data model. group-wise Shapley values, features values plotted mean feature values features group.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_SV_several_approaches.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","text":"","code":"plot_SV_several_approaches(   explanation_list,   index_explicands = NULL,   index_explicands_sort = FALSE,   only_these_features = NULL,   plot_phi0 = FALSE,   digits = 4,   add_zero_line = FALSE,   axis_labels_n_dodge = NULL,   axis_labels_rotate_angle = NULL,   horizontal_bars = TRUE,   facet_scales = \"free\",   facet_ncol = 2,   geom_col_width = 0.85,   brewer_palette = NULL,   include_group_feature_means = FALSE )"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_SV_several_approaches.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","text":"explanation_list list explain() objects applied data model. entries list named, function use names. Otherwise, default approach names (integer suffix duplicates) explanation objects explanation_list. index_explicands Integer vector. explicands (test observations) plot. E.g. explained 10 observations using explain(), can generate plot first 5 observations/explicands 10th setting index_x_explain = c(1:5, 10). argument index_explicands_sort must FALSE plot explicand order specified index_x_explain. index_explicands_sort Boolean. FALSE (default), shapr plots explicands order specified index_explicands. TRUE, shapr sort indices increasing order based id. only_these_features String vector. Containing names features included bar plots. plot_phi0 Boolean. include \\(\\phi_0\\) bar plots . digits Integer. Number significant digits use feature description. Applicable plot_type \"bar\" \"waterfall\" add_zero_line Boolean. add black line feature contribution 0. axis_labels_n_dodge Integer. number rows used render labels. useful displaying labels otherwise overlap. axis_labels_rotate_angle Numeric. angle axis label, 0 means horizontal, 45 means tilted, 90 means vertical. Compared setting angle ggplot2::theme() / ggplot2::element_text(), also uses heuristics automatically pick hjust vjust probably want. horizontal_bars Boolean. Flip Cartesian coordinates horizontal becomes vertical, vertical, horizontal. primarily useful converting geoms statistics display y conditional x, x conditional y. See ggplot2::coord_flip(). facet_scales scales free (\"free\", default), fixed (\"fixed\"), free one dimension (\"free_x\", \"free_y\")? user change latter manually depending value horizontal_bars. facet_ncol Integer. number columns facet grid. Default facet_ncol = 2. geom_col_width Numeric. Bar width. default, set 85% ggplot2::resolution() data. brewer_palette String. Name one color palettes RColorBrewer::RColorBrewer(). NULL, function uses default ggplot2::ggplot() color scheme. following palettes available use scales: Diverging BrBG, PiYG, PRGn, PuOr, RdBu, RdGy, RdYlBu, RdYlGn, Spectral Qualitative Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3 Sequential Blues, BuGn, BuPu, GnBu, Greens, Greys, Oranges, OrRd, PuBu, PuBuGn, PuRd, Purples, RdPu, Reds, YlGn, YlGnBu, YlOrBr, YlOrRd include_group_feature_means Logical. Whether include average feature value group y-axis . FALSE (default), value shown groups. TRUE, shapr includes mean features group.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_SV_several_approaches.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","text":"ggplot2::ggplot() object.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_SV_several_approaches.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_SV_several_approaches.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Shapley value bar plots for several explanation objects ‚Äî plot_SV_several_approaches","text":"","code":"if (FALSE) { # \\dontrun{ if (requireNamespace(\"xgboost\", quietly = TRUE) && requireNamespace(\"ggplot2\", quietly = TRUE)) {   # Get the data   data(\"airquality\")   data <- data.table::as.data.table(airquality)   data <- data[complete.cases(data), ]    # Define the features and the response   x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\")   y_var <- \"Ozone\"    # Split data into test and training data set   ind_x_explain <- 1:12   x_train <- data[-ind_x_explain, ..x_var]   y_train <- data[-ind_x_explain, get(y_var)]   x_explain <- data[ind_x_explain, ..x_var]    # Fitting a basic xgboost model to the training data   model <- xgboost::xgboost(     data = as.matrix(x_train),     label = y_train,     nround = 20,     verbose = FALSE   )    # Specifying the phi_0, i.e. the expected prediction without any features   phi0 <- mean(y_train)    # Independence approach   explanation_independence <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"independence\",     phi0 = phi0,     n_MC_samples = 1e2   )    # Empirical approach   explanation_empirical <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"empirical\",     phi0 = phi0,     n_MC_samples = 1e2   )    # Gaussian 1e1 approach   explanation_gaussian_1e1 <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"gaussian\",     phi0 = phi0,     n_MC_samples = 1e1   )    # Gaussian 1e2 approach   explanation_gaussian_1e2 <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"gaussian\",     phi0 = phi0,     n_MC_samples = 1e2   )    # Combined approach   explanation_combined <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = c(\"gaussian\", \"ctree\", \"empirical\"),     phi0 = phi0,     n_MC_samples = 1e2   )    # Create a list of explanations with names   explanation_list <- list(     \"Ind.\" = explanation_independence,     \"Emp.\" = explanation_empirical,     \"Gaus. 1e1\" = explanation_gaussian_1e1,     \"Gaus. 1e2\" = explanation_gaussian_1e2,     \"Combined\" = explanation_combined   )    # The function uses the provided names.   plot_SV_several_approaches(explanation_list)    # We can change the number of columns in the grid of plots and add other visual alterations   plot_SV_several_approaches(explanation_list,     facet_ncol = 3,     facet_scales = \"free_y\",     add_zero_line = TRUE,     digits = 2,     brewer_palette = \"Paired\",     geom_col_width = 0.6   ) +     ggplot2::theme_minimal() +     ggplot2::theme(legend.position = \"bottom\", plot.title = ggplot2::element_text(size = 0))     # We can specify which explicands to plot to get less chaotic plots and make the bars vertical   plot_SV_several_approaches(explanation_list,     index_explicands = c(1:2, 5, 10),     horizontal_bars = FALSE,     axis_labels_rotate_angle = 45   )    # We can change the order of the features by specifying the   # order using the `only_these_features` parameter.   plot_SV_several_approaches(explanation_list,     index_explicands = c(1:2, 5, 10),     only_these_features = c(\"Temp\", \"Solar.R\", \"Month\", \"Wind\")   )    # We can also remove certain features if we are not interested in them   # or want to focus on, e.g., two features. The function will give a   # message to if the user specifies non-valid feature names.   plot_SV_several_approaches(explanation_list,     index_explicands = c(1:2, 5, 10),     only_these_features = c(\"Temp\", \"Solar.R\"),     plot_phi0 = TRUE   ) } } # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"function makes (ggplot2::ggplot()) figures training VLB validation IWAE list explain() objects approach = \"vaeac\". See setup_approach() information vaeac approach. Two figures returned function. figure, object explanation_list gets facet, second figure, plot criteria facet objects.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"","code":"plot_vaeac_eval_crit(   explanation_list,   plot_from_nth_epoch = 1,   plot_every_nth_epoch = 1,   criteria = c(\"VLB\", \"IWAE\"),   plot_type = c(\"method\", \"criterion\"),   facet_wrap_scales = \"fixed\",   facet_wrap_ncol = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"explanation_list list explain() objects applied data, model, vaeac must used approach. entries list named, function use names. Otherwise, defaults approach names (integer suffix duplicates) explanation objects explanation_list. plot_from_nth_epoch Integer. plot results form nth epoch forth. first epochs can large absolute value make rest plot difficult interpret. plot_every_nth_epoch Integer. plot every nth epoch. Usefully illustrate overall trend, can lot fluctuation oscillation values epoch. criteria Character vector. possible options \"VLB\", \"IWAE\", \"IWAE_running\". Default first two. plot_type Character vector. possible options \"method\" \"criterion\". Default plot . facet_wrap_scales String. scales fixed (\"fixed\", default), free (\"free\"), free one dimension (\"free_x\", \"free_y\"). facet_wrap_ncol Integer. Number columns facet wrap.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"Either single ggplot2::ggplot() object list ggplot2::ggplot() objects based plot_type parameter.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"See Olsen et al. (2022) blog post summary VLB IWAE.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_eval_crit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the training VLB and validation IWAE for vaeac models ‚Äî plot_vaeac_eval_crit","text":"","code":"# \\donttest{  if (requireNamespace(\"xgboost\", quietly = TRUE) &&   requireNamespace(\"torch\", quietly = TRUE) &&   torch::torch_is_installed()) {   data(\"airquality\")   data <- data.table::as.data.table(airquality)   data <- data[complete.cases(data), ]    x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\")   y_var <- \"Ozone\"    ind_x_explain <- 1:6   x_train <- data[-ind_x_explain, ..x_var]   y_train <- data[-ind_x_explain, get(y_var)]   x_explain <- data[ind_x_explain, ..x_var]    # Fitting a basic xgboost model to the training data   model <- xgboost::xgboost(     data = as.matrix(x_train),     label = y_train,     nround = 100,     verbose = FALSE   )    # Specifying the phi_0, i.e. the expected prediction without any features   p0 <- mean(y_train)    # Train vaeac with and without paired sampling   explanation_paired <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"vaeac\",     phi0 = p0,     n_MC_samples = 1, # As we are only interested in the training of the vaeac     vaeac.epochs = 10, # Should be higher in applications.     vaeac.n_vaeacs_initialize = 1,     vaeac.width = 16,     vaeac.depth = 2,     vaeac.extra_parameters = list(vaeac.paired_sampling = TRUE)   )    explanation_regular <- explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"vaeac\",     phi0 = p0,     n_MC_samples = 1, # As we are only interested in the training of the vaeac     vaeac.epochs = 10, # Should be higher in applications.     vaeac.width = 16,     vaeac.depth = 2,     vaeac.n_vaeacs_initialize = 1,     vaeac.extra_parameters = list(vaeac.paired_sampling = FALSE)   )    # Collect the explanation objects in an named list   explanation_list <- list(     \"Regular sampling\" = explanation_regular,     \"Paired sampling\" = explanation_paired   )    # Call the function with the named list, will use the provided names   plot_vaeac_eval_crit(explanation_list = explanation_list)    # The function also works if we have only one method,   # but then one should only look at the method plot.   plot_vaeac_eval_crit(     explanation_list = explanation_list[2],     plot_type = \"method\"   )    # Can alter the plot   plot_vaeac_eval_crit(     explanation_list = explanation_list,     plot_from_nth_epoch = 2,     plot_every_nth_epoch = 2,     facet_wrap_scales = \"free\"   )    # If we only want the VLB   plot_vaeac_eval_crit(     explanation_list = explanation_list,     criteria = \"VLB\",     plot_type = \"criterion\"   )    # If we want only want the criterion version   tmp_fig_criterion <-     plot_vaeac_eval_crit(explanation_list = explanation_list, plot_type = \"criterion\")    # Since tmp_fig_criterion is a ggplot2 object, we can alter it   # by, e.g,. adding points or smooths with se bands   tmp_fig_criterion + ggplot2::geom_point(shape = \"circle\", size = 1, ggplot2::aes(col = Method))   tmp_fig_criterion$layers[[1]] <- NULL   tmp_fig_criterion + ggplot2::geom_smooth(method = \"loess\", formula = y ~ x, se = TRUE) +     ggplot2::scale_color_brewer(palette = \"Set1\") +     ggplot2::theme_minimal() } # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"function creates matrix plots (GGally::ggpairs()) generated imputations unconditioned distribution \\(p(\\boldsymbol{x})\\) estimated vaeac model, compares imputed values data true distribution (provided). See ggpairs introduction GGally::ggpairs(), corresponding vignette.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"","code":"plot_vaeac_imputed_ggpairs(   explanation,   which_vaeac_model = \"best\",   x_true = NULL,   add_title = TRUE,   alpha = 0.5,   upper_cont = c(\"cor\", \"points\", \"smooth\", \"smooth_loess\", \"density\", \"blank\"),   upper_cat = c(\"count\", \"cross\", \"ratio\", \"facetbar\", \"blank\"),   upper_mix = c(\"box\", \"box_no_facet\", \"dot\", \"dot_no_facet\", \"facethist\",     \"facetdensity\", \"denstrip\", \"blank\"),   lower_cont = c(\"points\", \"smooth\", \"smooth_loess\", \"density\", \"cor\", \"blank\"),   lower_cat = c(\"facetbar\", \"ratio\", \"count\", \"cross\", \"blank\"),   lower_mix = c(\"facetdensity\", \"box\", \"box_no_facet\", \"dot\", \"dot_no_facet\",     \"facethist\", \"denstrip\", \"blank\"),   diag_cont = c(\"densityDiag\", \"barDiag\", \"blankDiag\"),   diag_cat = c(\"barDiag\", \"blankDiag\"),   cor_method = c(\"pearson\", \"kendall\", \"spearman\") )"},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"explanation Shapr list. output list explain() function. which_vaeac_model String. Indicating vaeac model use generating samples. Possible options always 'best', 'best_running', 'last'. possible options can obtained calling names(explanation$internal$parameters$vaeac$models). x_true Data.table containing data distribution vaeac model fitted . add_title Logical. TRUE, title added plot based internal description vaeac model specified which_vaeac_model. alpha Numeric 0 1 (default 0.5). degree color transparency. upper_cont String. Type plot use upper triangle continuous features, see GGally::ggpairs(). Possible options : 'cor' (default), 'points', 'smooth', 'smooth_loess', 'density', 'blank'. upper_cat String. Type plot use upper triangle categorical features, see GGally::ggpairs(). Possible options : 'count' (default), 'cross', 'ratio', 'facetbar', 'blank'. upper_mix String. Type plot use upper triangle mixed features, see GGally::ggpairs(). Possible options : 'box' (default), 'box_no_facet', 'dot', 'dot_no_facet', 'facethist', 'facetdensity', 'denstrip', 'blank' lower_cont String. Type plot use lower triangle continuous features, see GGally::ggpairs(). Possible options : 'points' (default), 'smooth', 'smooth_loess', 'density', 'cor', 'blank'. lower_cat String. Type plot use lower triangle categorical features, see GGally::ggpairs(). Possible options : 'facetbar' (default), 'ratio', 'count', 'cross', 'blank'. lower_mix String. Type plot use lower triangle mixed features, see GGally::ggpairs(). Possible options : 'facetdensity' (default), 'box', 'box_no_facet', 'dot', 'dot_no_facet', 'facethist', 'denstrip', 'blank'. diag_cont String. Type plot use diagonal continuous features, see GGally::ggpairs(). Possible options : 'densityDiag' (default), 'barDiag', 'blankDiag'. diag_cat String. Type plot use diagonal categorical features, see GGally::ggpairs(). Possible options : 'barDiag' (default) 'blankDiag'. cor_method String. Type correlation measure, see GGally::ggpairs(). Possible options : 'pearson' (default), 'kendall', 'spearman'.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"GGally::ggpairs() figure.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/plot_vaeac_imputed_ggpairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Pairwise Plots for Imputed and True Data ‚Äî plot_vaeac_imputed_ggpairs","text":"","code":"# \\donttest{  if (requireNamespace(\"xgboost\", quietly = TRUE) &&   requireNamespace(\"ggplot2\", quietly = TRUE) &&   requireNamespace(\"torch\", quietly = TRUE) &&   torch::torch_is_installed()) {   data(\"airquality\")   data <- data.table::as.data.table(airquality)   data <- data[complete.cases(data), ]    x_var <- c(\"Solar.R\", \"Wind\", \"Temp\", \"Month\")   y_var <- \"Ozone\"    ind_x_explain <- 1:6   x_train <- data[-ind_x_explain, ..x_var]   y_train <- data[-ind_x_explain, get(y_var)]   x_explain <- data[ind_x_explain, ..x_var]    # Fitting a basic xgboost model to the training data   model <- xgboost::xgboost(     data = as.matrix(x_train),     label = y_train,     nround = 100,     verbose = FALSE   )    explanation <- shapr::explain(     model = model,     x_explain = x_explain,     x_train = x_train,     approach = \"vaeac\",     phi0 = mean(y_train),     n_MC_samples = 1,     vaeac.epochs = 10,     vaeac.n_vaeacs_initialize = 1   )    # Plot the results   figure <- shapr::plot_vaeac_imputed_ggpairs(     explanation = explanation,     which_vaeac_model = \"best\",     x_true = x_train,     add_title = TRUE   )   figure    # Note that this is an ggplot2 object which we can alter, e.g., we can change the colors.   figure +     ggplot2::scale_color_manual(values = c(\"#E69F00\", \"#999999\")) +     ggplot2::scale_fill_manual(values = c(\"#E69F00\", \"#999999\")) } # }"},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate predictions for input data with specified model ‚Äî predict_model","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"Performs prediction response stats::lm(), stats::glm(), ranger::ranger(), mgcv::gam(), workflows::workflow() (.e., tidymodels models), xgboost::xgb.train() binary continuous response. See details information.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"","code":"predict_model(x, newdata, ...)  # Default S3 method predict_model(x, newdata, ...)  # S3 method for class 'ar' predict_model(x, newdata, newreg, horizon, ...)  # S3 method for class 'Arima' predict_model(   x,   newdata,   newreg,   horizon,   explain_idx,   explain_lags,   y,   xreg,   ... )  # S3 method for class 'forecast_ARIMA' predict_model(x, newdata, newreg, horizon, ...)  # S3 method for class 'glm' predict_model(x, newdata, ...)  # S3 method for class 'lm' predict_model(x, newdata, ...)  # S3 method for class 'gam' predict_model(x, newdata, ...)  # S3 method for class 'ranger' predict_model(x, newdata, ...)  # S3 method for class 'workflow' predict_model(x, newdata, ...)  # S3 method for class 'xgb.Booster' predict_model(x, newdata, ...)"},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"x Model object model explained. newdata data.frame/data.table features predict . ... newreg horizon parameters used models passed [explain_forecast()] horizon Numeric. forecast horizon explain. Passed predict_model function. explain_idx Numeric vector. row indices data reg denoting points time explain. y Matrix, data.frame/data.table numeric vector. Contains endogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. xreg Matrix, data.frame/data.table numeric vector. Contains exogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. exogenous variables used contemporaneously producing forecast, item contain nrow(y) + horizon rows.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"Numeric. Vector size equal number rows newdata.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"following models currently supported: stats::lm() stats::glm() ranger::ranger() mgcv::gam() workflows::workflow() xgboost::xgb.train() binary classification model always return probability prediction single class. explaining model supported natively, need create [predict_model()] function , pass argument [explain()]. details explain non-supported models (.e. custom models), see Advanced usage section general usage:  R: vignette(\"general_usage\", package = \"shapr\")   Web: https://norskregnesentral.github.io/shapr/articles/general_usage.html#explain-custom-models","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/predict_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate predictions for input data with specified model ‚Äî predict_model","text":"","code":"# Load example data data(\"airquality\") airquality <- airquality[complete.cases(airquality), ] # Split data into test- and training data x_train <- head(airquality, -3) x_explain <- tail(airquality, 3) # Fit a linear model model <- lm(Ozone ~ Solar.R + Wind + Temp + Month, data = x_train)  # Predicting for a model with a standardized format predict_model(x = model, newdata = x_explain) #>      151      152      153  #> 17.75241 37.75649 15.67266"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data used for predictions and Monte Carlo integration ‚Äî prepare_data","title":"Generate data used for predictions and Monte Carlo integration ‚Äî prepare_data","text":"Generate data used predictions Monte Carlo integration","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data used for predictions and Monte Carlo integration ‚Äî prepare_data","text":"","code":"prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'categorical' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'copula' prepare_data(internal, index_features, ...)  # S3 method for class 'ctree' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'empirical' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'gaussian' prepare_data(internal, index_features, ...)  # S3 method for class 'independence' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'regression_separate' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'regression_surrogate' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'timeseries' prepare_data(internal, index_features = NULL, ...)  # S3 method for class 'vaeac' prepare_data(internal, index_features = NULL, ...)"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data used for predictions and Monte Carlo integration ‚Äî prepare_data","text":"internal List. used directly, passed explain(). index_features Positive integer vector. Specifies id_coalition apply present method. NULL means coalitions. used internally. ... Currently used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate data used for predictions and Monte Carlo integration ‚Äî prepare_data","text":"data.table containing simulated data used estimate contribution function Monte Carlo integration.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate data used for predictions and Monte Carlo integration ‚Äî prepare_data","text":"Martin Jullum Annabelle Redelmeier Lars Henry Berge Olsen Lars Henry Berge Olsen Martin Jullum,","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_causal.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data used for predictions and Monte Carlo integration for causal Shapley values ‚Äî prepare_data_causal","title":"Generate data used for predictions and Monte Carlo integration for causal Shapley values ‚Äî prepare_data_causal","text":"function loops given coalitions, coalition extracts chain relevant sampling steps provided internal$object$S_causal. chain can contain sampling marginal conditional distributions. use approach given internal$parameters$approach generate samples conditional distributions, iteratively call prepare_data() modified internal_copy list reuse code. However, also means chains conditional distributions retrain model said conditional distributions several times. marginal distribution, sample Gaussian marginals approach gaussian marginals training data approaches. Note extend code sample marginal (gaussian) copula, , approach copula.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_causal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data used for predictions and Monte Carlo integration for causal Shapley values ‚Äî prepare_data_causal","text":"","code":"prepare_data_causal(internal, index_features = NULL, ...)"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_causal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data used for predictions and Monte Carlo integration for causal Shapley values ‚Äî prepare_data_causal","text":"internal List. used directly, passed explain(). index_features Positive integer vector. Specifies id_coalition apply present method. NULL means coalitions. used internally. ... Currently used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_causal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate data used for predictions and Monte Carlo integration for causal Shapley values ‚Äî prepare_data_causal","text":"data.table containing simulated data respects (partial) causal ordering confounding assumptions. data used estimate contribution function Monte Carlo integration.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_causal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate data used for predictions and Monte Carlo integration for causal Shapley values ‚Äî prepare_data_causal","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate (Gaussian) Copula MC samples ‚Äî prepare_data_copula_cpp","title":"Generate (Gaussian) Copula MC samples ‚Äî prepare_data_copula_cpp","text":"Generate (Gaussian) Copula MC samples","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate (Gaussian) Copula MC samples ‚Äî prepare_data_copula_cpp","text":"","code":"prepare_data_copula_cpp(   MC_samples_mat,   x_explain_mat,   x_explain_gaussian_mat,   x_train_mat,   S,   mu,   cov_mat )"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate (Gaussian) Copula MC samples ‚Äî prepare_data_copula_cpp","text":"MC_samples_mat arma::mat. Matrix dimension (n_MC_samples, n_features) containing samples univariate standard normal. x_explain_mat arma::mat. Matrix dimension (n_explain, n_features) containing observations explain. x_explain_gaussian_mat arma::mat. Matrix dimension (n_explain, n_features) containing observations explain transformed using Gaussian transform, .e., samples transformed standardized normal distribution. x_train_mat arma::mat. Matrix dimension (n_train, n_features) containing training observations. S arma::mat. Matrix dimension (n_coalitions, n_features) containing binary representations used coalitions. S contain empty grand coalition, .e., row containing zeros ones. problem internally shapr empty grand coalitions treated differently. mu arma::vec. Vector length n_features containing mean feature transformed using Gaussian transform, .e., samples transformed standardized normal distribution. cov_mat arma::mat. Matrix dimension (n_features, n_features) containing pairwise covariance pairs features transformed using Gaussian transform, .e., samples transformed standardized normal distribution.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate (Gaussian) Copula MC samples ‚Äî prepare_data_copula_cpp","text":"arma::cube/3D array dimension (n_MC_samples, n_explain * n_coalitions, n_features), columns (,j,) matrices dimension (n_MC_samples, n_features) containing conditional Gaussian copula MC samples explicand coalition original scale.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate (Gaussian) Copula MC samples ‚Äî prepare_data_copula_cpp","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp_caus.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate (Gaussian) Copula MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_copula_cpp_caus","title":"Generate (Gaussian) Copula MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_copula_cpp_caus","text":"Generate (Gaussian) Copula MC samples causal setup single MC sample explicand","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp_caus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate (Gaussian) Copula MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_copula_cpp_caus","text":"","code":"prepare_data_copula_cpp_caus(   MC_samples_mat,   x_explain_mat,   x_explain_gaussian_mat,   x_train_mat,   S,   mu,   cov_mat )"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp_caus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate (Gaussian) Copula MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_copula_cpp_caus","text":"MC_samples_mat arma::mat. Matrix dimension (n_MC_samples, n_features) containing samples univariate standard normal. x_explain_mat arma::mat. Matrix dimension (n_explain, n_features) containing observations explain. x_explain_gaussian_mat arma::mat. Matrix dimension (n_explain, n_features) containing observations explain transformed using Gaussian transform, .e., samples transformed standardized normal distribution. x_train_mat arma::mat. Matrix dimension (n_train, n_features) containing training observations. S arma::mat. Matrix dimension (n_coalitions, n_features) containing binary representations used coalitions. S contain empty grand coalition, .e., row containing zeros ones. problem internally shapr empty grand coalitions treated differently. mu arma::vec. Vector length n_features containing mean feature transformed using Gaussian transform, .e., samples transformed standardized normal distribution. cov_mat arma::mat. Matrix dimension (n_features, n_features) containing pairwise covariance pairs features transformed using Gaussian transform, .e., samples transformed standardized normal distribution.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp_caus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate (Gaussian) Copula MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_copula_cpp_caus","text":"arma::cube/3D array dimension (n_MC_samples, n_explain * n_coalitions, n_features), columns (,j,) matrices dimension (n_MC_samples, n_features) containing conditional Gaussian copula MC samples explicand coalition original scale.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_copula_cpp_caus.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate (Gaussian) Copula MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_copula_cpp_caus","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Gaussian MC samples ‚Äî prepare_data_gaussian_cpp","title":"Generate Gaussian MC samples ‚Äî prepare_data_gaussian_cpp","text":"Generate Gaussian MC samples","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Gaussian MC samples ‚Äî prepare_data_gaussian_cpp","text":"","code":"prepare_data_gaussian_cpp(MC_samples_mat, x_explain_mat, S, mu, cov_mat)"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Gaussian MC samples ‚Äî prepare_data_gaussian_cpp","text":"MC_samples_mat arma::mat. Matrix dimension (n_MC_samples, n_features) containing samples univariate standard normal. x_explain_mat arma::mat. Matrix dimension (n_explain, n_features) containing observations explain. S arma::mat. Matrix dimension (n_coalitions, n_features) containing binary representations used coalitions. S contain empty grand coalition, .e., row containing zeros ones. problem internally shapr empty grand coalitions treated differently. mu arma::vec. Vector length n_features containing mean feature. cov_mat arma::mat. Matrix dimension (n_features, n_features) containing covariance matrix features.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Gaussian MC samples ‚Äî prepare_data_gaussian_cpp","text":"arma::cube/3D array dimension (n_MC_samples, n_explain * n_coalitions, n_features), columns (,j,) matrices dimension (n_MC_samples, n_features) containing conditional Gaussian MC samples explicand coalition.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate Gaussian MC samples ‚Äî prepare_data_gaussian_cpp","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp_caus.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Gaussian MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_gaussian_cpp_caus","title":"Generate Gaussian MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_gaussian_cpp_caus","text":"Generate Gaussian MC samples causal setup single MC sample explicand","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp_caus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Gaussian MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_gaussian_cpp_caus","text":"","code":"prepare_data_gaussian_cpp_caus(MC_samples_mat, x_explain_mat, S, mu, cov_mat)"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp_caus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Gaussian MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_gaussian_cpp_caus","text":"MC_samples_mat arma::mat. Matrix dimension (n_MC_samples, n_features) containing samples univariate standard normal. x_explain_mat arma::mat. Matrix dimension (n_explain, n_features) containing observations explain. S arma::mat. Matrix dimension (n_coalitions, n_features) containing binary representations used coalitions. S contain empty grand coalition, .e., row containing zeros ones. problem internally shapr empty grand coalitions treated differently. mu arma::vec. Vector length n_features containing mean feature. cov_mat arma::mat. Matrix dimension (n_features, n_features) containing covariance matrix features.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp_caus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Gaussian MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_gaussian_cpp_caus","text":"arma::cube/3D array dimension (n_MC_samples, n_explain * n_coalitions, n_features), columns (,j,) matrices dimension (n_MC_samples, n_features) containing conditional Gaussian MC samples explicand coalition.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_gaussian_cpp_caus.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generate Gaussian MC samples for the causal setup with a single MC sample for each explicand ‚Äî prepare_data_gaussian_cpp_caus","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_single_coalition.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the conditional probabilities for a single coalition for the categorical approach ‚Äî prepare_data_single_coalition","title":"Compute the conditional probabilities for a single coalition for the categorical approach ‚Äî prepare_data_single_coalition","text":"prepare_data.categorical() function slow evaluated single coalition. bottleneck Causal Shapley values call said function lot single coalitions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_single_coalition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the conditional probabilities for a single coalition for the categorical approach ‚Äî prepare_data_single_coalition","text":"","code":"prepare_data_single_coalition(internal, index_features)"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_single_coalition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the conditional probabilities for a single coalition for the categorical approach ‚Äî prepare_data_single_coalition","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_data_single_coalition.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the conditional probabilities for a single coalition for the categorical approach ‚Äî prepare_data_single_coalition","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_next_iteration.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepares the next iteration of the iterative sampling algorithm ‚Äî prepare_next_iteration","title":"Prepares the next iteration of the iterative sampling algorithm ‚Äî prepare_next_iteration","text":"Prepares next iteration iterative sampling algorithm","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_next_iteration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepares the next iteration of the iterative sampling algorithm ‚Äî prepare_next_iteration","text":"","code":"prepare_next_iteration(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_next_iteration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepares the next iteration of the iterative sampling algorithm ‚Äî prepare_next_iteration","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/prepare_next_iteration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepares the next iteration of the iterative sampling algorithm ‚Äî prepare_next_iteration","text":"(updated) internal list","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/print.shapr.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for shapr objects ‚Äî print.shapr","title":"Print method for shapr objects ‚Äî print.shapr","text":"Print method shapr objects","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/print.shapr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for shapr objects ‚Äî print.shapr","text":"","code":"# S3 method for class 'shapr' print(   x,   what = c(\"shapley_est\", \"shapley_sd\", \"MSEv\", \"MSEv_explicand\", \"MSEv_coalition\",     \"timing_summary\"),   digits = 3L,   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/print.shapr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for shapr objects ‚Äî print.shapr","text":"x shapr object Character. component print. Options \"shapley_est\", \"shapley_sd\", \"MSEv\", \"MSEv_explicand\", \"MSEv_coalition\", \"timing_summary\". Defaults \"shapley_est\". one component can printed time. See details section get_results() details component. digits Integer. Number significant digits display. Defaults 3. ... arguments passed data.table::print.data.table().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/print.shapr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for shapr objects ‚Äî print.shapr","text":"object returned invisibly printing selected output.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/print_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints iterative information ‚Äî print_iter","title":"Prints iterative information ‚Äî print_iter","text":"Prints iterative information","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/print_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints iterative information ‚Äî print_iter","text":"","code":"print_iter(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/print_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints iterative information ‚Äî print_iter","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/print_iter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints iterative information ‚Äî print_iter","text":"return value (prints iterative information)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/process_factor_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Treat factors as numeric values ‚Äî process_factor_data","title":"Treat factors as numeric values ‚Äî process_factor_data","text":"Factors given numeric value highest numeric value data. value different levels sorted factor level.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/process_factor_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Treat factors as numeric values ‚Äî process_factor_data","text":"","code":"process_factor_data(dt, factor_cols)"},{"path":"https://norskregnesentral.github.io/shapr/reference/process_factor_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Treat factors as numeric values ‚Äî process_factor_data","text":"dt data.table plot factor_cols Columns factors character","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/process_factor_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Treat factors as numeric values ‚Äî process_factor_data","text":"list lookup table factor level numeric value, data.table similar input data, now numeric values factors, maximum feature value.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/quantile_type7_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","title":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","text":"Compute quantiles using quantile type seven","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/quantile_type7_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","text":"","code":"quantile_type7_cpp(x, probs)"},{"path":"https://norskregnesentral.github.io/shapr/reference/quantile_type7_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","text":"x arma::vec. Numeric vector whose sample quantiles wanted. probs arma::vec. Numeric vector probabilities values zero one.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/quantile_type7_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","text":"vector length length(probs) quantiles returned.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/quantile_type7_cpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","text":"Using quantile type number seven stats::quantile R.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/quantile_type7_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the quantiles using quantile type seven ‚Äî quantile_type7_cpp","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/reg_forecast_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up exogenous regressors for explanation in a forecast model. ‚Äî reg_forecast_setup","title":"Set up exogenous regressors for explanation in a forecast model. ‚Äî reg_forecast_setup","text":"Set exogenous regressors explanation forecast model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/reg_forecast_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up exogenous regressors for explanation in a forecast model. ‚Äî reg_forecast_setup","text":"","code":"reg_forecast_setup(x, horizon, group)"},{"path":"https://norskregnesentral.github.io/shapr/reference/reg_forecast_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up exogenous regressors for explanation in a forecast model. ‚Äî reg_forecast_setup","text":"x matrix exogenous variables. horizon Numeric. forecast horizon explain. Passed predict_model function. group list endogenous groups, append exogenous groups .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/reg_forecast_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up exogenous regressors for explanation in a forecast model. ‚Äî reg_forecast_setup","text":"list containing fcast matrix containing exogenous observations needed observation. group list group exogenous groups appended.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_namespaces.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that needed libraries are installed ‚Äî regression.check_namespaces","title":"Check that needed libraries are installed ‚Äî regression.check_namespaces","text":"function checks parsnip, recipes, workflows, tune, dials, yardstick, hardhat rsample, packages available.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_namespaces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that needed libraries are installed ‚Äî regression.check_namespaces","text":"","code":"regression.check_namespaces()"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_namespaces.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check that needed libraries are installed ‚Äî regression.check_namespaces","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Check regression parameters ‚Äî regression.check_parameters","title":"Check regression parameters ‚Äî regression.check_parameters","text":"Check regression parameters","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check regression parameters ‚Äî regression.check_parameters","text":"","code":"regression.check_parameters(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check regression parameters ‚Äî regression.check_parameters","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check regression parameters ‚Äî regression.check_parameters","text":"internal list, added logical indicator internal$parameters$regression.tune tune regression model/models.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_parameters.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check regression parameters ‚Äî regression.check_parameters","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_recipe_func.html","id":null,"dir":"Reference","previous_headings":"","what":"Check regression.recipe_func ‚Äî regression.check_recipe_func","title":"Check regression.recipe_func ‚Äî regression.check_recipe_func","text":"Check regression.recipe_func function returns RHS formula arbitrary feature name inputs.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_recipe_func.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check regression.recipe_func ‚Äî regression.check_recipe_func","text":"","code":"regression.check_recipe_func(regression.recipe_func, x_explain)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_recipe_func.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check regression.recipe_func ‚Äî regression.check_recipe_func","text":"regression.recipe_func Either NULL (default) function takes recipes::recipe() object returns modified recipes::recipe() potentially additional recipe steps. See regression vignette several examples. Note, make easier call explain() Python, regression.recipe_func can also string containing R function. example, \"function(recipe) return(recipes::step_ns(recipe, recipes::all_numeric_predictors(), deg_free = 2))\" also valid input. essential include package prefix package loaded. x_explain Data.table features observation whose predictions explained (test data).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_recipe_func.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check regression.recipe_func ‚Äî regression.check_recipe_func","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_sur_n_comb.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the regression.surrogate_n_comb parameter ‚Äî regression.check_sur_n_comb","title":"Check the regression.surrogate_n_comb parameter ‚Äî regression.check_sur_n_comb","text":"Check regression.surrogate_n_comb either NULL valid integer.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_sur_n_comb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the regression.surrogate_n_comb parameter ‚Äî regression.check_sur_n_comb","text":"","code":"regression.check_sur_n_comb(regression.surrogate_n_comb, n_coalitions)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_sur_n_comb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the regression.surrogate_n_comb parameter ‚Äî regression.check_sur_n_comb","text":"regression.surrogate_n_comb Positive integer. Specifies number unique coalitions apply training observation. default number sampled coalitions present iteration. integer 1 default allowed. Larger values requires memory, may improve surrogate model. user sets value lower maximum, sample amount unique coalitions separately training observations. , average, coalitions equally trained. n_coalitions Integer. number used coalitions (including empty grand coalition).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_sur_n_comb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check the regression.surrogate_n_comb parameter ‚Äî regression.check_sur_n_comb","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_vfold_cv_para.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the parameters that are sent to rsample::vfold_cv() ‚Äî regression.check_vfold_cv_para","title":"Check the parameters that are sent to rsample::vfold_cv() ‚Äî regression.check_vfold_cv_para","text":"Check regression.vfold_cv_para either NULL named list contains recognized parameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_vfold_cv_para.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the parameters that are sent to rsample::vfold_cv() ‚Äî regression.check_vfold_cv_para","text":"","code":"regression.check_vfold_cv_para(regression.vfold_cv_para)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_vfold_cv_para.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the parameters that are sent to rsample::vfold_cv() ‚Äî regression.check_vfold_cv_para","text":"regression.vfold_cv_para Either NULL (default) named list containing parameters sent rsample::vfold_cv(). See regression vignette several examples.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.check_vfold_cv_para.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check the parameters that are sent to rsample::vfold_cv() ‚Äî regression.check_vfold_cv_para","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.cv_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce message about which batch prepare_data is working on ‚Äî regression.cv_message","title":"Produce message about which batch prepare_data is working on ‚Äî regression.cv_message","text":"Produce message batch prepare_data working ","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.cv_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce message about which batch prepare_data is working on ‚Äî regression.cv_message","text":"","code":"regression.cv_message(   regression.results,   regression.grid,   n_cv = 10,   current_comb )"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.cv_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce message about which batch prepare_data is working on ‚Äî regression.cv_message","text":"regression.results results CV procedures. regression.grid Object containing hyperparameter values. n_cv Integer (default 10) specifying number CV hyperparameter configurations print. current_comb Integer vector. current combination features, passed verbosity printing function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.cv_message.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce message about which batch prepare_data is working on ‚Äî regression.cv_message","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_string_to_R.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert the string into an R object ‚Äî regression.get_string_to_R","title":"Convert the string into an R object ‚Äî regression.get_string_to_R","text":"Convert string R object","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_string_to_R.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert the string into an R object ‚Äî regression.get_string_to_R","text":"","code":"regression.get_string_to_R(string)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_string_to_R.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert the string into an R object ‚Äî regression.get_string_to_R","text":"string character vector/string containing text convert R code.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_string_to_R.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Convert the string into an R object ‚Äî regression.get_string_to_R","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_tune.html","id":null,"dir":"Reference","previous_headings":"","what":"Get if model is to be tuned ‚Äî regression.get_tune","title":"Get if model is to be tuned ‚Äî regression.get_tune","text":", regression model contains hyperparameters tune using cross validation. See tidymodels default model hyperparameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_tune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get if model is to be tuned ‚Äî regression.get_tune","text":"","code":"regression.get_tune(regression.model, regression.tune_values, x_train)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_tune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get if model is to be tuned ‚Äî regression.get_tune","text":"regression.model tidymodels object class model_specs. Default linear regression model, .e., parsnip::linear_reg(). See tidymodels possible models, see vignette add new/models. Note, make easier call explain() Python, regression.model parameter can also string specifying model parsed evaluated. example, \"parsnip::rand_forest(mtry = hardhat::tune(), trees = 100, engine = \"ranger\", mode = \"regression\")\" also valid input. essential include package prefix package loaded. regression.tune_values Either NULL (default), data.frame/data.table/tibble, function. data.frame must contain possible hyperparameter value combinations try. column names must match names tunable parameters specified regression.model. regression.tune_values function, take one argument x training data current coalition returns data.frame/data.table/tibble properties described . Using function allows hyperparameter values change based size coalition See regression vignette several examples. Note, make easier call explain() Python, regression.tune_values can also string containing R function. example, \"function(x) return(dials::grid_regular(dials::mtry(c(1, ncol(x)))), levels = 3))\" also valid input. essential include package prefix package loaded. x_train Data.table training data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_tune.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get if model is to be tuned ‚Äî regression.get_tune","text":"boolean variable indicating regression model tuned.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_tune.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get if model is to be tuned ‚Äî regression.get_tune","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_y_hat.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the predicted responses ‚Äî regression.get_y_hat","title":"Get the predicted responses ‚Äî regression.get_y_hat","text":"Get predicted responses","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_y_hat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the predicted responses ‚Äî regression.get_y_hat","text":"","code":"regression.get_y_hat(internal, model, predict_model)"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_y_hat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the predicted responses ‚Äî regression.get_y_hat","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. model Objects. model object explained. See documentation explain() details. predict_model Function. prediction function used model natively supported. See documentation explain() details.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_y_hat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the predicted responses ‚Äî regression.get_y_hat","text":"internal list, added vectors internal$data$x_train_y_hat internal$data$x_explain_y_hat containing predicted response training explain data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.get_y_hat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the predicted responses ‚Äî regression.get_y_hat","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.surrogate_aug_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment the training data and the explicands ‚Äî regression.surrogate_aug_data","title":"Augment the training data and the explicands ‚Äî regression.surrogate_aug_data","text":"Augment training data explicands","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.surrogate_aug_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment the training data and the explicands ‚Äî regression.surrogate_aug_data","text":"","code":"regression.surrogate_aug_data(   internal,   x,   y_hat = NULL,   index_features = NULL,   augment_masks_as_factor = FALSE,   augment_include_grand = FALSE,   augment_add_id_coal = FALSE,   augment_comb_prob = NULL,   augment_weights = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.surrogate_aug_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment the training data and the explicands ‚Äî regression.surrogate_aug_data","text":"internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list. x Data.table containing training data. y_hat Vector numerics (optional) containing predicted responses observations x. index_features Array integers (optional) containing coalitions consider. Must provided x explicands. augment_masks_as_factor Logical (default FALSE). TRUE, binary masks converted factors. FALSE, binary masks numerics. augment_include_grand Logical (default FALSE). TRUE, grand coalition included. index_features provided, augment_include_grand effect. Note sample coalitions grand coalition equally likely sampled coalitions (weighted augment_comb_prob provided). augment_add_id_coal Logical (default FALSE). TRUE, additional column adding containing coalition applied. augment_comb_prob Array numerics (default NULL). length array must match number coalitions considered, entry specifies probability sampling corresponding coalition. useful want generate training data specific coalitions. One possible choice augment_comb_prob = (use_Shapley_weights) internal$objects$X$shapley_weight[2:actual_n_coalitions] else NULL. augment_weights String (optional). Specifying type weights add observations. NULL (default), weights added. \"Shapley\", Shapley weights different coalitions added corresponding observations coalition applied. uniform, observations get equal weight one.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.surrogate_aug_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment the training data and the explicands ‚Äî regression.surrogate_aug_data","text":"data.table containing augmented data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.surrogate_aug_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Augment the training data and the explicands ‚Äî regression.surrogate_aug_data","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.train_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Train a tidymodels model via workflows ‚Äî regression.train_model","title":"Train a tidymodels model via workflows ‚Äî regression.train_model","text":"Function trains tidymodels model via workflows based provided input parameters. function allows cross validating hyperparameters model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.train_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train a tidymodels model via workflows ‚Äî regression.train_model","text":"","code":"regression.train_model(   x,   seed = 1,   verbose = NULL,   regression.model = parsnip::linear_reg(),   regression.tune = FALSE,   regression.tune_values = NULL,   regression.vfold_cv_para = NULL,   regression.recipe_func = NULL,   regression.response_var = \"y_hat\",   regression.surrogate_n_comb = NULL,   current_comb = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.train_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train a tidymodels model via workflows ‚Äî regression.train_model","text":"x Data.table containing training data. seed Positive integer. Specifies seed code involving randomness run. NULL (default), seed set calling environment. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). regression.model tidymodels object class model_specs. Default linear regression model, .e., parsnip::linear_reg(). See tidymodels possible models, see vignette add new/models. Note, make easier call explain() Python, regression.model parameter can also string specifying model parsed evaluated. example, \"parsnip::rand_forest(mtry = hardhat::tune(), trees = 100, engine = \"ranger\", mode = \"regression\")\" also valid input. essential include package prefix package loaded. regression.tune Logical (default FALSE). TRUE, tune hyperparemeters based values provided regression.tune_values. Note checks conducted checked earlier setup_approach.regression_separate setup_approach.regression_surrogate. regression.tune_values Either NULL (default), data.frame/data.table/tibble, function. data.frame must contain possible hyperparameter value combinations try. column names must match names tunable parameters specified regression.model. regression.tune_values function, take one argument x training data current coalition returns data.frame/data.table/tibble properties described . Using function allows hyperparameter values change based size coalition See regression vignette several examples. Note, make easier call explain() Python, regression.tune_values can also string containing R function. example, \"function(x) return(dials::grid_regular(dials::mtry(c(1, ncol(x)))), levels = 3))\" also valid input. essential include package prefix package loaded. regression.vfold_cv_para Either NULL (default) named list containing parameters sent rsample::vfold_cv(). See regression vignette several examples. regression.recipe_func Either NULL (default) function takes recipes::recipe() object returns modified recipes::recipe() potentially additional recipe steps. See regression vignette several examples. Note, make easier call explain() Python, regression.recipe_func can also string containing R function. example, \"function(recipe) return(recipes::step_ns(recipe, recipes::all_numeric_predictors(), deg_free = 2))\" also valid input. essential include package prefix package loaded. regression.response_var String (default y_hat) containing name response variable. regression.surrogate_n_comb Integer (default NULL). number times training observations augmented. NULL, assume separate regression. current_comb Integer vector. current combination features, passed verbosity printing function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.train_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train a tidymodels model via workflows ‚Äî regression.train_model","text":"trained tidymodels model based provided input parameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/regression.train_model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Train a tidymodels model via workflows ‚Äî regression.train_model","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/release_questions.html","id":null,"dir":"Reference","previous_headings":"","what":"Auxiliary function for the vignettes ‚Äî release_questions","title":"Auxiliary function for the vignettes ‚Äî release_questions","text":"Ask whether vignettes built using rebuild-long-running-vignette.R script. useful using devtools release shapr CRAN. See devtools::release() information.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/release_questions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Auxiliary function for the vignettes ‚Äî release_questions","text":"","code":"release_questions()"},{"path":"https://norskregnesentral.github.io/shapr/reference/round_manual.html","id":null,"dir":"Reference","previous_headings":"","what":"Round numbers to the specified number of decimal places ‚Äî round_manual","title":"Round numbers to the specified number of decimal places ‚Äî round_manual","text":"function rounds numbers specified number decimal places using manual method avoids typical rounding issues R may vary across different OS.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/round_manual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Round numbers to the specified number of decimal places ‚Äî round_manual","text":"","code":"round_manual(x, digits = 0L)"},{"path":"https://norskregnesentral.github.io/shapr/reference/round_manual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Round numbers to the specified number of decimal places ‚Äî round_manual","text":"x Numeric vector. numbers round. digits Integer. number digits round . Defaults 0.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/round_manual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Round numbers to the specified number of decimal places ‚Äî round_manual","text":"Numeric vector. rounded numbers.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/rss_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Function for computing sigma_hat_sq ‚Äî rss_cpp","title":"Function for computing sigma_hat_sq ‚Äî rss_cpp","text":"Function computing sigma_hat_sq","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/rss_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function for computing sigma_hat_sq ‚Äî rss_cpp","text":"","code":"rss_cpp(H, y)"},{"path":"https://norskregnesentral.github.io/shapr/reference/rss_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function for computing sigma_hat_sq ‚Äî rss_cpp","text":"H Matrix. Output hat_matrix_cpp() y Vector Representing (temporary) response variable","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/rss_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function for computing sigma_hat_sq ‚Äî rss_cpp","text":"Scalar","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/rss_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function for computing sigma_hat_sq ‚Äî rss_cpp","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_coalition_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get table with sampled coalitions using the semi-deterministic sampling approach ‚Äî sample_coalition_table","title":"Get table with sampled coalitions using the semi-deterministic sampling approach ‚Äî sample_coalition_table","text":"Get table sampled coalitions using semi-deterministic sampling approach","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_coalition_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get table with sampled coalitions using the semi-deterministic sampling approach ‚Äî sample_coalition_table","text":"","code":"sample_coalition_table(   m,   n_coalitions = 200,   n_coal_each_size = choose(m, seq(m - 1)),   weight_zero_m = 10^6,   paired_shap_sampling = TRUE,   prev_X = NULL,   kernelSHAP_reweighting = \"on_all_cond\",   semi_deterministic_sampling = FALSE,   dt_coal_samp_info = NULL,   dt_valid_causal_coalitions = NULL,   n_samps_scale = 10 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_coalition_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get table with sampled coalitions using the semi-deterministic sampling approach ‚Äî sample_coalition_table","text":"m Positive integer. Total number features/groups. n_coalitions Positive integer. Note exact = TRUE, n_coalitions ignored. n_coal_each_size Vector integers length m-1. number valid coalitions coalition size 1, 2,..., m-1. symmetric Shapley values, choose(m, seq(m-1)) (default). asymmetric Shapley values, number valid coalitions size causal ordering. Used correctly normalize Shapley weights. weight_zero_m Numeric. value use replacement infinite coalition weights numerical operations. paired_shap_sampling Logical. Whether paired sampling coalitions. prev_X data.table. X data.table previous iteration. kernelSHAP_reweighting String. reweight sampling frequency weights kernelSHAP solution sampling. aim reduce randomness thereby variance Shapley value estimates. options one 'none', 'on_N', 'on_all', 'on_all_cond' (default). 'none' means reweighting, .e. sampling frequency weights used . 'on_N' means sampling frequencies averaged coalitions original sampling probabilities. 'on_all' means original sampling probabilities used coalitions. 'on_all_cond' means original sampling probabilities used coalitions, adjusting probability sampled least . 'on_all_cond' preferred performs best simulation studies, see Olsen & Jullum (2024). semi_deterministic_sampling Logical. FALSE (default), sample coalitions. TRUE, sampling coalitions semi-deterministic, .e. sampling done way ensures coalitions expected sampled based number coalitions deterministically included sample among fewer coalitions. done reduce variance Shapley value estimates, corresponds PySHAP* strategy paper Olsen & Jullum (2024). dt_coal_samp_info data.table. data.table contains information coalitions deterministically included can sampled, addition sampling probabilities available coalition size, weight given sampled deterministically included coalitions (excluding empty grand coalitions given weight_zero_m weight). dt_valid_causal_coalitions data.table. applicable asymmetric Shapley value explanations, NULL symmetric Shapley values. data.table contains information coalitions respects causal ordering. n_samps_scale Positive integer. Integer scales number coalitions n_coalitions sample sampling cheap, checking n_coalitions unique coalitions expensive, thus sample number coalitions factor n_samps_scale determine n_coalitions unique coalitions use coalitions point throw away remaining coalitions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_coalitions_cpp_str_paired.html","id":null,"dir":"Reference","previous_headings":"","what":"We here return a vector of strings/characters, i.e., a CharacterVector, where each string is a space-separated list of integers. ‚Äî sample_coalitions_cpp_str_paired","title":"We here return a vector of strings/characters, i.e., a CharacterVector, where each string is a space-separated list of integers. ‚Äî sample_coalitions_cpp_str_paired","text":"return vector strings/characters, .e., CharacterVector, string space-separated list integers.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_coalitions_cpp_str_paired.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"We here return a vector of strings/characters, i.e., a CharacterVector, where each string is a space-separated list of integers. ‚Äî sample_coalitions_cpp_str_paired","text":"","code":"sample_coalitions_cpp_str_paired(m, n_coalitions, paired_shap_sampling = TRUE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_coalitions_cpp_str_paired.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"We here return a vector of strings/characters, i.e., a CharacterVector, where each string is a space-separated list of integers. ‚Äî sample_coalitions_cpp_str_paired","text":"m Positive integer. Total number features/groups. n_coalitions IntegerVector. number features sample feature combination. paired_shap_sampling Logical. Whether paired sampling coalitions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_combinations.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to sample a combination of training and testing rows, which does not risk getting the same observation twice. Need to improve this help file. ‚Äî sample_combinations","title":"Helper function to sample a combination of training and testing rows, which does not risk getting the same observation twice. Need to improve this help file. ‚Äî sample_combinations","text":"Helper function sample combination training testing rows, risk getting observation twice. Need improve help file.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_combinations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to sample a combination of training and testing rows, which does not risk getting the same observation twice. Need to improve this help file. ‚Äî sample_combinations","text":"","code":"sample_combinations(ntrain, ntest, nsamples, joint_sampling = TRUE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_combinations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to sample a combination of training and testing rows, which does not risk getting the same observation twice. Need to improve this help file. ‚Äî sample_combinations","text":"ntrain Positive integer. Number training observations sample . ntest Positive integer. Number test observations sample . nsamples Positive integer. Number samples. joint_sampling Logical. Indicates whether train- test data sampled separately joint sampling space. sampled separately (typically used optimizing one distribution ) sample replacement nsamples > ntrain. Note solution optimal. careful optimization every test observation nsamples > ntrain.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_combinations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to sample a combination of training and testing rows, which does not risk getting the same observation twice. Need to improve this help file. ‚Äî sample_combinations","text":"data.frame","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_combinations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Helper function to sample a combination of training and testing rows, which does not risk getting the same observation twice. Need to improve this help file. ‚Äî sample_combinations","text":"Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_ctree.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","title":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","text":"Sample ctree variables given conditional inference tree","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_ctree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","text":"","code":"sample_ctree(tree, n_MC_samples, x_explain, x_train, n_features, sample)"},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_ctree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","text":"tree List. Contains tree object type ctree built party package. Also contains given_ind, features condition upon. n_MC_samples Scalar integer. Corresponds number samples leaf node. See exception sample = FALSE setup_approach.ctree(). x_explain Data.table features observation whose predictions explained (test data). x_train Data.table training data. n_features Positive integer. number features.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_ctree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","text":"data.table n_MC_samples (conditional) Gaussian samples","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_ctree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","text":"See documentation setup_approach.ctree() function undocumented parameters.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/sample_ctree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample ctree variables from a given conditional inference tree ‚Äî sample_ctree","text":"Annabelle Redelmeier","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/save_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves the intermediate results to disk ‚Äî save_results","title":"Saves the intermediate results to disk ‚Äî save_results","text":"Saves intermediate results disk","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/save_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves the intermediate results to disk ‚Äî save_results","text":"","code":"save_results(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/save_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves the intermediate results to disk ‚Äî save_results","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/save_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Saves the intermediate results to disk ‚Äî save_results","text":"return value (saves intermediate results disk)","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup.html","id":null,"dir":"Reference","previous_headings":"","what":"check_setup ‚Äî setup","title":"check_setup ‚Äî setup","text":"check_setup","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"check_setup ‚Äî setup","text":"","code":"setup(   x_train,   x_explain,   approach,   phi0,   output_size = 1,   max_n_coalitions,   group,   n_MC_samples,   seed,   feature_specs,   type = \"regular\",   horizon = NULL,   y = NULL,   xreg = NULL,   train_idx = NULL,   explain_idx = NULL,   explain_y_lags = NULL,   explain_xreg_lags = NULL,   group_lags = NULL,   verbose,   iterative = NULL,   iterative_args = list(),   is_python = FALSE,   testing = FALSE,   init_time = NULL,   prev_shapr_object = NULL,   asymmetric = FALSE,   causal_ordering = NULL,   confounding = NULL,   output_args = list(),   extra_computation_args = list(),   model_class,   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"check_setup ‚Äî setup","text":"x_train Matrix data.frame/data.table. Data used estimate (conditional) feature distributions needed properly estimate conditional expectations Shapley formula. x_explain Matrix data.frame/data.table. Features predictions explained. approach Character vector length 1 one less number features. elements either \"gaussian\", \"copula\", \"empirical\", \"ctree\", \"vaeac\", \"categorical\", \"timeseries\", \"independence\", \"regression_separate\", \"regression_surrogate\". two regression approaches combined approach. See details information. phi0 Numeric. prediction value unseen data, .e., estimate expected prediction without conditioning features. Typically set equal mean response training data, alternatives mean training predictions also reasonable. output_size Scalar integer. Specifies dimension output prediction model every observation. max_n_coalitions Integer. Upper limit number unique feature/group coalitions use iterative procedure (iterative = TRUE). iterative = FALSE, represents number feature/group coalitions use directly. quantity refers number unique feature coalitions group = NULL, group coalitions group != NULL. max_n_coalitions = NULL corresponds 2^n_features. group List. NULL, regular feature-wise Shapley values computed. provided, group-wise Shapley values computed. group length equal number groups. list element contains character vectors features included corresponding group. See Jullum et al. (2021) information group-wise Shapley values. n_MC_samples Positive integer. approaches, indicates maximum number samples use Monte Carlo integration every conditional expectation. approach=\"ctree\", n_MC_samples corresponds number samples leaf node (see exception related ctree.sample argument setup_approach.ctree()). approach=\"empirical\", n_MC_samples \\(K\\) parameter equations (14-15) Aas et al. (2021), .e. maximum number observations (largest weights) used, see also empirical.eta argument setup_approach.empirical(). seed Positive integer. Specifies seed code involving randomness run. NULL (default), seed set calling environment. feature_specs List. output get_model_specs() get_data_specs(). Contains three elements: labels Character vector names feature. classes Character vector classes feature. factor_levels Character vector levels categorical features. type Character. Either \"regular\" \"forecast\", matching function call originated , thus type explanation generate. horizon Numeric. forecast horizon explain. Passed predict_model function. y Matrix, data.frame/data.table numeric vector. Contains endogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. xreg Matrix, data.frame/data.table numeric vector. Contains exogenous variables used estimate (conditional) distributions needed properly estimate conditional expectations Shapley formula including observations explained. exogenous variables used contemporaneously producing forecast, item contain nrow(y) + horizon rows. train_idx Numeric vector. row indices data reg denoting points time use estimating conditional expectations Shapley value formula. train_idx = NULL (default) indices selected explained used. explain_idx Numeric vector. row indices data reg denoting points time explain. explain_y_lags Numeric vector. Denotes number lags used variable y making forecast. explain_xreg_lags Numeric vector. xreg != NULL, denotes number lags used variable xreg making forecast. group_lags Logical. TRUE lags variable grouped together explained group. FALSE lags variable explained individually. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). iterative Logical NULL. NULL (default), set TRUE 5 features/groups, FALSE otherwise. TRUE, Shapley values estimated iteratively faster, sufficiently accurate results. First initial number coalitions sampled, bootstrapping estimates variance Shapley values. convergence criterion determines variances sufficiently small. , additional samples added. process repeats variances threshold. Specifics iterative process convergence criterion set via iterative_args. iterative_args Named list. Specifies arguments iterative procedure. See get_iterative_args_default() description arguments default values. is_python Logical. Indicates whether function called Python wrapper. Default FALSE, never changed calling function via explain() R. parameter later used disallow running AICc versions empirical method, requires data-based optimization, supported shaprpy. testing Logical. used remove random components, like timing, output comparing testthat. Defaults FALSE. init_time POSIXct. time explain() function called, returned Sys.time(). Used calculate total time explain() call. prev_shapr_object shapr object string. object class shapr provided, string path intermediate results stored, function use previous object continue computation. useful computation interrupted want higher accuracy already obtained, therefore want continue iterative estimation. See general usage vignette examples. asymmetric Logical. applicable (regular) non-causal explanations. FALSE (default), explain computes regular symmetric Shapley values. TRUE, explain computes asymmetric Shapley values based (partial) causal ordering given causal_ordering. , explain uses feature coalitions respect causal ordering. asymmetric TRUE confounding NULL (default), explain computes asymmetric conditional Shapley values specified  Frye et al. (2020). confounding provided, .e., NULL, explain computes asymmetric causal Shapley values specified  Heskes et al. (2020). causal_ordering List. applicable (regular) non-causal asymmetric explanations. causal_ordering unnamed list vectors specifying components partial causal ordering coalitions must respect. vector represents component contains one features/groups identified names (strings) indices (integers). causal_ordering NULL (default), causal ordering assumed possible coalitions allowed. causal ordering equivalent causal ordering single component includes features (list(1:n_features)) groups (list(1:n_groups)) feature-wise group-wise Shapley values, respectively. feature-wise Shapley values causal_ordering = list(c(1, 2), c(3, 4)), interpretation features 1 2 ancestors features 3 4, features 3 4 level. Note: features/groups must included causal_ordering without duplicates. confounding Logical vector. applicable (regular) non-causal asymmetric explanations. confounding logical vector specifying whether confounding assumed component causal_ordering. NULL (default), assumption confounding structure made explain computes asymmetric/symmetric conditional Shapley values, depending asymmetric. confounding single logical (FALSE TRUE), assumption set globally components causal ordering. Otherwise, confounding must length causal_ordering, indicating confounding assumption component. confounding specified, explain computes asymmetric/symmetric causal Shapley values, depending asymmetric. approach regression_separate regression_surrogate, regression-based approaches applicable causal Shapley methodology. output_args Named list. Specifies certain arguments related output function. See get_output_args_default() description arguments default values. extra_computation_args Named list. Specifies extra arguments related computation Shapley values. See get_extra_comp_args_default() description arguments default values. model_class Character string. class model object, e.g., \"lm\", \"glm\", \"xgboost\", etc. obtained class(model)[1]. ... arguments passed specific approaches, see .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"check_setup ‚Äî setup","text":"internal list containing parameters, info, data, computations needed later steps. list expanded modified functions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup_approach.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up the framework for the chosen approach ‚Äî setup_approach","title":"Set up the framework for the chosen approach ‚Äî setup_approach","text":"Different choices approach take different (optional) parameters, forwarded explain(). See general usage vignette information different approaches.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup_approach.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up the framework for the chosen approach ‚Äî setup_approach","text":"","code":"setup_approach(internal, ...)  # S3 method for class 'combined' setup_approach(internal, ...)  # S3 method for class 'categorical' setup_approach(   internal,   categorical.joint_prob_dt = NULL,   categorical.epsilon = 0.001,   ... )  # S3 method for class 'copula' setup_approach(internal, ...)  # S3 method for class 'ctree' setup_approach(   internal,   ctree.mincriterion = 0.95,   ctree.minsplit = 20,   ctree.minbucket = 7,   ctree.sample = TRUE,   ... )  # S3 method for class 'empirical' setup_approach(   internal,   empirical.type = \"fixed_sigma\",   empirical.eta = 0.95,   empirical.fixed_sigma = 0.1,   empirical.n_samples_aicc = 1000,   empirical.eval_max_aicc = 20,   empirical.start_aicc = 0.1,   empirical.cov_mat = NULL,   model = NULL,   predict_model = NULL,   ... )  # S3 method for class 'gaussian' setup_approach(internal, gaussian.mu = NULL, gaussian.cov_mat = NULL, ...)  # S3 method for class 'independence' setup_approach(internal, ...)  # S3 method for class 'regression_separate' setup_approach(   internal,   regression.model = parsnip::linear_reg(),   regression.tune_values = NULL,   regression.vfold_cv_para = NULL,   regression.recipe_func = NULL,   ... )  # S3 method for class 'regression_surrogate' setup_approach(   internal,   regression.model = parsnip::linear_reg(),   regression.tune_values = NULL,   regression.vfold_cv_para = NULL,   regression.recipe_func = NULL,   regression.surrogate_n_comb =     internal$iter_list[[length(internal$iter_list)]]$n_coalitions - 2,   ... )  # S3 method for class 'timeseries' setup_approach(   internal,   timeseries.fixed_sigma = 2,   timeseries.bounds = c(NULL, NULL),   ... )  # S3 method for class 'vaeac' setup_approach(   internal,   vaeac.depth = 3,   vaeac.width = 32,   vaeac.latent_dim = 8,   vaeac.activation_function = torch::nn_relu,   vaeac.lr = 0.001,   vaeac.n_vaeacs_initialize = 4,   vaeac.epochs = 100,   vaeac.extra_parameters = list(),   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/setup_approach.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up the framework for the chosen approach ‚Äî setup_approach","text":"internal List. used directly, passed explain(). ... Arguments passed specific classes. See . categorical.joint_prob_dt Data.table. (Optional) Containing joint probability distribution combination feature values. NULL means estimated x_train x_explain. categorical.epsilon Numeric value. (Optional) categorical.joint_prob_dt supplied, probabilities/frequencies estimated using x_train. certain observations occur x_explain x_train, epsilon used proportion times observations occur training data. theory, proportion zero, causes error later Shapley computation. ctree.mincriterion Numeric scalar vector. Either scalar vector length equal number features model. value equal 1 - \\(\\alpha\\) \\(\\alpha\\) nominal level conditional independence tests. vector, indicates value use conditioning various numbers features. default value 0.95. ctree.minsplit Numeric scalar. Determines minimum value sum left right daughter nodes must reach split. default value 20. ctree.minbucket Numeric scalar. Determines minimum sum weights terminal node required split. default value 7. ctree.sample Boolean. TRUE (default), method always samples n_MC_samples observations leaf nodes (replacement). FALSE number observations leaf node less n_MC_samples, method take observations leaf. FALSE number observations leaf node n_MC_samples, method sample n_MC_samples observations (replacement). means always sampling leaf unless sample = FALSE number obs node less n_MC_samples. empirical.type Character. (default = \"fixed_sigma\") Must one \"independence\", \"fixed_sigma\", \"AICc_each_k\", \"AICc_full\". Note: \"empirical.type = independence\" deprecated; use approach = \"independence\" instead. \"fixed_sigma\" uses fixed bandwidth (set empirical.fixed_sigma) kernel density estimation. \"AICc_each_k\" \"AICc_full\" optimize bandwidth using AICc criterion, respectively one bandwidth per coalition size one bandwidth coalition sizes. empirical.eta Numeric scalar. Needs 0 < eta <= 1. default value 0.95. Represents minimum proportion total empirical weight data samples use. example, eta = .8, choose K samples largest weights sum weights accounts 80\\ eta \\(\\eta\\) parameter equation (15) Aas et al. (2021). empirical.fixed_sigma Positive numeric scalar. default value 0.1. Represents kernel bandwidth distance computation used conditioning different coalitions. used empirical.type = \"fixed_sigma\" empirical.n_samples_aicc Positive integer. Number samples consider AICc optimization. default value 1000. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.eval_max_aicc Positive integer. Maximum number iterations optimizing AICc. default value 20. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.start_aicc Numeric. Start value sigma parameter optimizing AICc. default value 0.1. used empirical.type either \"AICc_each_k\" \"AICc_full\". empirical.cov_mat Numeric matrix. (Optional) covariance matrix data generating distribution used define Mahalanobis distance. NULL means estimated x_train. model Objects. model object explained. See documentation explain() details. predict_model Function. prediction function used model natively supported. See documentation explain() details. gaussian.mu Numeric vector. (Optional) Containing mean data generating distribution. NULL means estimated x_train. gaussian.cov_mat Numeric matrix. (Optional) Containing covariance matrix data generating distribution. NULL means estimated x_train. regression.model tidymodels object class model_specs. Default linear regression model, .e., parsnip::linear_reg(). See tidymodels possible models, see vignette add new/models. Note, make easier call explain() Python, regression.model parameter can also string specifying model parsed evaluated. example, \"parsnip::rand_forest(mtry = hardhat::tune(), trees = 100, engine = \"ranger\", mode = \"regression\")\" also valid input. essential include package prefix package loaded. regression.tune_values Either NULL (default), data.frame/data.table/tibble, function. data.frame must contain possible hyperparameter value combinations try. column names must match names tunable parameters specified regression.model. regression.tune_values function, take one argument x training data current coalition returns data.frame/data.table/tibble properties described . Using function allows hyperparameter values change based size coalition See regression vignette several examples. Note, make easier call explain() Python, regression.tune_values can also string containing R function. example, \"function(x) return(dials::grid_regular(dials::mtry(c(1, ncol(x)))), levels = 3))\" also valid input. essential include package prefix package loaded. regression.vfold_cv_para Either NULL (default) named list containing parameters sent rsample::vfold_cv(). See regression vignette several examples. regression.recipe_func Either NULL (default) function takes recipes::recipe() object returns modified recipes::recipe() potentially additional recipe steps. See regression vignette several examples. Note, make easier call explain() Python, regression.recipe_func can also string containing R function. example, \"function(recipe) return(recipes::step_ns(recipe, recipes::all_numeric_predictors(), deg_free = 2))\" also valid input. essential include package prefix package loaded. regression.surrogate_n_comb Positive integer. Specifies number unique coalitions apply training observation. default number sampled coalitions present iteration. integer 1 default allowed. Larger values requires memory, may improve surrogate model. user sets value lower maximum, sample amount unique coalitions separately training observations. , average, coalitions equally trained. timeseries.fixed_sigma Positive numeric scalar. Represents kernel bandwidth distance computation. default value 2. timeseries.bounds Numeric vector length two. Specifies lower upper bounds timeseries. default c(NULL, NULL), .e. bounds. one bounds NULL, restrict sampled time series bounds. useful underlying time series scaled 0 1, example. vaeac.depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. vaeac.width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. vaeac.latent_dim Positive integer (default 8). number dimensions latent space. vaeac.activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu() (default), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid(). vaeac.lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. vaeac.n_vaeacs_initialize Positive integer (default 4). number different vaeac models initiate start. Pick best performing one vaeac.extra_parameters$epochs_initiation_phase epochs (default 2) continue training one. vaeac.epochs Positive integer (default 100). number epochs train final vaeac model. includes vaeac.extra_parameters$epochs_initiation_phase, default 2. vaeac.extra_parameters Named list extra parameters vaeac approach. See vaeac_get_extra_para_default() description possible additional parameters default values.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup_approach.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up the framework for the chosen approach ‚Äî setup_approach","text":"Updated internal object approach set .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup_approach.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Set up the framework for the chosen approach ‚Äî setup_approach","text":"Aas, K., Jullum, M., & L√∏land, . (2021). Explaining individual predictions features dependent: accurate approximations Shapley values. Artificial Intelligence, 298, 103502","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/setup_approach.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set up the framework for the chosen approach ‚Äî setup_approach","text":"Martin Jullum Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up the kernelSHAP framework ‚Äî shapley_setup","title":"Set up the kernelSHAP framework ‚Äî shapley_setup","text":"Set kernelSHAP framework","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up the kernelSHAP framework ‚Äî shapley_setup","text":"","code":"shapley_setup(internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up the kernelSHAP framework ‚Äî shapley_setup","text":"internal List. used directly, passed explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set up the kernelSHAP framework ‚Äî shapley_setup","text":"internal list updated coalitions estimated","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Shapley weight ‚Äî shapley_weights","title":"Calculate Shapley weight ‚Äî shapley_weights","text":"Calculate Shapley weight","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Shapley weight ‚Äî shapley_weights","text":"","code":"shapley_weights(m, N, n_components, weight_zero_m = 10^6)"},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Shapley weight ‚Äî shapley_weights","text":"m Positive integer. Total number features/groups. N Positive integer. number unique coalitions sampling n_components features/feature groups, without replacement, sample space consisting m different features/feature groups. n_components Positive integer. Represents number features/feature groups want sample feature space consisting m unique features/feature groups. Note  0 < = n_components <= m. weight_zero_m Numeric. value use replacement infinite coalition weights numerical operations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Shapley weight ‚Äî shapley_weights","text":"Numeric","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapley_weights.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate Shapley weight ‚Äî shapley_weights","text":"Nikolai Sellereite","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/shapr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"shapr: Prediction Explanation with Dependence-Aware Shapley Values ‚Äî shapr-package","title":"shapr: Prediction Explanation with Dependence-Aware Shapley Values ‚Äî shapr-package","text":"Complex machine learning models often hard interpret. However, many situations crucial understand explain model made specific prediction. Shapley values method prediction explanation framework solid theoretical foundation. Previously known methods estimating Shapley values , however, assume feature independence. package implements methods accounts feature dependence, thereby produces accurate estimates true Shapley values. accompanying 'Python' wrapper ('shaprpy') available GitHub repository.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/reference/shapr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"shapr: Prediction Explanation with Dependence-Aware Shapley Values ‚Äî shapr-package","text":"Maintainer: Martin Jullum Martin.Jullum@nr.(ORCID) Authors: Lars Henry Berge Olsen lhbolsen@nr.(ORCID) Annabelle Redelmeier ardelmeier@gmail.com Jon Lachmann Jon@lachmann.nu (ORCID) Nikolai Sellereite nikolaisellereite@gmail.com (ORCID) contributors: Anders L√∏land Anders.Loland@nr.[contributor] Jens Christian Wahl jens.c.wahl@gmail.com [contributor] Camilla Lingj√¶rde [contributor] Norsk Regnesentral [copyright holder, funder]","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/skip_connection.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a skip connection ‚Äî skip_connection","title":"A torch::nn_module() Representing a skip connection ‚Äî skip_connection","text":"Skip connection sequence layers constructor. module passes input data sequentially layers adds original data result.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/skip_connection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a skip connection ‚Äî skip_connection","text":"","code":"skip_connection(...)"},{"path":"https://norskregnesentral.github.io/shapr/reference/skip_connection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a skip connection ‚Äî skip_connection","text":"... network modules , e.g., torch::nn_linear(), torch::nn_relu(), memory_layer() objects. See vaeac() information.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/skip_connection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a skip connection ‚Äî skip_connection","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_masks_mask_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a specified_masks_mask_generator ‚Äî specified_masks_mask_generator","title":"A torch::nn_module() Representing a specified_masks_mask_generator ‚Äî specified_masks_mask_generator","text":"mask generator masks entries based sampling provided 1D masks corresponding probabilities. Used Shapley value estimation subset coalitions used compute Shapley values.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_masks_mask_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a specified_masks_mask_generator ‚Äî specified_masks_mask_generator","text":"","code":"specified_masks_mask_generator(masks, masks_probs, paired_sampling = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_masks_mask_generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a specified_masks_mask_generator ‚Äî specified_masks_mask_generator","text":"masks Matrix/Tensor possible/allowed 'masks' sample . masks_probs Array 'probabilities' masks specified 'masks'. Note need 0 1 (e.g. sampling frequency). scaled, hence, need positive. paired_sampling Boolean. paired sampling. include S \\(\\bar{S}\\). TRUE, batch must sampled using 'paired_sampler' creates batches first half second half rows duplicates . , batch = [row1, row1, row2, row2, row3, row3, ...].","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_masks_mask_generator.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"A torch::nn_module() Representing a specified_masks_mask_generator ‚Äî specified_masks_mask_generator","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_prob_mask_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"A torch::nn_module() Representing a specified_prob_mask_generator ‚Äî specified_prob_mask_generator","title":"A torch::nn_module() Representing a specified_prob_mask_generator ‚Äî specified_prob_mask_generator","text":"mask generator masks entries based specified probabilities.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_prob_mask_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A torch::nn_module() Representing a specified_prob_mask_generator ‚Äî specified_prob_mask_generator","text":"","code":"specified_prob_mask_generator(masking_probs, paired_sampling = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_prob_mask_generator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A torch::nn_module() Representing a specified_prob_mask_generator ‚Äî specified_prob_mask_generator","text":"masking_probs M+1 numerics containing probabilities masking 'd' (0,...M) entries observation. paired_sampling Boolean. paired sampling. include S \\(\\bar{S}\\). TRUE, batch must sampled using 'paired_sampler' creates batches first half second half rows duplicates . , batch = [row1, row1, row2, row2, row3, row3, ...].","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/specified_prob_mask_generator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A torch::nn_module() Representing a specified_prob_mask_generator ‚Äî specified_prob_mask_generator","text":"class takes probabilities d masked observations.  .e., M dimensional data, masking_probs length M+1, d'th entry probability d-1 masked values. mask generator first samples number entries 'd' masked 'M'-dimensional observation 'x' batch based given M+1 probabilities. 'd' masked uniformly sampled 'M' possible feature indices. d'th entry probability d-1 masked values. Note mcar_mask_generator p = 0.5 using specified_prob_mask_generator() masking_ratio = choose(M, 0:M), M number features. function initially created check increasing probability masks many masked features improved vaeac's performance focusing situations training.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/summary.shapr.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for shapr objects ‚Äî summary.shapr","title":"Summary method for shapr objects ‚Äî summary.shapr","text":"Summary method shapr objects","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/summary.shapr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for shapr objects ‚Äî summary.shapr","text":"","code":"# S3 method for class 'shapr' summary(object, digits = 2L, ...)"},{"path":"https://norskregnesentral.github.io/shapr/reference/summary.shapr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for shapr objects ‚Äî summary.shapr","text":"object shapr object. digits Integer. (Maximum) number digits displayed decimal point. Defaults 2. ... Currently unused.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/summary.shapr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for shapr objects ‚Äî summary.shapr","text":"Prints formatted summary shapr object, invisibly returns named list summary components. See details section get_results() details component.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/test_predict_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Model testing function ‚Äî test_predict_model","title":"Model testing function ‚Äî test_predict_model","text":"Model testing function","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/test_predict_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model testing function ‚Äî test_predict_model","text":"","code":"test_predict_model(x_test, predict_model, model, internal)"},{"path":"https://norskregnesentral.github.io/shapr/reference/test_predict_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model testing function ‚Äî test_predict_model","text":"predict_model Function. prediction function used model natively supported. See documentation explain() details. model Objects. model object explained. See documentation explain() details. internal List. Holds parameters, data, functions computed objects used within explain() list contains one elements parameters, data, objects, iter_list, timing_list, main_timing_list, output, iter_timing_list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/testing_cleanup.html","id":null,"dir":"Reference","previous_headings":"","what":"Cleans out certain output arguments to allow perfect reproducibility of the output ‚Äî testing_cleanup","title":"Cleans out certain output arguments to allow perfect reproducibility of the output ‚Äî testing_cleanup","text":"Cleans certain output arguments allow perfect reproducibility output","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/testing_cleanup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cleans out certain output arguments to allow perfect reproducibility of the output ‚Äî testing_cleanup","text":"","code":"testing_cleanup(output)"},{"path":"https://norskregnesentral.github.io/shapr/reference/testing_cleanup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cleans out certain output arguments to allow perfect reproducibility of the output ‚Äî testing_cleanup","text":"Cleaned version output list used testthat testing","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/testing_cleanup.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cleans out certain output arguments to allow perfect reproducibility of the output ‚Äî testing_cleanup","text":"Lars Henry Berge Olsen, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializing a vaeac model ‚Äî vaeac","title":"Initializing a vaeac model ‚Äî vaeac","text":"Class represents vaeac model, .e., class creates neural networks vaeac model necessary training utilities. details, see Olsen et al. (2022).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializing a vaeac model ‚Äî vaeac","text":"","code":"vaeac(   one_hot_max_sizes,   width = 32,   depth = 3,   latent_dim = 8,   activation_function = torch::nn_relu,   skip_conn_layer = FALSE,   skip_conn_masked_enc_dec = FALSE,   batch_normalization = FALSE,   paired_sampling = FALSE,   mask_generator_name = c(\"mcar_mask_generator\", \"specified_prob_mask_generator\",     \"specified_masks_mask_generator\"),   masking_ratio = 0.5,   mask_gen_coalitions = NULL,   mask_gen_coalitions_prob = NULL,   sigma_mu = 10000,   sigma_sigma = 1e-04 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializing a vaeac model ‚Äî vaeac","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. width Integer. number neurons hidden layer neural networks masked encoder, full encoder, decoder. depth Integer. number hidden layers neural networks masked encoder, full encoder, decoder. latent_dim Integer. number dimensions latent space. activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu(), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid(). skip_conn_layer Boolean. use skip connections layer, see skip_connection(). TRUE, add input outcome hidden layer, output becomes \\(X + \\operatorname{activation}(WX + b)\\). .e., identity skip connection. skip_conn_masked_enc_dec Boolean. apply concatenating skip connections layers masked encoder decoder. first layer masked encoder linked last layer decoder. second layer masked encoder linked second last layer decoder, . batch_normalization Boolean. use batch normalization activation function. Note skip_conn_layer TRUE, normalization done adding skip connection. .e, batch normalize whole quantity X + activation(WX + b). paired_sampling Boolean. paired sampling. .e., include coalition S \\(\\bar{S}\\) sample coalitions training batch. mask_generator_name String specifying type mask generator use. Need one 'mcar_mask_generator', 'specified_prob_mask_generator', 'specified_masks_mask_generator'. masking_ratio Scalar. probability entry generated mask 1 (masked). used mask_gen_coalitions given. mask_gen_coalitions Matrix containing different coalitions learn. Must given mask_generator_name = 'specified_masks_mask_generator'. mask_gen_coalitions_prob Numerics containing probabilities sampling mask mask_gen_coalitions. Array containing probabilities sampling coalitions mask_gen_coalitions. sigma_mu Numeric representing hyperparameter normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). sigma_sigma Numeric representing hyperparameter normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initializing a vaeac model ‚Äî vaeac","text":"Returns list neural networks masked encoder, full encoder, decoder together reconstruction log probability function, optimizer constructor, sampler decoder output, mask generator, batch size, scale factor stability variational lower bound optimization.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initializing a vaeac model ‚Äî vaeac","text":"function builds neural networks (masked encoder, full encoder, decoder) given list one-hot max sizes features dataset use train vaeac model, provided parameters networks. also creates, e.g., reconstruction log probability function, methods sampling decoder output, use create vaeac model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"make-observed","dir":"Reference","previous_headings":"","what":"make_observed","title":"Initializing a vaeac model ‚Äî vaeac","text":"Apply Mask Batch Create Observed Batch Compute parameters latent normal distributions inferred encoders. only_masked_encoder = TRUE, compute latent normal distributions inferred masked encoder. used deployment phase access full observation.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"make-latent-distributions","dir":"Reference","previous_headings":"","what":"make_latent_distributions","title":"Initializing a vaeac model ‚Äî vaeac","text":"Compute Latent Distributions Inferred Encoders Compute parameters latent normal distributions inferred encoders. only_masked_encoder = TRUE, compute latent normal distributions inferred masked encoder. used deployment phase access full observation.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"masked-encoder-regularization","dir":"Reference","previous_headings":"","what":"masked_encoder_regularization","title":"Initializing a vaeac model ‚Äî vaeac","text":"Compute Regularizes Latent Distribution Inferred Masked Encoder. masked encoder (prior) distribution regularization latent space. used compute extended variational lower bound used train vaeac, see Section 3.3.1 Olsen et al. (2022). Though regularizing prevents masked encoder distribution parameters going infinity, model usually diverge even without regularization. almost affect learning process near zero default regularization parameters recommended used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"batch-vlb","dir":"Reference","previous_headings":"","what":"batch_vlb","title":"Initializing a vaeac model ‚Äî vaeac","text":"Compute Variational Lower Bound Observations Batch Compute differentiable lower bound given batch objects mask. Used (negative) loss function training vaeac model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"batch-iwae","dir":"Reference","previous_headings":"","what":"batch_iwae","title":"Initializing a vaeac model ‚Äî vaeac","text":"Compute IWAE log likelihood estimate K samples per object. Technically, differentiable, recommended use evaluation purposes inside torch.no_grad order save memory. torch::with_no_grad() method almost require extra memory large K. method makes K independent passes decoder network, batch size training batch_vlb. IWAE abbreviation Importance Sampling Estimator: $$ \\log p_{\\theta, \\psi}(x|y) \\approx \\log {\\frac{1}{K} \\sum_{=1}^K [p_\\theta(x|z_i, y) * p_\\psi(z_i|y) / q_\\phi(z_i|x,y)]} \\newline = \\log {\\sum_{=1}^K \\exp(\\log[p_\\theta(x|z_i, y) * p_\\psi(z_i|y) / q_\\phi(z_i|x,y)])} - \\log(K) \\newline = \\log {\\sum_{=1}^K \\exp(\\log[p_\\theta(x|z_i, y)] + \\log[p_\\psi(z_i|y)] - \\log[q_\\phi(z_i|x,y)])} - \\log(K) \\newline = \\operatorname{logsumexp}(\\log[p_\\theta(x|z_i, y)] + \\log[p_\\psi(z_i|y)] - \\log[q_\\phi(z_i|x,y)]) - \\log(K) \\newline = \\operatorname{logsumexp}(\\text{rec}\\_\\text{loss} + \\text{prior}\\_\\text{log}\\_\\text{prob} -  \\text{proposal}\\_\\text{log}\\_\\text{prob}) - \\log(K),$$ \\(z_i \\sim q_\\phi(z|x,y)\\).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"generate-samples-params","dir":"Reference","previous_headings":"","what":"generate_samples_params","title":"Initializing a vaeac model ‚Äî vaeac","text":"Generate parameters generative distributions samples batch. function makes K latent representation object batch, send latent representations decoder obtain parameters generative distributions. .e., means variances normal distributions (continuous features) probabilities categorical distribution (categorical features). second axis used index samples object, .e. batch shape [n x D1 x D2], result shape [n x K x D1 x D2]. better use inside torch::with_no_grad() order save memory. torch::with_no_grad() method require extra memory except memory result.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Initializing a vaeac model ‚Äî vaeac","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_categorical_parse_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","title":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","text":"Function takes tensor containing logits K classes. row corresponds observations. Send row softmax function convert logits probabilities sum 1 one. function also clamps probabilities minimum maximum probability. Note still normalize afterward, final probabilities can marginally thresholds.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_categorical_parse_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","text":"","code":"vaeac_categorical_parse_params(params, min_prob = 0, max_prob = 1)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_categorical_parse_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","text":"params Tensor dimension batch_size x K containing logits K classes batch_size observations. min_prob stability might desirable minimal probability close zero. max_prob stability might desirable maximal probability close one.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_categorical_parse_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","text":"torch::distr_categorical distributions provided probabilities class.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_categorical_parse_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","text":"Take Tensor (e. g. part neural network output) return torch::distr_categorical() distribution. input tensor applying softmax last axis contains batch categorical probabilities. restrictions input tensor. Technically, function treats last axis categorical probabilities, Categorical takes 2D input first axis batch axis second one corresponds probabilities, practically function requires 2D input batch probabilities one categorical feature. min_prob minimal probability class. clipping probabilities renormalized order valid distribution. regularization required numerical stability may considered neural network architecture choice without change probabilistic model.Note softmax function given \\(\\operatorname{Softmax}(x_i) = (\\exp(x_i))/(\\sum_{j} \\exp(x_j))\\), \\(x_i\\) logits can take value, negative positive. output \\(\\operatorname{Softmax}(x_i) \\[0,1]\\) \\(\\sum_{j} Softmax(x_i) = 1\\).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_categorical_parse_params.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Creates Categorical Distributions ‚Äî vaeac_categorical_parse_params","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_activation_func.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks the provided activation function ‚Äî vaeac_check_activation_func","title":"Function that checks the provided activation function ‚Äî vaeac_check_activation_func","text":"Function checks provided activation function","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_activation_func.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks the provided activation function ‚Äî vaeac_check_activation_func","text":"","code":"vaeac_check_activation_func(activation_function)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_activation_func.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks the provided activation function ‚Äî vaeac_check_activation_func","text":"activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu() (default), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_activation_func.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks the provided activation function ‚Äî vaeac_check_activation_func","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_activation_func.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks the provided activation function ‚Äî vaeac_check_activation_func","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_cuda.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks for access to CUDA ‚Äî vaeac_check_cuda","title":"Function that checks for access to CUDA ‚Äî vaeac_check_cuda","text":"Function checks access CUDA","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_cuda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks for access to CUDA ‚Äî vaeac_check_cuda","text":"","code":"vaeac_check_cuda(cuda, verbose)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_cuda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks for access to CUDA ‚Äî vaeac_check_cuda","text":"cuda Logical (default FALSE). TRUE, vaeac model trained using cuda/GPU. torch::cuda_is_available() FALSE, fall back using CPU. Using GPU smaller tabular dataset often improve efficiency. See vignette(\"installation\", package = \"torch\") fo help enable running GPU (Linux Windows). verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\").","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_cuda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks for access to CUDA ‚Äî vaeac_check_cuda","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_cuda.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks for access to CUDA ‚Äî vaeac_check_cuda","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_epoch_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks provided epoch arguments ‚Äî vaeac_check_epoch_values","title":"Function that checks provided epoch arguments ‚Äî vaeac_check_epoch_values","text":"Function checks provided epoch arguments","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_epoch_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks provided epoch arguments ‚Äî vaeac_check_epoch_values","text":"","code":"vaeac_check_epoch_values(   epochs,   epochs_initiation_phase,   epochs_early_stopping,   save_every_nth_epoch,   verbose )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_epoch_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks provided epoch arguments ‚Äî vaeac_check_epoch_values","text":"epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. epochs_initiation_phase Positive integer (default 2). number epochs run n_vaeacs_initialize vaeac models continuing train best performing model. epochs_early_stopping Positive integer (default NULL). training stops improvement validation IWAE epochs_early_stopping epochs. user wants training process solely based training criterion, epochs explain() set large number. NULL, shapr internally set epochs_early_stopping = vaeac.epochs early stopping occur. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\").","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_epoch_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks provided epoch arguments ‚Äî vaeac_check_epoch_values","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_epoch_values.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks provided epoch arguments ‚Äî vaeac_check_epoch_values","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_extra_named_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Check vaeac.extra_parameters list ‚Äî vaeac_check_extra_named_list","title":"Check vaeac.extra_parameters list ‚Äî vaeac_check_extra_named_list","text":"Check vaeac.extra_parameters list","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_extra_named_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check vaeac.extra_parameters list ‚Äî vaeac_check_extra_named_list","text":"","code":"vaeac_check_extra_named_list(vaeac.extra_parameters)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_extra_named_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check vaeac.extra_parameters list ‚Äî vaeac_check_extra_named_list","text":"vaeac.extra_parameters List containing extra parameters vaeac approach","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_extra_named_list.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Check vaeac.extra_parameters list ‚Äî vaeac_check_extra_named_list","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_logicals.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks logicals ‚Äî vaeac_check_logicals","title":"Function that checks logicals ‚Äî vaeac_check_logicals","text":"Function checks logicals","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_logicals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks logicals ‚Äî vaeac_check_logicals","text":"","code":"vaeac_check_logicals(named_list_logicals)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_logicals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks logicals ‚Äî vaeac_check_logicals","text":"named_list_logicals List containing named entries. .e., list(= TRUE, b = FALSE).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_logicals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks logicals ‚Äî vaeac_check_logicals","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_logicals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks logicals ‚Äî vaeac_check_logicals","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_mask_gen.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks the specified masking scheme ‚Äî vaeac_check_mask_gen","title":"Function that checks the specified masking scheme ‚Äî vaeac_check_mask_gen","text":"Function checks specified masking scheme","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_mask_gen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks the specified masking scheme ‚Äî vaeac_check_mask_gen","text":"","code":"vaeac_check_mask_gen(mask_gen_coalitions, mask_gen_coalitions_prob, x_train)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_mask_gen.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks the specified masking scheme ‚Äî vaeac_check_mask_gen","text":"mask_gen_coalitions Matrix (default NULL). Matrix containing coalitions vaeac model trained , see specified_masks_mask_generator(). parameter used internally shapr consider subset coalitions, .e., n_coalitions \\(< 2^{n_{\\text{features}}}\\), group Shapley, .e., group specified explain(). mask_gen_coalitions_prob Numeric array (default NULL). Array length equal height mask_gen_coalitions containing probabilities sampling corresponding coalitions mask_gen_coalitions. x_train data.table containing training data. Categorical data must class names \\(1,2,\\dots,K\\).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_mask_gen.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks the specified masking scheme ‚Äî vaeac_check_mask_gen","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_mask_gen.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks the specified masking scheme ‚Äî vaeac_check_mask_gen","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_masking_ratio.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks that the masking ratio argument is valid ‚Äî vaeac_check_masking_ratio","title":"Function that checks that the masking ratio argument is valid ‚Äî vaeac_check_masking_ratio","text":"Function checks masking ratio argument valid","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_masking_ratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks that the masking ratio argument is valid ‚Äî vaeac_check_masking_ratio","text":"","code":"vaeac_check_masking_ratio(masking_ratio, n_features)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_masking_ratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks that the masking ratio argument is valid ‚Äî vaeac_check_masking_ratio","text":"masking_ratio Numeric (default 0.5). Probability masking feature mcar_mask_generator() (MCAR = Missing Completely Random). MCAR masking scheme ensures vaeac model can arbitrary conditioning coalitions trained. masking_ratio overruled mask_gen_coalitions specified. n_features number features, .e., number columns training data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_masking_ratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks that the masking ratio argument is valid ‚Äî vaeac_check_masking_ratio","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_masking_ratio.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks that the masking ratio argument is valid ‚Äî vaeac_check_masking_ratio","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that calls all vaeac parameters check functions ‚Äî vaeac_check_parameters","title":"Function that calls all vaeac parameters check functions ‚Äî vaeac_check_parameters","text":"Function calls vaeac parameters check functions","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that calls all vaeac parameters check functions ‚Äî vaeac_check_parameters","text":"","code":"vaeac_check_parameters(   x_train,   model_description,   folder_to_save_model,   cuda,   n_vaeacs_initialize,   epochs_initiation_phase,   epochs,   epochs_early_stopping,   save_every_nth_epoch,   val_ratio,   val_iwae_n_samples,   depth,   width,   latent_dim,   lr,   batch_size,   running_avg_n_values,   activation_function,   skip_conn_layer,   skip_conn_masked_enc_dec,   batch_normalization,   paired_sampling,   masking_ratio,   mask_gen_coalitions,   mask_gen_coalitions_prob,   sigma_mu,   sigma_sigma,   save_data,   log_exp_cont_feat,   which_vaeac_model,   verbose,   seed,   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that calls all vaeac parameters check functions ‚Äî vaeac_check_parameters","text":"x_train data.table containing training data. Categorical data must class names \\(1,2,\\dots,K\\). model_description String (default make.names(Sys.time())). String containing, e.g., name data distribution additional parameter information. Used save name fitted model. provided, name generated based base::Sys.time() ensure unique name. use base::make.names() ensure valid file name operating systems. folder_to_save_model String (default base::tempdir()). String specifying path folder function save fitted vaeac model. Note  path removed returned explain() object vaeac.save_model = FALSE. cuda Logical (default FALSE). TRUE, vaeac model trained using cuda/GPU. torch::cuda_is_available() FALSE, fall back using CPU. Using GPU smaller tabular dataset often improve efficiency. See vignette(\"installation\", package = \"torch\") fo help enable running GPU (Linux Windows). n_vaeacs_initialize Positive integer (default 4). number different vaeac models initiate start. Pick best performing one epochs_initiation_phase epochs (default 2) continue training one. epochs_initiation_phase Positive integer (default 2). number epochs run n_vaeacs_initialize vaeac models continuing train best performing model. epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. epochs_early_stopping Positive integer (default NULL). training stops improvement validation IWAE epochs_early_stopping epochs. user wants training process solely based training criterion, epochs explain() set large number. NULL, shapr internally set epochs_early_stopping = vaeac.epochs early stopping occur. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. val_ratio Numeric (default 0.25). Scalar 0 1 indicating ratio instances input data used validation data. , val_ratio = 0.25 means 75% provided data used training data, remaining 25% used validation data. val_iwae_n_samples Positive integer (default 25). number generated samples used compute IWAE criterion validating vaeac model validation data. depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. latent_dim Positive integer (default 8). number dimensions latent space. lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. batch_size Positive integer (default 64). number samples include batch training vaeac model. Used torch::dataloader(). running_avg_n_values running_avg_n_values Positive integer (default 5). number previous IWAE values include compute running means IWAE criterion. activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu() (default), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid(). skip_conn_layer Logical (default TRUE). TRUE, apply identity skip connections layer, see skip_connection(). , add input \\(X\\) outcome hidden layer, output becomes \\(X + activation(WX + b)\\). skip_conn_masked_enc_dec Logical (default TRUE). TRUE, apply concatenate skip connections layers masked encoder decoder. first layer masked encoder linked last layer decoder. second layer masked encoder linked second last layer decoder, . batch_normalization Logical (default FALSE). TRUE, apply batch normalization activation function. Note skip_conn_layer = TRUE, normalization applied inclusion skip connection. , batch normalize whole quantity \\(X + activation(WX + b)\\). paired_sampling Logical (default TRUE). TRUE, apply paired sampling training batches. , training observations batch duplicated, first instance masked \\(S\\) second instance masked \\(\\bar{S}\\). ensures training vaeac model becomes stable model access full version training observation. However, increase training time due complex implementation doubling size batch. See paired_sampler() information. masking_ratio Numeric (default 0.5). Probability masking feature mcar_mask_generator() (MCAR = Missing Completely Random). MCAR masking scheme ensures vaeac model can arbitrary conditioning coalitions trained. masking_ratio overruled mask_gen_coalitions specified. mask_gen_coalitions Matrix (default NULL). Matrix containing coalitions vaeac model trained , see specified_masks_mask_generator(). parameter used internally shapr consider subset coalitions, .e., n_coalitions \\(< 2^{n_{\\text{features}}}\\), group Shapley, .e., group specified explain(). mask_gen_coalitions_prob Numeric array (default NULL). Array length equal height mask_gen_coalitions containing probabilities sampling corresponding coalitions mask_gen_coalitions. sigma_mu Numeric (default 1e4). One two hyperparameter values normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). sigma_sigma Numeric (default 1e-4). One two hyperparameter values normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). save_data Logical (default FALSE). TRUE, data stored together model. Useful one continue train model later using vaeac_train_model_continue(). log_exp_cont_feat Logical (default FALSE). \\(\\log\\) transform continuous features sending data vaeac(). vaeac model creates unbounded Monte Carlo sample values. Thus, continuous features strictly positive (, e.g., Burr distribution Abalone data set), can advantageous \\(\\log\\) transform data unbounded form using vaeac. TRUE, vaeac_postprocess_data() take \\(\\exp\\) results get back strictly positive values using vaeac model impute missing values/generate Monte Carlo samples. which_vaeac_model String (default best). name vaeac model (snapshots different epochs) use generating Monte Carlo samples. standard choices : \"best\" (epoch lowest IWAE), \"best_running\" (epoch lowest running IWAE, see vaeac.running_avg_n_values), last (last epoch). Note additional choices available vaeac.save_every_nth_epoch provided. example, vaeac.save_every_nth_epoch = 5, vaeac.which_vaeac_model can also take values \"epoch_5\", \"epoch_10\", \"epoch_15\", . verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). seed Positive integer (default 1). Seed reproducibility. Specifies seed randomness based code run. ... List extra parameters, currently used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that calls all vaeac parameters check functions ‚Äî vaeac_check_parameters","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_parameters.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that calls all vaeac parameters check functions ‚Äî vaeac_check_parameters","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_integers.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks positive integers ‚Äî vaeac_check_positive_integers","title":"Function that checks positive integers ‚Äî vaeac_check_positive_integers","text":"Function checks positive integers","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_integers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks positive integers ‚Äî vaeac_check_positive_integers","text":"","code":"vaeac_check_positive_integers(named_list_positive_integers)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_integers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks positive integers ‚Äî vaeac_check_positive_integers","text":"named_list_positive_integers List containing named entries. .e., list(= 1, b = 2).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_integers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks positive integers ‚Äî vaeac_check_positive_integers","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_integers.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks positive integers ‚Äî vaeac_check_positive_integers","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_numerics.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks positive numerics ‚Äî vaeac_check_positive_numerics","title":"Function that checks positive numerics ‚Äî vaeac_check_positive_numerics","text":"Function checks positive numerics","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_numerics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks positive numerics ‚Äî vaeac_check_positive_numerics","text":"","code":"vaeac_check_positive_numerics(named_list_positive_numerics)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_numerics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks positive numerics ‚Äî vaeac_check_positive_numerics","text":"named_list_positive_numerics List containing named entries. .e., list(= 0.2, b = 10^3).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_numerics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks positive numerics ‚Äî vaeac_check_positive_numerics","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_positive_numerics.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks positive numerics ‚Äî vaeac_check_positive_numerics","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_probabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks probabilities ‚Äî vaeac_check_probabilities","title":"Function that checks probabilities ‚Äî vaeac_check_probabilities","text":"Function checks probabilities","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_probabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks probabilities ‚Äî vaeac_check_probabilities","text":"","code":"vaeac_check_probabilities(named_list_probabilities)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_probabilities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks probabilities ‚Äî vaeac_check_probabilities","text":"named_list_probabilities List containing named entries. .e., list(= 0.2, b = 0.9).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_probabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks probabilities ‚Äî vaeac_check_probabilities","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_probabilities.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks probabilities ‚Äî vaeac_check_probabilities","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks that the save folder exists and for a valid file name ‚Äî vaeac_check_save_names","title":"Function that checks that the save folder exists and for a valid file name ‚Äî vaeac_check_save_names","text":"Function checks save folder exists valid file name","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks that the save folder exists and for a valid file name ‚Äî vaeac_check_save_names","text":"","code":"vaeac_check_save_names(folder_to_save_model, model_description)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks that the save folder exists and for a valid file name ‚Äî vaeac_check_save_names","text":"folder_to_save_model String (default base::tempdir()). String specifying path folder function save fitted vaeac model. Note  path removed returned explain() object vaeac.save_model = FALSE. model_description String (default make.names(Sys.time())). String containing, e.g., name data distribution additional parameter information. Used save name fitted model. provided, name generated based base::Sys.time() ensure unique name. use base::make.names() ensure valid file name operating systems.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks that the save folder exists and for a valid file name ‚Äî vaeac_check_save_names","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_names.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks that the save folder exists and for a valid file name ‚Äî vaeac_check_save_names","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_parameters.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that gives a warning about disk usage ‚Äî vaeac_check_save_parameters","title":"Function that gives a warning about disk usage ‚Äî vaeac_check_save_parameters","text":"Function gives warning disk usage","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_parameters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that gives a warning about disk usage ‚Äî vaeac_check_save_parameters","text":"","code":"vaeac_check_save_parameters(   save_data,   epochs,   save_every_nth_epoch,   x_train_size,   verbose )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_parameters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that gives a warning about disk usage ‚Äî vaeac_check_save_parameters","text":"save_data Logical (default FALSE). TRUE, data stored together model. Useful one continue train model later using vaeac_train_model_continue(). epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. x_train_size object size x_train object. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\").","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_parameters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that gives a warning about disk usage ‚Äî vaeac_check_save_parameters","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_save_parameters.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that gives a warning about disk usage ‚Äî vaeac_check_save_parameters","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_which_vaeac_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks for valid vaeac model name ‚Äî vaeac_check_which_vaeac_model","title":"Function that checks for valid vaeac model name ‚Äî vaeac_check_which_vaeac_model","text":"Function checks valid vaeac model name","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_which_vaeac_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks for valid vaeac model name ‚Äî vaeac_check_which_vaeac_model","text":"","code":"vaeac_check_which_vaeac_model(   which_vaeac_model,   epochs,   save_every_nth_epoch = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_which_vaeac_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks for valid vaeac model name ‚Äî vaeac_check_which_vaeac_model","text":"which_vaeac_model String (default best). name vaeac model (snapshots different epochs) use generating Monte Carlo samples. standard choices : \"best\" (epoch lowest IWAE), \"best_running\" (epoch lowest running IWAE, see vaeac.running_avg_n_values), last (last epoch). Note additional choices available vaeac.save_every_nth_epoch provided. example, vaeac.save_every_nth_epoch = 5, vaeac.which_vaeac_model can also take values \"epoch_5\", \"epoch_10\", \"epoch_15\", . epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_which_vaeac_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks for valid vaeac model name ‚Äî vaeac_check_which_vaeac_model","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_which_vaeac_model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks for valid vaeac model name ‚Äî vaeac_check_which_vaeac_model","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_x_colnames.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks the feature names of data and vaeac model ‚Äî vaeac_check_x_colnames","title":"Function that checks the feature names of data and vaeac model ‚Äî vaeac_check_x_colnames","text":"Function checks feature names data vaeac model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_x_colnames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks the feature names of data and vaeac model ‚Äî vaeac_check_x_colnames","text":"","code":"vaeac_check_x_colnames(feature_names_vaeac, feature_names_new)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_x_colnames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks the feature names of data and vaeac model ‚Äî vaeac_check_x_colnames","text":"feature_names_vaeac Array strings containing feature names vaeac model. feature_names_new Array strings containing feature names compare .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_x_colnames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks the feature names of data and vaeac model ‚Äî vaeac_check_x_colnames","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_check_x_colnames.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks the feature names of data and vaeac model ‚Äî vaeac_check_x_colnames","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_compute_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Featurewise Means and Standard Deviations ‚Äî vaeac_compute_normalization","title":"Compute Featurewise Means and Standard Deviations ‚Äî vaeac_compute_normalization","text":"Returns means standard deviations continuous features data set. Categorical features get \\(mean = 0\\) \\(sd = 1\\) default.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_compute_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Featurewise Means and Standard Deviations ‚Äî vaeac_compute_normalization","text":"","code":"vaeac_compute_normalization(data, one_hot_max_sizes)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_compute_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Featurewise Means and Standard Deviations ‚Äî vaeac_compute_normalization","text":"data torch_tensor dimension n_observation x n_features containing data. one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_compute_normalization.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Featurewise Means and Standard Deviations ‚Äî vaeac_compute_normalization","text":"List containing means standard deviations different features.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_compute_normalization.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute Featurewise Means and Standard Deviations ‚Äî vaeac_compute_normalization","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset used by the vaeac model ‚Äî vaeac_dataset","title":"Dataset used by the vaeac model ‚Äî vaeac_dataset","text":"Convert data torch::dataset() vaeac model creates batches .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset used by the vaeac model ‚Äî vaeac_dataset","text":"","code":"vaeac_dataset(X, one_hot_max_sizes)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataset used by the vaeac model ‚Äî vaeac_dataset","text":"X torch_tensor contain data shape N x p, N p number observations features, respectively. one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_dataset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dataset used by the vaeac model ‚Äî vaeac_dataset","text":"function creates torch::dataset() object represent map keys data samples. used torch::dataloader() load data used extract batches epochs training phase neural network. Note dataset object R6 instance, see https://r6.r-lib.org/articles/Introduction.html, classical object-oriented programming, self reference. .e, vaeac_dataset() subclass type torch::dataset().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_dataset.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Dataset used by the vaeac model ‚Äî vaeac_dataset","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_extend_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extends Incomplete Batches by Sampling Extra Data from Dataloader ‚Äî vaeac_extend_batch","title":"Extends Incomplete Batches by Sampling Extra Data from Dataloader ‚Äî vaeac_extend_batch","text":"height batch less batch_size, function extends batch data torch::dataloader() batch reaches required size. Note batch tensor.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_extend_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extends Incomplete Batches by Sampling Extra Data from Dataloader ‚Äî vaeac_extend_batch","text":"","code":"vaeac_extend_batch(batch, dataloader, batch_size)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_extend_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extends Incomplete Batches by Sampling Extra Data from Dataloader ‚Äî vaeac_extend_batch","text":"batch batch want check right size, extend right size. dataloader torch::dataloader() object can create iterator object load data extend batch. batch_size Integer. number samples include batch.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_extend_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extends Incomplete Batches by Sampling Extra Data from Dataloader ‚Äî vaeac_extend_batch","text":"Returns extended batch correct batch_size.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_extend_batch.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extends Incomplete Batches by Sampling Extra Data from Dataloader ‚Äî vaeac_extend_batch","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_current_save_state.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that extracts additional objects from the environment into the state list ‚Äî vaeac_get_current_save_state","title":"Function that extracts additional objects from the environment into the state list ‚Äî vaeac_get_current_save_state","text":"function extract objects going save together vaeac model make possible train model evaluate . environment local environment inside vaeac_train_model_auxiliary() function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_current_save_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that extracts additional objects from the environment into the state list ‚Äî vaeac_get_current_save_state","text":"","code":"vaeac_get_current_save_state(environment)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_current_save_state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that extracts additional objects from the environment into the state list ‚Äî vaeac_get_current_save_state","text":"environment base::environment() objects stored.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_current_save_state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that extracts additional objects from the environment into the state list ‚Äî vaeac_get_current_save_state","text":"List containing values epoch, train_vlb, val_iwae, val_iwae_running, state_dict() vaeac model optimizer.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_current_save_state.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that extracts additional objects from the environment into the state list ‚Äî vaeac_get_current_save_state","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_data_objects.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to set up data loaders and save file names ‚Äî vaeac_get_data_objects","title":"Function to set up data loaders and save file names ‚Äî vaeac_get_data_objects","text":"Function set data loaders save file names","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_data_objects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to set up data loaders and save file names ‚Äî vaeac_get_data_objects","text":"","code":"vaeac_get_data_objects(   x_train,   log_exp_cont_feat,   val_ratio,   batch_size,   paired_sampling,   model_description,   depth,   width,   latent_dim,   lr,   epochs,   save_every_nth_epoch,   folder_to_save_model,   train_indices = NULL,   val_indices = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_data_objects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to set up data loaders and save file names ‚Äî vaeac_get_data_objects","text":"x_train data.table containing training data. Categorical data must class names \\(1,2,\\dots,K\\). log_exp_cont_feat Logical (default FALSE). \\(\\log\\) transform continuous features sending data vaeac(). vaeac model creates unbounded Monte Carlo sample values. Thus, continuous features strictly positive (, e.g., Burr distribution Abalone data set), can advantageous \\(\\log\\) transform data unbounded form using vaeac. TRUE, vaeac_postprocess_data() take \\(\\exp\\) results get back strictly positive values using vaeac model impute missing values/generate Monte Carlo samples. val_ratio Numeric (default 0.25). Scalar 0 1 indicating ratio instances input data used validation data. , val_ratio = 0.25 means 75% provided data used training data, remaining 25% used validation data. batch_size Positive integer (default 64). number samples include batch training vaeac model. Used torch::dataloader(). paired_sampling Logical (default TRUE). TRUE, apply paired sampling training batches. , training observations batch duplicated, first instance masked \\(S\\) second instance masked \\(\\bar{S}\\). ensures training vaeac model becomes stable model access full version training observation. However, increase training time due complex implementation doubling size batch. See paired_sampler() information. model_description String (default make.names(Sys.time())). String containing, e.g., name data distribution additional parameter information. Used save name fitted model. provided, name generated based base::Sys.time() ensure unique name. use base::make.names() ensure valid file name operating systems. depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. latent_dim Positive integer (default 8). number dimensions latent space. lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. folder_to_save_model String (default base::tempdir()). String specifying path folder function save fitted vaeac model. Note  path removed returned explain() object vaeac.save_model = FALSE. train_indices Numeric array (optional) containing indices training observations. conducted checks validate indices. val_indices Numeric array (optional) containing indices validation observations. #' conducted checks validate indices.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_data_objects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to set up data loaders and save file names ‚Äî vaeac_get_data_objects","text":"List objects needed train vaeac model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_evaluation_criteria.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the Training VLB and Validation IWAE from a list of explanations objects using the vaeac approach ‚Äî vaeac_get_evaluation_criteria","title":"Extract the Training VLB and Validation IWAE from a list of explanations objects using the vaeac approach ‚Äî vaeac_get_evaluation_criteria","text":"Extract Training VLB Validation IWAE list explanations objects using vaeac approach","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_evaluation_criteria.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the Training VLB and Validation IWAE from a list of explanations objects using the vaeac approach ‚Äî vaeac_get_evaluation_criteria","text":"","code":"vaeac_get_evaluation_criteria(explanation_list)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_evaluation_criteria.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the Training VLB and Validation IWAE from a list of explanations objects using the vaeac approach ‚Äî vaeac_get_evaluation_criteria","text":"explanation_list list explain() objects applied data, model, vaeac must used approach. entries list named, function use names. Otherwise, defaults approach names (integer suffix duplicates) explanation objects explanation_list.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_evaluation_criteria.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the Training VLB and Validation IWAE from a list of explanations objects using the vaeac approach ‚Äî vaeac_get_evaluation_criteria","text":"data.table containing training VLB, validation IWAE, running validation IWAE epoch vaeac model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_evaluation_criteria.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract the Training VLB and Validation IWAE from a list of explanations objects using the vaeac approach ‚Äî vaeac_get_evaluation_criteria","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"function, specify default values extra parameters used explain() approach = \"vaeac\".","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"","code":"vaeac_get_extra_para_default(   vaeac.model_description = make.names(Sys.time()),   vaeac.folder_to_save_model = tempdir(),   vaeac.pretrained_vaeac_model = NULL,   vaeac.cuda = FALSE,   vaeac.epochs_initiation_phase = 2,   vaeac.epochs_early_stopping = NULL,   vaeac.save_every_nth_epoch = NULL,   vaeac.val_ratio = 0.25,   vaeac.val_iwae_n_samples = 25,   vaeac.batch_size = 64,   vaeac.batch_size_sampling = NULL,   vaeac.running_avg_n_values = 5,   vaeac.skip_conn_layer = TRUE,   vaeac.skip_conn_masked_enc_dec = TRUE,   vaeac.batch_normalization = FALSE,   vaeac.paired_sampling = TRUE,   vaeac.masking_ratio = 0.5,   vaeac.mask_gen_coalitions = NULL,   vaeac.mask_gen_coalitions_prob = NULL,   vaeac.sigma_mu = 10000,   vaeac.sigma_sigma = 1e-04,   vaeac.sample_random = TRUE,   vaeac.save_data = FALSE,   vaeac.log_exp_cont_feat = FALSE,   vaeac.which_vaeac_model = \"best\",   vaeac.save_model = TRUE )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"vaeac.model_description String (default make.names(Sys.time())). String containing, e.g., name data distribution additional parameter information. Used save name fitted model. provided, name generated based base::Sys.time() ensure unique name. use base::make.names() ensure valid file name operating systems. vaeac.folder_to_save_model String (default base::tempdir()). String specifying path folder function save fitted vaeac model. Note path removed returned explain() object vaeac.save_model = FALSE. Furthermore, model moved original folder use vaeac_train_model_continue() function continue training model. vaeac.pretrained_vaeac_model List String (default NULL). 1) Either list class vaeac, .e., list stored explanation$internal$parameters$vaeac explanation returned list earlier call explain() function. 2) string containing path vaeac model stored disk, example, explanation$internal$parameters$vaeac$models$best. vaeac.cuda Logical (default FALSE). TRUE, vaeac model trained using cuda/GPU. torch::cuda_is_available() FALSE, fall back using CPU. Using GPU smaller tabular dataset often improve efficiency. See vignette(\"installation\", package = \"torch\") fo help enable running GPU (Linux Windows). vaeac.epochs_initiation_phase Positive integer (default 2). number epochs run vaeac.n_vaeacs_initialize vaeac models continuing train best performing model. vaeac.epochs_early_stopping Positive integer (default NULL). training stops improvement validation IWAE vaeac.epochs_early_stopping epochs. user wants training process solely based training criterion, vaeac.epochs explain() set large number. NULL, shapr internally set vaeac.epochs_early_stopping = vaeac.epochs early stopping occur. vaeac.save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every vaeac.save_every_nth_epochth epoch saved. vaeac.val_ratio Numeric (default 0.25). Scalar 0 1 indicating ratio instances input data used validation data. , vaeac.val_ratio = 0.25 means 75% provided data used training data, remaining 25% used validation data. vaeac.val_iwae_n_samples Positive integer (default 25). number generated samples used compute IWAE criterion validating vaeac model validation data. vaeac.batch_size Positive integer (default 64). number samples include batch training vaeac model. Used torch::dataloader(). vaeac.batch_size_sampling Positive integer (default NULL) number samples include batch generating Monte Carlo samples. NULL, function generates Monte Carlo samples provided coalitions explicands sent explain() time. number coalitions determined n_batches used explain(). recommend tweak extra_computation_args$max_batch_size extra_computation_args$min_n_batches rather vaeac.batch_size_sampling. Larger batch sizes often much faster provided sufficient memory. vaeac.running_avg_n_values Positive integer (default 5). number previous IWAE values include compute running means IWAE criterion. vaeac.skip_conn_layer Logical (default TRUE). TRUE, apply identity skip connections layer, see skip_connection(). , add input \\(X\\) outcome hidden layer, output becomes \\(X + activation(WX + b)\\). vaeac.skip_conn_masked_enc_dec Logical (default TRUE). TRUE, apply concatenate skip connections layers masked encoder decoder. first layer masked encoder linked last layer decoder. second layer masked encoder linked second last layer decoder, . vaeac.batch_normalization Logical (default FALSE). TRUE, apply batch normalization activation function. Note vaeac.skip_conn_layer = TRUE, normalization applied inclusion skip connection. , batch normalize whole quantity \\(X + activation(WX + b)\\). vaeac.paired_sampling Logical (default TRUE). TRUE, apply paired sampling training batches. , training observations batch duplicated, first instance masked \\(S\\) second instance masked \\(\\bar{S}\\). ensures training vaeac model becomes stable model access full version training observation. However, increase training time due complex implementation doubling size batch. See paired_sampler() information. vaeac.masking_ratio Numeric (default 0.5). Probability masking feature mcar_mask_generator() (MCAR = Missing Completely Random). MCAR masking scheme ensures vaeac model can arbitrary conditioning coalitions trained. vaeac.masking_ratio overruled vaeac.mask_gen_coalitions specified. vaeac.mask_gen_coalitions Matrix (default NULL). Matrix containing coalitions vaeac model trained , see specified_masks_mask_generator(). parameter used internally shapr consider subset coalitions, .e., n_coalitions \\(< 2^{n_{\\text{features}}}\\), group Shapley, .e., group specified explain(). vaeac.mask_gen_coalitions_prob Numeric array (default NULL). Array length equal height vaeac.mask_gen_coalitions containing probabilities sampling corresponding coalitions vaeac.mask_gen_coalitions. vaeac.sigma_mu Numeric (default 1e4). One two hyperparameter values normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). vaeac.sigma_sigma Numeric (default 1e-4). One two hyperparameter values normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). vaeac.sample_random Logical (default TRUE). TRUE, function generates random Monte Carlo samples inferred generative distributions. FALSE, function use likely values, .e., mean class highest probability continuous categorical, respectively. vaeac.save_data Logical (default FALSE). TRUE, data stored together model. Useful one continue train model later using vaeac_train_model_continue(). vaeac.log_exp_cont_feat Logical (default FALSE). \\(\\log\\) transform continuous features sending data vaeac(). vaeac model creates unbounded Monte Carlo sample values. Thus, continuous features strictly positive (, e.g., Burr distribution Abalone data set), can advantageous \\(\\log\\) transform data unbounded form using vaeac. TRUE, vaeac_postprocess_data() take \\(\\exp\\) results get back strictly positive values using vaeac model impute missing values/generate Monte Carlo samples. vaeac.which_vaeac_model String (default best). name vaeac model (snapshots different epochs) use generating Monte Carlo samples. standard choices : \"best\" (epoch lowest IWAE), \"best_running\" (epoch lowest running IWAE, see vaeac.running_avg_n_values), last (last epoch). Note additional choices available vaeac.save_every_nth_epoch provided. example, vaeac.save_every_nth_epoch = 5, vaeac.which_vaeac_model can also take values \"epoch_5\", \"epoch_10\", \"epoch_15\", . vaeac.save_model Boolean. TRUE (default), vaeac model saved either base::tempdir() folder user specified location vaeac.folder_to_save_model. FALSE, paths model model deleted returned object explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"Named list default values vaeac extra parameter arguments specified function call. Note vaeac.model_description vaeac.folder_to_save_model change time R session.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"vaeac model consists three neural network (full encoder, masked encoder, decoder) based provided vaeac.depth vaeac.width. encoders map full masked input representations latent representations, respectively, dimension given vaeac.latent_dim. latent representations sent decoder go back real feature space provide samplable probabilistic representation, Monte Carlo samples generated. use vaeac method epoch lowest validation error (IWAE) default, possibilities available setting vaeac.which_vaeac_model parameter. See Olsen et al. (2022) details.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_extra_para_default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to specify the extra parameters in the vaeac model ‚Äî vaeac_get_extra_para_default","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_full_state_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that extracts the state list objects from the environment ‚Äî vaeac_get_full_state_list","title":"Function that extracts the state list objects from the environment ‚Äî vaeac_get_full_state_list","text":"#' @description function extract objects going save together vaeac model make possible train model evaluate . environment local environment inside vaeac_train_model_auxiliary() function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_full_state_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that extracts the state list objects from the environment ‚Äî vaeac_get_full_state_list","text":"","code":"vaeac_get_full_state_list(environment)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_full_state_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that extracts the state list objects from the environment ‚Äî vaeac_get_full_state_list","text":"environment base::environment() objects stored.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_full_state_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that extracts the state list objects from the environment ‚Äî vaeac_get_full_state_list","text":"List containing values norm_mean, norm_std, model_description, folder_to_save_model, n_train, n_features, one_hot_max_sizes, epochs, epochs_specified, epochs_early_stopping, early_stopping_applied, running_avg_n_values, paired_sampling, mask_generator_name, masking_ratio, mask_gen_coalitions, mask_gen_coalitions_prob, val_ratio, val_iwae_n_samples, n_vaeacs_initialize, epochs_initiation_phase, width, depth, latent_dim, activation_function, lr, batch_size, skip_conn_layer, skip_conn_masked_enc_dec, batch_normalization, cuda, train_indices, val_indices, save_every_nth_epoch, sigma_mu, sigma_sigma, feature_list, col_cat_names, col_cont_names, col_cat, col_cont, cat_in_dataset, map_new_to_original_names, map_original_to_new_names, log_exp_cont_feat, save_data, verbose, seed, vaeac_save_file_names.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_full_state_list.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that extracts the state list objects from the environment ‚Äî vaeac_get_full_state_list","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_mask_generator_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that determines which mask generator to use ‚Äî vaeac_get_mask_generator_name","title":"Function that determines which mask generator to use ‚Äî vaeac_get_mask_generator_name","text":"Function determines mask generator use","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_mask_generator_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that determines which mask generator to use ‚Äî vaeac_get_mask_generator_name","text":"","code":"vaeac_get_mask_generator_name(   mask_gen_coalitions,   mask_gen_coalitions_prob,   masking_ratio,   verbose )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_mask_generator_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that determines which mask generator to use ‚Äî vaeac_get_mask_generator_name","text":"mask_gen_coalitions Matrix (default NULL). Matrix containing coalitions vaeac model trained , see specified_masks_mask_generator(). parameter used internally shapr consider subset coalitions, .e., n_coalitions \\(< 2^{n_{\\text{features}}}\\), group Shapley, .e., group specified explain(). mask_gen_coalitions_prob Numeric array (default NULL). Array length equal height mask_gen_coalitions containing probabilities sampling corresponding coalitions mask_gen_coalitions. masking_ratio Numeric (default 0.5). Probability masking feature mcar_mask_generator() (MCAR = Missing Completely Random). MCAR masking scheme ensures vaeac model can arbitrary conditioning coalitions trained. masking_ratio overruled mask_gen_coalitions specified. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\").","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_mask_generator_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that determines which mask generator to use ‚Äî vaeac_get_mask_generator_name","text":"function return anything.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_mask_generator_name.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that determines which mask generator to use ‚Äî vaeac_get_mask_generator_name","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_model_from_checkp.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to load a vaeac model and set it in the right state and mode ‚Äî vaeac_get_model_from_checkp","title":"Function to load a vaeac model and set it in the right state and mode ‚Äî vaeac_get_model_from_checkp","text":"Function load vaeac model set right state mode","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_model_from_checkp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to load a vaeac model and set it in the right state and mode ‚Äî vaeac_get_model_from_checkp","text":"","code":"vaeac_get_model_from_checkp(checkpoint, cuda, mode_train)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_model_from_checkp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to load a vaeac model and set it in the right state and mode ‚Äî vaeac_get_model_from_checkp","text":"checkpoint List. must loaded vaeac save object. , torch::torch_load('vaeac_save_path'). cuda Logical (default FALSE). TRUE, vaeac model trained using cuda/GPU. torch::cuda_is_available() FALSE, fall back using CPU. Using GPU smaller tabular dataset often improve efficiency. See vignette(\"installation\", package = \"torch\") fo help enable running GPU (Linux Windows). mode_train Logical. TRUE, returned vaeac model set training mode. FALSE, returned vaeac model set evaluation mode.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_model_from_checkp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to load a vaeac model and set it in the right state and mode ‚Äî vaeac_get_model_from_checkp","text":"vaeac model correct state (based checkpoint), sent desired hardware (based cuda), right mode (based mode_train).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_model_from_checkp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to load a vaeac model and set it in the right state and mode ‚Äî vaeac_get_model_from_checkp","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_n_decimals.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to get string of values with specific number of decimals ‚Äî vaeac_get_n_decimals","title":"Function to get string of values with specific number of decimals ‚Äî vaeac_get_n_decimals","text":"Function get string values specific number decimals","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_n_decimals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to get string of values with specific number of decimals ‚Äî vaeac_get_n_decimals","text":"","code":"vaeac_get_n_decimals(value, n_decimals = 3)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_n_decimals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to get string of values with specific number of decimals ‚Äî vaeac_get_n_decimals","text":"value number get n_decimals . n_decimals Positive integer. number decimals. Default three.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_n_decimals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to get string of values with specific number of decimals ‚Äî vaeac_get_n_decimals","text":"String value n_decimals decimals.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_n_decimals.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to get string of values with specific number of decimals ‚Äî vaeac_get_n_decimals","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_optimizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create the optimizer used to train vaeac ‚Äî vaeac_get_optimizer","title":"Function to create the optimizer used to train vaeac ‚Äî vaeac_get_optimizer","text":"torch::optim_adam() currently supported. easy add additional option later.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_optimizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create the optimizer used to train vaeac ‚Äî vaeac_get_optimizer","text":"","code":"vaeac_get_optimizer(vaeac_model, lr, optimizer_name = \"adam\")"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_optimizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to create the optimizer used to train vaeac ‚Äî vaeac_get_optimizer","text":"vaeac_model vaeac model created using vaeac(). lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. optimizer_name String containing name torch::optimizer() use.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_optimizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to create the optimizer used to train vaeac ‚Äî vaeac_get_optimizer","text":"torch::optim_adam() optimizer connected parameters vaeac_model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_optimizer.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to create the optimizer used to train vaeac ‚Äî vaeac_get_optimizer","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_save_file_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that creates the save file names for the vaeac model ‚Äî vaeac_get_save_file_names","title":"Function that creates the save file names for the vaeac model ‚Äî vaeac_get_save_file_names","text":"Function creates save file names vaeac model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_save_file_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that creates the save file names for the vaeac model ‚Äî vaeac_get_save_file_names","text":"","code":"vaeac_get_save_file_names(   model_description,   n_features,   n_train,   depth,   width,   latent_dim,   lr,   epochs,   save_every_nth_epoch,   folder_to_save_model = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_save_file_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that creates the save file names for the vaeac model ‚Äî vaeac_get_save_file_names","text":"model_description String (default make.names(Sys.time())). String containing, e.g., name data distribution additional parameter information. Used save name fitted model. provided, name generated based base::Sys.time() ensure unique name. use base::make.names() ensure valid file name operating systems. depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. latent_dim Positive integer (default 8). number dimensions latent space. lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. folder_to_save_model String (default base::tempdir()). String specifying path folder function save fitted vaeac model. Note  path removed returned explain() object vaeac.save_model = FALSE.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_save_file_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that creates the save file names for the vaeac model ‚Äî vaeac_get_save_file_names","text":"Array string containing save files use training vaeac model. first three names corresponds best, best_running, last epochs, order.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_save_file_names.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that creates the save file names for the vaeac model ‚Äî vaeac_get_save_file_names","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_val_iwae.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","title":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","text":"Compute Importance Sampling Estimator vaeac model uses evaluate performance validation data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_val_iwae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","text":"","code":"vaeac_get_val_iwae(   val_dataloader,   mask_generator,   batch_size,   vaeac_model,   val_iwae_n_samples )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_val_iwae.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","text":"val_dataloader torch dataloader loads validation data. mask_generator mask generator object generates masks. batch_size Integer. number samples include batch. vaeac_model vaeac model. val_iwae_n_samples Number samples generate computing IWAE validation sample.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_val_iwae.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","text":"average iwae instances validation dataset.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_val_iwae.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","text":"Compute mean IWAE log likelihood estimation validation set. IWAE abbreviation Importance Sampling Estimator $$\\log p_{\\theta, \\psi}(x|y) \\approx \\log {\\frac{1}{S}\\sum_{=1}^S p_\\theta(x|z_i, y) p_\\psi(z_i|y) \\big/ q_\\phi(z_i|x,y),}$$ \\(z_i \\sim q_\\phi(z|x,y)\\). details, see Olsen et al. (2022).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_val_iwae.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the Importance Sampling Estimator (Validation Error) ‚Äî vaeac_get_val_iwae","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_x_explain_extended.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to extend the explicands and apply all relevant masks/coalitions ‚Äî vaeac_get_x_explain_extended","title":"Function to extend the explicands and apply all relevant masks/coalitions ‚Äî vaeac_get_x_explain_extended","text":"Function extend explicands apply relevant masks/coalitions","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_x_explain_extended.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to extend the explicands and apply all relevant masks/coalitions ‚Äî vaeac_get_x_explain_extended","text":"","code":"vaeac_get_x_explain_extended(x_explain, S, index_features)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_x_explain_extended.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to extend the explicands and apply all relevant masks/coalitions ‚Äî vaeac_get_x_explain_extended","text":"x_explain Matrix data.frame/data.table. Features predictions explained. S internal$objects$S matrix containing possible coalitions. index_features Positive integer vector. Specifies id_coalition apply present method. NULL means coalitions. used internally.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_x_explain_extended.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to extend the explicands and apply all relevant masks/coalitions ‚Äî vaeac_get_x_explain_extended","text":"extended version x_explain masks S indices index_features applied.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_get_x_explain_extended.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to extend the explicands and apply all relevant masks/coalitions ‚Äî vaeac_get_x_explain_extended","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_impute_missing_entries.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","title":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","text":"Impute Missing Values Using Vaeac","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_impute_missing_entries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","text":"","code":"vaeac_impute_missing_entries(   x_explain_with_NaNs,   n_MC_samples,   vaeac_model,   checkpoint,   sampler,   batch_size,   verbose = NULL,   seed = NULL,   n_explain = NULL,   index_features = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_impute_missing_entries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","text":"x_explain_with_NaNs 2D matrix, missing entries impute represented NaN. n_MC_samples Integer. number imputed versions create row x_explain_with_NaNs. vaeac_model initialized vaeac model going use generate MC samples. checkpoint List containing parameters vaeac model. sampler sampler object used sample MC samples. batch_size Positive integer (default 64). number samples include batch training vaeac model. Used torch::dataloader(). verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). seed Positive integer (default 1). Seed reproducibility. Specifies seed randomness based code run. n_explain Positive integer. number explicands. index_features Optional integer vector. Used internally shapr package index coalitions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_impute_missing_entries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","text":"data.table missing values (NaN) x_explain_with_NaNs imputed n_MC_samples times. data table contain extra id columns index_features n_explain provided.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_impute_missing_entries.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","text":"Function imputes missing values 2D matrix row constitute individual. values sampled conditional distribution estimated vaeac model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_impute_missing_entries.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Impute Missing Values Using Vaeac ‚Äî vaeac_impute_missing_entries","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_kl_normal_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the KL Divergence Between Two Gaussian Distributions. ‚Äî vaeac_kl_normal_normal","title":"Compute the KL Divergence Between Two Gaussian Distributions. ‚Äî vaeac_kl_normal_normal","text":"Computes KL divergence univariate normal distributions using analytical formula, see https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_kl_normal_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the KL Divergence Between Two Gaussian Distributions. ‚Äî vaeac_kl_normal_normal","text":"","code":"vaeac_kl_normal_normal(p, q)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_kl_normal_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the KL Divergence Between Two Gaussian Distributions. ‚Äî vaeac_kl_normal_normal","text":"p torch::distr_normal() object. q torch::distr_normal() object.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_kl_normal_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the KL Divergence Between Two Gaussian Distributions. ‚Äî vaeac_kl_normal_normal","text":"KL divergence two Gaussian distributions.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_kl_normal_normal.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the KL Divergence Between Two Gaussian Distributions. ‚Äî vaeac_kl_normal_normal","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normal_parse_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","title":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","text":"Function takes tensor first half columns contains means normal distributions, latter half columns contains standard deviations. standard deviations clamped min_sigma ensure stable results. params dimensions batch_size x 8, function create 4 independent normal distributions observation (batch_size observations total).","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normal_parse_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","text":"","code":"vaeac_normal_parse_params(params, min_sigma = 1e-04)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normal_parse_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","text":"params Tensor dimension batch_size x 2*n_featuers containing means standard deviations used normal distributions batch_size observations. min_sigma stability might desirable minimal sigma close zero.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normal_parse_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","text":"torch::distr_normal() distribution provided means standard deviations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normal_parse_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","text":"Take Tensor (e.g. neural network output) return torch::distr_normal() distribution. normal distribution component-wise independent, dimensionality depends input shape. First half channels mean (\\(\\mu\\)) distribution, softplus second half std (\\(\\sigma\\)), restrictions input tensor. min_sigma minimal value \\(\\sigma\\). .e., softplus less min_sigma, \\(\\sigma\\) clipped value min_sigma. regularization required numerical stability may considered neural network architecture choice without change probabilistic model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normal_parse_params.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Creates Normal Distributions ‚Äî vaeac_normal_parse_params","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normalize_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize mixed data for vaeac ‚Äî vaeac_normalize_data","title":"Normalize mixed data for vaeac ‚Äî vaeac_normalize_data","text":"Compute mean std continuous feature, categorical features mean 0 std 1.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normalize_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize mixed data for vaeac ‚Äî vaeac_normalize_data","text":"","code":"vaeac_normalize_data(   data_torch,   one_hot_max_sizes,   norm_mean = NULL,   norm_std = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normalize_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize mixed data for vaeac ‚Äî vaeac_normalize_data","text":"one_hot_max_sizes torch tensor dimension n_features containing one hot sizes n_features features. , ith feature categorical feature 5 levels, one_hot_max_sizes[] = 5. size continuous features can either 0 1. norm_mean Torch tensor (optional). 1D array containing means columns x_torch. norm_std Torch tensor (optional). 1D array containing stds columns x_torch.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normalize_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize mixed data for vaeac ‚Äî vaeac_normalize_data","text":"list containing normalized version x_torch, norm_mean norm_std.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_normalize_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Normalize mixed data for vaeac ‚Äî vaeac_normalize_data","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_postprocess_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Postprocess Data Generated by a vaeac Model ‚Äî vaeac_postprocess_data","title":"Postprocess Data Generated by a vaeac Model ‚Äî vaeac_postprocess_data","text":"vaeac generates numerical values. function converts categorical features numerics class labels 1,2,...,K, factors original class labels.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_postprocess_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Postprocess Data Generated by a vaeac Model ‚Äî vaeac_postprocess_data","text":"","code":"vaeac_postprocess_data(data, vaeac_model_state_list)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_postprocess_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Postprocess Data Generated by a vaeac Model ‚Äî vaeac_postprocess_data","text":"data data.table containing data generated vaeac model vaeac_model_state_list List. returned list vaeac_preprocess_data function loaded checkpoint list saved vaeac object.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_postprocess_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Postprocess Data Generated by a vaeac Model ‚Äî vaeac_postprocess_data","text":"data.table generated data vaeac model categorical features now original class names.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_postprocess_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Postprocess Data Generated by a vaeac Model ‚Äî vaeac_postprocess_data","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_preprocess_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Data for the vaeac approach ‚Äî vaeac_preprocess_data","title":"Preprocess Data for the vaeac approach ‚Äî vaeac_preprocess_data","text":"vaeac supports numerical values. function converts categorical features numerics class labels 1,2,...,K, keeps track map original new class labels. also computes one_hot_max_sizes.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_preprocess_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Data for the vaeac approach ‚Äî vaeac_preprocess_data","text":"","code":"vaeac_preprocess_data(   data,   log_exp_cont_feat = FALSE,   normalize = TRUE,   norm_mean = NULL,   norm_std = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_preprocess_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Data for the vaeac approach ‚Äî vaeac_preprocess_data","text":"data matrix/data.frame/data.table containing training data. features response. log_exp_cont_feat Boolean. log transform continuous features sending data vaeac. vaeac creates unbounded values, continuous features strictly positive, Burr Abalone data, can advantageous log-transform data unbounded form using vaeac. TRUE, vaeac_postprocess_data take exp results get back strictly positive values. norm_mean Torch tensor (optional). 1D array containing means columns x_torch. norm_std Torch tensor (optional). 1D array containing stds columns x_torch.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_preprocess_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Data for the vaeac approach ‚Äî vaeac_preprocess_data","text":"list containing data can used vaeac, maps original new class names categorical features, one_hot_max_sizes, list information data.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_preprocess_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Preprocess Data for the vaeac approach ‚Äî vaeac_preprocess_data","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_print_train_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to printout a training summary for the vaeac model ‚Äî vaeac_print_train_summary","title":"Function to printout a training summary for the vaeac model ‚Äî vaeac_print_train_summary","text":"Function printout training summary vaeac model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_print_train_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to printout a training summary for the vaeac model ‚Äî vaeac_print_train_summary","text":"","code":"vaeac_print_train_summary(best_epoch, best_epoch_running, last_state)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_print_train_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to printout a training summary for the vaeac model ‚Äî vaeac_print_train_summary","text":"best_epoch Positive integer. epoch lowest validation error. best_epoch_running Positive integer. epoch lowest running validation error. last_state state list (.e., saved vaeac object) vaeac model epoch lowest IWAE.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_print_train_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to printout a training summary for the vaeac model ‚Äî vaeac_print_train_summary","text":"function prints message.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_print_train_summary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function to printout a training summary for the vaeac model ‚Äî vaeac_print_train_summary","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_save_state.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that saves the state list and the current save state of the vaeac model ‚Äî vaeac_save_state","title":"Function that saves the state list and the current save state of the vaeac model ‚Äî vaeac_save_state","text":"Function saves state list current save state vaeac model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_save_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that saves the state list and the current save state of the vaeac model ‚Äî vaeac_save_state","text":"","code":"vaeac_save_state(state_list, file_name, return_state = FALSE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_save_state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that saves the state list and the current save state of the vaeac model ‚Äî vaeac_save_state","text":"state_list List containing parameters state. file_name String containing file path. return_state Logical return state list .","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_save_state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that saves the state list and the current save state of the vaeac model ‚Äî vaeac_save_state","text":"function return anything","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_save_state.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that saves the state list and the current save state of the vaeac model ‚Äî vaeac_save_state","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Train the Vaeac Model ‚Äî vaeac_train_model","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"Function fits vaeac model given dataset based provided parameters, described Olsen et al. (2022). Note default parameters specified origin setup_approach.vaeac() vaeac_get_extra_para_default().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"","code":"vaeac_train_model(   x_train,   model_description,   folder_to_save_model,   cuda,   n_vaeacs_initialize,   epochs_initiation_phase,   epochs,   epochs_early_stopping,   save_every_nth_epoch,   val_ratio,   val_iwae_n_samples,   depth,   width,   latent_dim,   lr,   batch_size,   running_avg_n_values,   activation_function,   skip_conn_layer,   skip_conn_masked_enc_dec,   batch_normalization,   paired_sampling,   masking_ratio,   mask_gen_coalitions,   mask_gen_coalitions_prob,   sigma_mu,   sigma_sigma,   save_data,   log_exp_cont_feat,   which_vaeac_model,   verbose,   seed,   ... )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"x_train data.table containing training data. Categorical data must class names \\(1,2,\\dots,K\\). model_description String (default make.names(Sys.time())). String containing, e.g., name data distribution additional parameter information. Used save name fitted model. provided, name generated based base::Sys.time() ensure unique name. use base::make.names() ensure valid file name operating systems. folder_to_save_model String (default base::tempdir()). String specifying path folder function save fitted vaeac model. Note  path removed returned explain() object vaeac.save_model = FALSE. cuda Logical (default FALSE). TRUE, vaeac model trained using cuda/GPU. torch::cuda_is_available() FALSE, fall back using CPU. Using GPU smaller tabular dataset often improve efficiency. See vignette(\"installation\", package = \"torch\") fo help enable running GPU (Linux Windows). n_vaeacs_initialize Positive integer (default 4). number different vaeac models initiate start. Pick best performing one epochs_initiation_phase epochs (default 2) continue training one. epochs_initiation_phase Positive integer (default 2). number epochs run n_vaeacs_initialize vaeac models continuing train best performing model. epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. epochs_early_stopping Positive integer (default NULL). training stops improvement validation IWAE epochs_early_stopping epochs. user wants training process solely based training criterion, epochs explain() set large number. NULL, shapr internally set epochs_early_stopping = vaeac.epochs early stopping occur. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. val_ratio Numeric (default 0.25). Scalar 0 1 indicating ratio instances input data used validation data. , val_ratio = 0.25 means 75% provided data used training data, remaining 25% used validation data. val_iwae_n_samples Positive integer (default 25). number generated samples used compute IWAE criterion validating vaeac model validation data. depth Positive integer (default 3). number hidden layers neural networks masked encoder, full encoder, decoder. width Positive integer (default 32). number neurons hidden layer neural networks masked encoder, full encoder, decoder. latent_dim Positive integer (default 8). number dimensions latent space. lr Positive numeric (default 0.001). learning rate used torch::optim_adam() optimizer. batch_size Positive integer (default 64). number samples include batch training vaeac model. Used torch::dataloader(). running_avg_n_values running_avg_n_values Positive integer (default 5). number previous IWAE values include compute running means IWAE criterion. activation_function torch::nn_module() representing activation function , e.g., torch::nn_relu() (default), torch::nn_leaky_relu(), torch::nn_selu(), torch::nn_sigmoid(). skip_conn_layer Logical (default TRUE). TRUE, apply identity skip connections layer, see skip_connection(). , add input \\(X\\) outcome hidden layer, output becomes \\(X + activation(WX + b)\\). skip_conn_masked_enc_dec Logical (default TRUE). TRUE, apply concatenate skip connections layers masked encoder decoder. first layer masked encoder linked last layer decoder. second layer masked encoder linked second last layer decoder, . batch_normalization Logical (default FALSE). TRUE, apply batch normalization activation function. Note skip_conn_layer = TRUE, normalization applied inclusion skip connection. , batch normalize whole quantity \\(X + activation(WX + b)\\). paired_sampling Logical (default TRUE). TRUE, apply paired sampling training batches. , training observations batch duplicated, first instance masked \\(S\\) second instance masked \\(\\bar{S}\\). ensures training vaeac model becomes stable model access full version training observation. However, increase training time due complex implementation doubling size batch. See paired_sampler() information. masking_ratio Numeric (default 0.5). Probability masking feature mcar_mask_generator() (MCAR = Missing Completely Random). MCAR masking scheme ensures vaeac model can arbitrary conditioning coalitions trained. masking_ratio overruled mask_gen_coalitions specified. mask_gen_coalitions Matrix (default NULL). Matrix containing coalitions vaeac model trained , see specified_masks_mask_generator(). parameter used internally shapr consider subset coalitions, .e., n_coalitions \\(< 2^{n_{\\text{features}}}\\), group Shapley, .e., group specified explain(). mask_gen_coalitions_prob Numeric array (default NULL). Array length equal height mask_gen_coalitions containing probabilities sampling corresponding coalitions mask_gen_coalitions. sigma_mu Numeric (default 1e4). One two hyperparameter values normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). sigma_sigma Numeric (default 1e-4). One two hyperparameter values normal-gamma prior used masked encoder, see Section 3.3.1 Olsen et al. (2022). save_data Logical (default FALSE). TRUE, data stored together model. Useful one continue train model later using vaeac_train_model_continue(). log_exp_cont_feat Logical (default FALSE). \\(\\log\\) transform continuous features sending data vaeac(). vaeac model creates unbounded Monte Carlo sample values. Thus, continuous features strictly positive (, e.g., Burr distribution Abalone data set), can advantageous \\(\\log\\) transform data unbounded form using vaeac. TRUE, vaeac_postprocess_data() take \\(\\exp\\) results get back strictly positive values using vaeac model impute missing values/generate Monte Carlo samples. which_vaeac_model String (default best). name vaeac model (snapshots different epochs) use generating Monte Carlo samples. standard choices : \"best\" (epoch lowest IWAE), \"best_running\" (epoch lowest running IWAE, see vaeac.running_avg_n_values), last (last epoch). Note additional choices available vaeac.save_every_nth_epoch provided. example, vaeac.save_every_nth_epoch = 5, vaeac.which_vaeac_model can also take values \"epoch_5\", \"epoch_10\", \"epoch_15\", . verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). seed Positive integer (default 1). Seed reproducibility. Specifies seed randomness based code run. ... List extra parameters, currently used.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"list containing training/validation errors paths vaeac models saved disk.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"vaeac model consists three neural networks, .e., masked encoder, full encoder, decoder. networks shared depth, width, activation_function. encoders maps x_train latent representation dimension latent_dim, decoder maps latent representations back feature space. See Olsen et al. (2022) details. function first initiates n_vaeacs_initialize vaeac models different randomly initiated network parameter values remedy poorly initiated values. epochs_initiation_phase epochs, n_vaeacs_initialize vaeac models compared function continues train best performing one total epochs epochs. networks trained using ADAM optimizer learning rate lr.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Train the Vaeac Model ‚Äî vaeac_train_model","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_auxiliary.html","id":null,"dir":"Reference","previous_headings":"","what":"Function used to train a vaeac model ‚Äî vaeac_train_model_auxiliary","title":"Function used to train a vaeac model ‚Äî vaeac_train_model_auxiliary","text":"function can applied initialization phase , train several initiated vaeac models, keep training best performing vaeac model remaining number epochs. former setting initialization_idx provided latter NULL. NULL, save vaeac models lowest VLB, IWAE, running IWAE, epochs according save_every_nth_epoch disk.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_auxiliary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function used to train a vaeac model ‚Äî vaeac_train_model_auxiliary","text":"","code":"vaeac_train_model_auxiliary(   vaeac_model,   optimizer,   train_dataloader,   val_dataloader,   val_iwae_n_samples,   running_avg_n_values,   verbose,   cuda,   epochs,   save_every_nth_epoch,   epochs_early_stopping,   epochs_start = 1,   progressr_bar = NULL,   vaeac_save_file_names = NULL,   state_list = NULL,   initialization_idx = NULL,   n_vaeacs_initialize = NULL,   train_vlb = NULL,   val_iwae = NULL,   val_iwae_running = NULL )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_auxiliary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function used to train a vaeac model ‚Äî vaeac_train_model_auxiliary","text":"vaeac_model vaeac() object. vaeac model function train. optimizer torch::optimizer() object. See vaeac_get_optimizer(). train_dataloader torch::dataloader() containing training data vaeac model. val_dataloader torch::dataloader() containing validation data vaeac model. val_iwae_n_samples Positive integer (default 25). number generated samples used compute IWAE criterion validating vaeac model validation data. running_avg_n_values running_avg_n_values Positive integer (default 5). number previous IWAE values include compute running means IWAE criterion. verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). cuda Logical (default FALSE). TRUE, vaeac model trained using cuda/GPU. torch::cuda_is_available() FALSE, fall back using CPU. Using GPU smaller tabular dataset often improve efficiency. See vignette(\"installation\", package = \"torch\") fo help enable running GPU (Linux Windows). epochs Positive integer (default 100). number epochs train final vaeac model. includes epochs_initiation_phase, default 2. save_every_nth_epoch Positive integer (default NULL). provided, vaeac model every save_every_nth_epochth epoch saved. epochs_early_stopping Positive integer (default NULL). training stops improvement validation IWAE epochs_early_stopping epochs. user wants training process solely based training criterion, epochs explain() set large number. NULL, shapr internally set epochs_early_stopping = vaeac.epochs early stopping occur. epochs_start Positive integer (default 1). epoch training starting . progressr_bar progressr::progressor() object (default NULL) keep track progress. vaeac_save_file_names Array strings containing save file names vaeac model. state_list Named list containing objects returned vaeac_get_full_state_list(). initialization_idx Positive integer (default NULL). index current vaeac model initialization phase. n_vaeacs_initialize Positive integer (default 4). number different vaeac models initiate start. Pick best performing one epochs_initiation_phase epochs (default 2) continue training one. train_vlb torch::torch_tensor() (default NULL) one dimension containing previous values training VLB. val_iwae torch::torch_tensor() (default NULL) one dimension containing previous values validation IWAE. val_iwae_running torch::torch_tensor() (default NULL) one dimension containing previous values running validation IWAE.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_auxiliary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function used to train a vaeac model ‚Äî vaeac_train_model_auxiliary","text":"Depending initialization phase . either trained vaeac model, list vaeac models stored disk parameters model.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_auxiliary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function used to train a vaeac model ‚Äî vaeac_train_model_auxiliary","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_continue.html","id":null,"dir":"Reference","previous_headings":"","what":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","title":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","text":"Function loads previously trained vaeac model continue training, either new data dataset trained . given new dataset, assume new dataset distribution one_hot_max_sizes original dataset.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_continue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","text":"","code":"vaeac_train_model_continue(   explanation,   epochs_new,   lr_new = NULL,   x_train = NULL,   save_data = FALSE,   verbose = NULL,   seed = 1 )"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_continue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","text":"explanation explain() object vaeac must used approach. epochs_new Positive integer. number extra epochs conduct. lr_new Positive numeric. overwrite old learning rate adam optimizer. x_train data.table containing training data. Categorical data must class names \\(1,2,\\dots,K\\). save_data Logical (default FALSE). TRUE, data stored together model. Useful one continue train model later using vaeac_train_model_continue(). verbose String vector NULL. Controls verbosity (printout detail level) via one \"basic\", \"progress\", \"convergence\", \"shapley\" \"vS_details\". \"basic\" (default) displays basic information computation messages parameters/checks. \"progress\" displays calculation process function currently . \"convergence\" displays close Shapley value estimates convergence (iterative = TRUE). \"shapley\" displays intermediate Shapley value estimates standard deviations (iterative = TRUE), final estimates. \"vS_details\" displays information v(S) estimates, relevant approach %% c(\"regression_separate\", \"regression_surrogate\", \"vaeac\"). NULL means printout. combination can used, e.g., verbose = c(\"basic\", \"vS_details\"). seed Positive integer (default 1). Seed reproducibility. Specifies seed randomness based code run.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_continue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","text":"list containing training/validation errors paths vaeac models saved disk.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_continue.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","text":"Olsen, L. H., Glad, . K., Jullum, M., & Aas, K. (2022). Using Shapley values variational autoencoders explain predictive models dependent mixed features. Journal machine learning research, 23(213), 1-51","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_train_model_continue.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Continue to Train the vaeac Model ‚Äî vaeac_train_model_continue","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_para_locations.html","id":null,"dir":"Reference","previous_headings":"","what":"Move vaeac parameters to correct location ‚Äî vaeac_update_para_locations","title":"Move vaeac parameters to correct location ‚Äî vaeac_update_para_locations","text":"function ensures main extra parameters vaeac approach located right locations.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_para_locations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move vaeac parameters to correct location ‚Äî vaeac_update_para_locations","text":"","code":"vaeac_update_para_locations(parameters)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_para_locations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move vaeac parameters to correct location ‚Äî vaeac_update_para_locations","text":"parameters List. internal$parameters list created inside explain() function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_para_locations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move vaeac parameters to correct location ‚Äî vaeac_update_para_locations","text":"Updated version parameters vaeac parameters located correct location.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_para_locations.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Move vaeac parameters to correct location ‚Äî vaeac_update_para_locations","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_pretrained_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that checks and adds a pre-trained vaeac model ‚Äî vaeac_update_pretrained_model","title":"Function that checks and adds a pre-trained vaeac model ‚Äî vaeac_update_pretrained_model","text":"Function checks adds pre-trained vaeac model","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_pretrained_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that checks and adds a pre-trained vaeac model ‚Äî vaeac_update_pretrained_model","text":"","code":"vaeac_update_pretrained_model(parameters)"},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_pretrained_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that checks and adds a pre-trained vaeac model ‚Äî vaeac_update_pretrained_model","text":"parameters List containing parameters used within explain().","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_pretrained_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that checks and adds a pre-trained vaeac model ‚Äî vaeac_update_pretrained_model","text":"function adds valid pre-trained vaeac model parameter.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/vaeac_update_pretrained_model.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function that checks and adds a pre-trained vaeac model ‚Äî vaeac_update_pretrained_model","text":"Lars Henry Berge Olsen","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate weighted matrix ‚Äî weight_matrix","title":"Calculate weighted matrix ‚Äî weight_matrix","text":"Calculate weighted matrix","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate weighted matrix ‚Äî weight_matrix","text":"","code":"weight_matrix(X, normalize_W_weights = TRUE)"},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate weighted matrix ‚Äî weight_matrix","text":"X data.table. Output create_coalition_table(). normalize_W_weights Logical. Whether normalize coalition weights sum 1 increased numerical stability solving WLS (weighted least squares). Applies coalitions except coalitions 1 2^m.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate weighted matrix ‚Äî weight_matrix","text":"Numeric matrix. See weight_matrix_cpp() information.","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate weighted matrix ‚Äî weight_matrix","text":"Nikolai Sellereite, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix_cpp.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate weight matrix ‚Äî weight_matrix_cpp","title":"Calculate weight matrix ‚Äî weight_matrix_cpp","text":"Calculate weight matrix","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix_cpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate weight matrix ‚Äî weight_matrix_cpp","text":"","code":"weight_matrix_cpp(coalitions, m, n, w)"},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix_cpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate weight matrix ‚Äî weight_matrix_cpp","text":"coalitions List. elements equals integer vector representing valid combination features/feature groups. m Integer. Number features/feature groups. n Integer. Number combinations. w Numeric vector length n. w[] equals Shapley weight feature/feature group combination , represented coalitions[[]].","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix_cpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate weight matrix ‚Äî weight_matrix_cpp","text":"Matrix dimension n x m + 1","code":""},{"path":"https://norskregnesentral.github.io/shapr/reference/weight_matrix_cpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate weight matrix ‚Äî weight_matrix_cpp","text":"Nikolai Sellereite, Martin Jullum","code":""},{"path":"https://norskregnesentral.github.io/shapr/shaprpy.html","id":null,"dir":"","previous_headings":"","what":"shaprpy","title":"shaprpy","text":"Python wrapper R package shapr. NOTE: wrapper comprehensively tested R-package. shaprpy relies heavily rpy2 Python library accessing R within Python. rpy2 limited support Windows. shaprpy tested Linux.","code":""},{"path":"https://norskregnesentral.github.io/shapr/shaprpy.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"shaprpy","text":"instructions assume already pip R installed exposed python environment want run shaprpy. Official instructions installing pip can found , R . R can also installed pip follows: conda:","code":"pip install rbase conda install -c r r"},{"path":"https://norskregnesentral.github.io/shapr/shaprpy.html","id":"install-r-package","dir":"","previous_headings":"Install","what":"Install R-package","title":"shaprpy","text":"shaprpy Python wrapper requires latest version shapr R-package CRAN. Install running following terminal command folder readme file (.../shapr/python):","code":"Rscript -e 'install.packages(\"shapr\", repos=\"https://cran.rstudio.com\")'"},{"path":"https://norskregnesentral.github.io/shapr/shaprpy.html","id":"install-python-wrapper","dir":"","previous_headings":"","what":"Install python wrapper","title":"shaprpy","text":"folder readme file (.../shapr/python), run","code":"pip install -e ."},{"path":"https://norskregnesentral.github.io/shapr/shaprpy.html","id":"demo","dir":"","previous_headings":"","what":"Demo","title":"shaprpy","text":"shaprpy knows explain predictions models sklearn, keras (sequential) xgboost. models, one can provide custom predict_model function (optionally custom get_model_specs) shaprpy.explain. See /examples runnable examples, including example custom PyTorch model. Specifically, /examples/regression_paradigm.py file demonstrates use regression paradigm explained Olsen et al.¬†(2024). show specify regression model, enable automatic cross-validation model‚Äôs hyperparameters, applying pre-processing steps data fitting regression models.","code":"from sklearn.ensemble import RandomForestRegressor from shaprpy import explain from shaprpy.datasets import load_california_housing  dfx_train, dfx_test, dfy_train, dfy_test = load_california_housing()  ## Fit model model = RandomForestRegressor() model.fit(dfx_train, dfy_train.values.flatten())  ## Shapr explanation = explain(     model = model,     x_train = dfx_train,     x_explain = dfx_test,     approach = 'empirical',     phi0 = dfy_train.mean().item(),     seed = 1 ) print(explanation[\"shapley_values_est\"])"},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-105","dir":"Changelog","previous_headings":"","what":"shapr 1.0.5","title":"shapr 1.0.5","text":"CRAN release: 2025-08-25","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"new-features-1-0-5","dir":"Changelog","previous_headings":"","what":"New features","title":"shapr 1.0.5","text":"Added get_results() extracting key components shapr object, including Shapley values, model parameters, iterative computation details (#460). Added summary.shapr() method, builds get_results() internal format_xyz() functions provide concise overview explanation objects (#460).","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"improvements-1-0-5","dir":"Changelog","previous_headings":"","what":"Improvements","title":"shapr 1.0.5","text":"Enhanced print.shapr() support printing specific components, customizable control digits decimal precision (#460). Refactored cli-based output functions improved reuse across multiple methods (#460). Updated vignettes, examples, tests reflect new functionality (#460). Fixed spelling, grammar, textual inconsistencies documentation, comments, vignettes (#465). Applied various minor visual improvements (#460, #464).","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"bug-fixes-1-0-5","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"shapr 1.0.5","text":"Fixed error handling many features removing .integer() coercion computation coalitions per coalition size (#462).","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-104","dir":"Changelog","previous_headings":"","what":"shapr 1.0.4","title":"shapr 1.0.4","text":"CRAN release: 2025-04-28 Implement semi-deterministic sampling coalitions similar default shap python library described discussed PySHAP* strategy Olsen & Jullum (2024). disabled default, can set via extra_computation_args = list(semi_deterministic_sampling = TRUE) explain(). functionality available paired coalition sampling (default) enabled. See #449 details. Deletes regression-surrogate parsnip object testing avoid future conflicts model object changes. (Second last commit #447). Improve update logic print setting number coalitions next iteration iterative = TRUE (#452) Allow passing vS_batching_method explain()/explain_forecast() specify batch computation method (default \"future\" , \"forloop\" available mainly dev purposes) (#452) Transform use cli rlang packages provide messages/warnings/stops nicer formatting layout. messages (via cli_inform()) now also obey verbose argument displayed 'basic' %% verbose TRUE. header printout also differs explain()/explain_forecast() whether called Python. also adds cli rlang imports. (#453) Now using testthat::skip_if_not_installed tests requiring suggested packages ensure skipped gracefully dependencies unavailable (#451)","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"other-minor-fixes-1-0-4","dir":"Changelog","previous_headings":"","what":"Other minor fixes","title":"shapr 1.0.4","text":"Two minor bugs related KernelSHAP_reweighing() (#448) Two minor bugs related weighting asymmetric Shapley values (#449) Check seed argument, pass torch NULL (#452) Make explain_forecast() use future batch computation well (default) (#452) Fix bug AICc + independence variants approach = 'empirical' occurring n_features < n_explain (#453)","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-103","dir":"Changelog","previous_headings":"","what":"shapr 1.0.3","title":"shapr 1.0.3","text":"CRAN release: 2025-03-26 Fix documentation issues detected shapr 1.0.2 release (#442) Remove examples unexported functions Replace long running examples Replace usage print() warning() two occasions Fix issue Expected <nn_module> got object type <NULL> approach='vaeac' recent torch update broke (#444) Changes default seed explain() explain_forecast() 1 NULL avoid set.seed() conflict later called code (#445) minor fixes Add digits arguments internal snapshot testing expect_snapshot_rds() reduce false positive roundoff-errors platforms (#444) Adjust dependencies Suggests usage tests (#446) Used skip_on_cran() reduce check time CRAN snapshot tests tested anyway","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-102","dir":"Changelog","previous_headings":"","what":"shapr 1.0.2","title":"shapr 1.0.2","text":"CRAN release: 2025-02-06 Fix CRAN NOTE turned bug related returning NULL rather integer(0) identify (unconditional) asymmetric causal sampling (#435) [Py] Get ‚Äòshaprpy‚Äô speed latest ‚Äòshapr‚Äô version return internal list properly (#436) Allow manual groups explain_forecast() (#433) Minor updates readme pkgdown site CRAN release shapr 1.0.1 (#437, #438) Require data.table >= 1.15.0 allow uniform usage =.(#434) Minor doc edits (#439)","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-101","dir":"Changelog","previous_headings":"","what":"shapr 1.0.1","title":"shapr 1.0.1","text":"CRAN release: 2025-01-16 Spelling checking minor clean (#431) Add extra_computation_args output_args explain_forecast() (#428) Rename vaeac plotting functions (#428) Move explain() arguments paired_shap_sampling kernelSHAP_reweighting extra_computation_args (#428) Improved unified documentation (#427) Remove seed argument boostrap function better handled mother function (#427) Renamed various internal functions consistent names rest package (#427) Remove MSEv explain_forecast (supported horizon=1). return general manner future (#427) Improve efficiency coalition sampling code move string sampling (#426) Bugfix iterative = TRUE explain_forecast() using coalitions previous iterations (#426) Bugfix handling output verbose argument explain_forecast() (#425) Improved flexibility beeswarm plot functionality (#424) Bugfix edge case party package returns constparty object (#423) Bugfix error due extra comma rarely used warning (#422) Shined vignettes bit (#421) Bugfix keep_samp_for_vS iterative approach (#417) [Python] Brought python code base speed essentially functionality explain() R (#416) Please CRAN dontrun long running examples + skip_on_cran parallelized tests.","code":""},{"path":[]},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"breaking-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"shapr 1.0.0 (GitHub only)","text":"Moved explaining predictions using two functions (shapr() initial setup + explain() explanation specific observations), single function call (also named explain()). data used training explained gotten explicit names (x_train x_explain). order input arguments also slightly changed (model now first argument). Prediction checking functions custom models now passed directly arguments explain() instead defined functions specific class global env. previously exported function make_dummies used explain xgboost models categorical data, removed simplify code base. rather handled custom prediction model. function explain.ctree_comb_mincrit, allowed combining models approch=ctree different mincrit parameters, removed simplify code base. may return completely general manner later version shapr. New argument names: prediction_zero -> phi0, n_combinations -> max_n_coalitions, n_samples -> n_MC_samples,","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"new-features-1-0-0","dir":"Changelog","previous_headings":"","what":"New features","title":"shapr 1.0.0 (GitHub only)","text":"Iterative Shapley value estimation convergence detection New approaches: vaeac, regression_separate, regression_surrogate, timeseries, categorical verbose argument explain() control amount output Parallelized computation v(S) future, including progress updates Paired_sampling coalitions prev_shapr_object argument explain() continue explanation previous object asymmetric causal Shapley values Improved KernelSHAP estimation adjusted weights reduced variance Release Python wrapper (shaprpyr, #325) explaining predictions Python models (Python) utilizing almost functionality shapr. wrapper moves back forth back forth Python R, prediction Python, almost everything else R. simplifies maintenance shaprpy significantly. wrapper available . Introduce batch computation conditional expectations (#244). essentially compute v(S)v(S) portion SS-subsets time, reduce amount data needed held memory. user can control number batches , set reasonable value default (#327). allows models large number features explained significantly lower RAM consumption (cost slight increase computation time) Parallelization batches (#38) using future framework. Progress bar (#293) using progressr package. Must activated user progressr::handlers(global = TRUE) wrapping call explain() around progressr::with_progress({}) Added approach = 'categorical' (#256, #307) used explain models solely categorical features directly using/estimating joint distribution feature combinations. Added approch='timeseries' (#314) explaining classifications based time series data/models method described Sec 4.3 groupShapley paper. Implemented unique sampling Shapley value subsets (#227) Added new function explain_forecast explain forecasts time series models, various prediction horizons (#328). Uses different set input argument appropriate models. Re-implementation approach = 'independence' method providing significantly faster computation (longer special case empirical method). Also allow method used models categorical data (#315). Added ‚Äòbeeswarm‚Äô ‚Äòwaterfall‚Äô plots + new coloring scheme plots. See vignette examples. Added timing various parts explanation process.","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"under-the-hood-1-0-0","dir":"Changelog","previous_headings":"","what":"Under the hood","title":"shapr 1.0.0 (GitHub only)","text":"test base completely rewritten (#249). Now heavily utilizing snapshots large set benchmark calls explain, also using vdiffr plot tests. Test functions written exported core functions. Internal functions tested exported ones. Update GitHub actions (#335). Avoid unnecessary computation inverse weight matrix (#280)","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"minor-improvements-and-bug-fixes-1-0-0","dir":"Changelog","previous_headings":"","what":"Minor improvements and bug fixes","title":"shapr 1.0.0 (GitHub only)","text":"vignette/readme/tests now uses datasets::airquality dataset. avoids including new package just dataset (#248). Allows lm/glm/gam models interactions (#303). Previously, possible prediction functions defined internally due bug. Sampling group subsets implemented also grouping, features.","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"documentation-improvements-1-0-0","dir":"Changelog","previous_headings":"Minor improvements and bug fixes","what":"Documentation improvements","title":"shapr 1.0.0 (GitHub only)","text":"vignette updated reflect new framework explaining predictions, new package features/functionality. New vignettes also regression paradigm, vaeac asymmetric/causal Shapley values","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-023-github-only","dir":"Changelog","previous_headings":"","what":"shapr 0.2.3 (GitHub only)","title":"shapr 0.2.3 (GitHub only)","text":"Development version Added support groupSHAP, including check appropriate groups, examples tests Various modifications input internal functions reflect Shapley values may computed feature-wise group-wise Fixed bug passing non-named data shapr() explain() (e.g.¬†shapr(data[,1:5],model...)","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-022","dir":"Changelog","previous_headings":"","what":"shapr 0.2.2","title":"shapr 0.2.2","text":"CRAN release: 2023-05-04 Patch fix failing CRAN-tests R-devel due changed behavior attach(): Fixed changing simulate adding function .GlobalEnv failing test. Actual package affected.","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-021","dir":"Changelog","previous_headings":"","what":"shapr 0.2.1","title":"shapr 0.2.1","text":"CRAN release: 2023-02-27 Patch fix warning development version data.table due use nomatch argument merge(), requested data.table developers.","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-020","dir":"Changelog","previous_headings":"","what":"shapr 0.2.0","title":"shapr 0.2.0","text":"CRAN release: 2021-01-28 Minor CRAN release Added new dependence modeling approach ‚Äúctree‚Äù handles categorical features addition numerical ones. information see paper https://doi.org/10.1007/978-3-030-57321-8_7 Added support explain models take input categorical features model classes like xgboost originally takes numeric input. user side, additional call new make_dummies function required. See vignette details. Slight change user procedure explaining predictions custom models. now requires single function predict_model. Introduced thorough system extracting checking feature information model data passed shapr explain. features data checked consistency can extracted model object. model object missing necessary information, info data used instead. system checks feature labels, classes, factor levels. Due previous point, feature_names option previously used custom models removed. Added manual testing script custom model (currently handled testthat due environment issues). --hood changes checking shapr function.","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-014","dir":"Changelog","previous_headings":"","what":"shapr 0.1.4","title":"shapr 0.1.4","text":"CRAN release: 2021-01-21 Patch fulfill CRAN policy using packages Suggests conditionally (tests examples)","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-013","dir":"Changelog","previous_headings":"","what":"shapr 0.1.3","title":"shapr 0.1.3","text":"CRAN release: 2020-09-03 Fix installation error Solaris Updated README CRAN installation instructions badges","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-012","dir":"Changelog","previous_headings":"","what":"shapr 0.1.2","title":"shapr 0.1.2","text":"CRAN release: 2020-09-03 CRAN release Removed unused clustering code Removed several package dependencies Moved automatic check pkgdown site build Circle CI GitHub actions minor efficiency fixes Changed stopping threshold 12 13 features none-sampling version KernelSHAP consistency recommendation Changed package title (shortened) Minor fixes fulfill CRAN policy Improved documentation Revised internal/external exported/non-exported functions, leading far fewer external functions cleaner manual.","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-011","dir":"Changelog","previous_headings":"","what":"shapr 0.1.1","title":"shapr 0.1.1","text":"Journal Open Source Software release Improved installation instructions community guidelines README Improved documentation minor bugfixes","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-010","dir":"Changelog","previous_headings":"","what":"shapr 0.1.0","title":"shapr 0.1.0","text":"Support custom models Improved documentation Automated testing using testthat Added vignette gives introduction package Added webpage package using pkgdown Improved API end user Various bugfixes","code":""},{"path":"https://norskregnesentral.github.io/shapr/news/index.html","id":"shapr-0009000","dir":"Changelog","previous_headings":"","what":"shapr 0.0.0.9000","title":"shapr 0.0.0.9000","text":"First version package. Currently development.","code":""}]
